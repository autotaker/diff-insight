<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="dcterms.date" content="2024-09-19" />
  <title>Diff Insight Report - openai</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Diff Insight Report - openai</h1>
<p class="date">2024-09-19</p>
</header>
<p><a
href="https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:78943fc...MicrosoftDocs:e496207"
target="_blank">View Diff on GitHub</a></p>
<h1 id="ハイライト">ハイライト</h1>
<p>このコード変更では、Azure
OpenAIに関するいくつかのドキュメントが更新され、新機能の追加や旧機能の削除、改善が行われました。主要な変更点として、レガシーAPIの明示、グローバルプロビジョニングの導入、GPT-4
Turbo with Visionに関連する内容の大幅な削除、JavaScriptおよびREST
APIでの新しい音声機能などが挙げられます。</p>
<h2 id="新機能">新機能</h2>
<ul class="incremental">
<li><code>text-to-speech-javascript.md</code> の追加:
JavaScriptを使用してAzure
OpenAIのテキストから音声への変換を実装する方法。</li>
<li><code>whisper-javascript.md</code> の追加:
JavaScriptを使用したWhisperを使った音声の文字起こしのガイド。</li>
<li><code>provisioned-throughput-onboarding.md</code> の更新:
グローバルプロビジョニングの詳細な説明の追加。</li>
</ul>
<h2 id="破壊的変更">破壊的変更</h2>
<ul class="incremental">
<li><code>gpt-with-vision.md</code>
からの「Visionエンハンスメント」および「ビデオプロンプト」機能の削除。</li>
<li><code>gpt-v-python.md</code>、<code>gpt-v-rest.md</code>、<code>gpt-v-studio.md</code>
におけるGPT-4 Turbo with Vision関連情報の削除。</li>
<li><code>whisper-quickstart.md</code> の大幅な改訂:
内容の整理と簡素化、不要な部分の削除。</li>
</ul>
<h2 id="その他の更新">その他の更新</h2>
<ul class="incremental">
<li><code>provisioned-migration.md</code>:
予約のサイズに関するリンクの更新。</li>
<li><code>provisioned-throughput.md</code>:
グローバルプロビジョニングに関する情報を更新。</li>
<li><code>completions.md</code>:
レガシーコンプリーションAPIに関するタイトルと説明の更新。</li>
<li><code>deployment-types.md</code>:
デプロイメントタイプに関する情報の更新。</li>
<li><code>provisioned-get-started.md</code>:
グローバルプロビジョンドデプロイメントに関する説明の追加。</li>
<li><code>whisper-powershell.md</code>:
Whisper用のPowerShellによる音声処理に関する事前条件や設定手順の更新。</li>
<li><code>whisper-python.md</code>:
Whisper用のPythonに関するドキュメントの更新。</li>
<li><code>whisper-rest.md</code>: Whisper用のREST
APIに関するドキュメントの更新。</li>
<li><code>index.yml</code>: Azure OpenAI
Serviceドキュメントのメタデータ更新。</li>
<li><code>overview.md</code>: Azure OpenAI Service概要の更新。</li>
<li><code>quickstart.md</code>:
クイックスタートガイドのタイトルと説明の更新。</li>
<li><code>text-to-speech-quickstart.md</code>:
テキスト音声合成クイックスタートの更新。</li>
<li><code>toc.yml</code>: ドキュメント目次の更新。</li>
<li><code>whats-new.md</code>:
OpenAIサービスの最新リリース情報の追加。</li>
</ul>
<h1 id="インサイト">インサイト</h1>
<p>今回の変更は、Azure
OpenAIサービスのドキュメントに多岐にわたる調整と改善をもたらしました。特に目立つのは、GPT-4
Turbo with
Vision関連の情報が多数のドキュメントから削除されたことです。この変更は、具体的な使用手順や設定方法が一掃されたことを意味し、ユーザーがこれらの機能を利用できなくなる可能性を示唆しています。</p>
<p>一方で、新しい機能や更新も数多く追加されました。JavaScriptを使用したテキストから音声への変換や、Whisperを用いた音声の文字起こしに関するドキュメントが新たに追加され、開発者に対してこれまで以上に多様なツールとリソースを提供しています。</p>
<p>また、グローバルプロビジョニングに関する詳細な説明が補完され、プロビジョニングされたスループットユニットやCLIでのデプロイメント作成に関する情報が明確に整理されました。これにより、ユーザーは新しいデプロイメントタイプをより理解しやすくなり、特にグローバルなインフラ利用における設定や最適なデータセンターへの動的ルーティングの利点を享受できるようになっています。</p>
<p>レガシーAPIのタイトルと説明の更新は、ユーザーに対して古いAPIであることを明確に認識させ、期待や使い方に対する正確な</p>
<h1 id="summary-table">Summary Table</h1>
<table style="width:100%;">
<colgroup>
<col style="width: 23%" />
<col style="width: 11%" />
<col style="width: 25%" />
<col style="width: 15%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
</colgroup>
<thead>
<tr>
<th>Filename</th>
<th>Type</th>
<th>Title</th>
<th>Status</th>
<th>A</th>
<th>D</th>
<th>M</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#item-991388">gpt-with-vision.md</a></td>
<td>minor update</td>
<td>GPT-4 Turbo with Visionの改善を削除しました</td>
<td>modified</td>
<td>0</td>
<td>36</td>
<td>36</td>
</tr>
<tr>
<td><a href="#item-68e143">provisioned-migration.md</a></td>
<td>minor update</td>
<td>予約のサイズに関するリンクを更新</td>
<td>modified</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td><a href="#item-022e0c">provisioned-throughput.md</a></td>
<td>minor update</td>
<td>プロビジョニングされたデプロイメントに関する情報を更新</td>
<td>modified</td>
<td>14</td>
<td>13</td>
<td>27</td>
</tr>
<tr>
<td><a href="#item-79f39a">completions.md</a></td>
<td>minor update</td>
<td>レガシーコンプリーションAPIに関するタイトルと説明の更新</td>
<td>modified</td>
<td>3</td>
<td>3</td>
<td>6</td>
</tr>
<tr>
<td><a href="#item-210814">deployment-types.md</a></td>
<td>minor update</td>
<td>デプロイメントタイプに関する情報の更新</td>
<td>modified</td>
<td>22</td>
<td>15</td>
<td>37</td>
</tr>
<tr>
<td><a href="#item-4d8502">gpt-with-vision.md</a></td>
<td>breaking change</td>
<td>Visionエンハンスメントおよびビデオプロンプトの機能削除</td>
<td>modified</td>
<td>1</td>
<td>414</td>
<td>415</td>
</tr>
<tr>
<td><a href="#item-c8df1c">provisioned-get-started.md</a></td>
<td>minor update</td>
<td>グローバルプロビジョンドデプロイメントに関する説明の追加</td>
<td>modified</td>
<td>13</td>
<td>13</td>
<td>26</td>
</tr>
<tr>
<td><a href="#item-3eb72b">provisioned-throughput-onboarding.md</a></td>
<td>minor update</td>
<td>グローバルプロビジョンドに関するコンテンツの追加</td>
<td>modified</td>
<td>10</td>
<td>11</td>
<td>21</td>
</tr>
<tr>
<td><a href="#item-366276">gpt-v-python.md</a></td>
<td>breaking change</td>
<td>GPT-4 Turbo with Visionに関する内容の削除</td>
<td>modified</td>
<td>0</td>
<td>91</td>
<td>91</td>
</tr>
<tr>
<td><a href="#item-65c91c">gpt-v-rest.md</a></td>
<td>breaking change</td>
<td>GPT-4 Turbo with Visionに関するコンテンツの削除</td>
<td>modified</td>
<td>0</td>
<td>97</td>
<td>97</td>
</tr>
<tr>
<td><a href="#item-dcd50e">gpt-v-studio.md</a></td>
<td>breaking change</td>
<td>GPT-4 Turbo with Visionに関する詳細の削除</td>
<td>modified</td>
<td>0</td>
<td>61</td>
<td>61</td>
</tr>
<tr>
<td><a href="#item-e9b653">text-to-speech-javascript.md</a></td>
<td>new feature</td>
<td>JavaScript用のテキストから音声への変換ガイドの追加</td>
<td>added</td>
<td>247</td>
<td>0</td>
<td>247</td>
</tr>
<tr>
<td><a href="#item-d067a1">text-to-speech-rest.md</a></td>
<td>minor update</td>
<td>REST APIの事前条件とセットアップ手順の拡充</td>
<td>modified</td>
<td>59</td>
<td>1</td>
<td>60</td>
</tr>
<tr>
<td><a href="#item-3ee990">whisper-javascript.md</a></td>
<td>new feature</td>
<td>Whisperを用いた音声の文字起こしに関するドキュメントの追加</td>
<td>added</td>
<td>235</td>
<td>0</td>
<td>235</td>
</tr>
<tr>
<td><a href="#item-7db269">whisper-powershell.md</a></td>
<td>minor update</td>
<td>Whisper用のPowerShellによる音声処理に関するドキュメントの更新</td>
<td>modified</td>
<td>61</td>
<td>1</td>
<td>62</td>
</tr>
<tr>
<td><a href="#item-e61179">whisper-python.md</a></td>
<td>minor update</td>
<td>Whisper用のPythonに関するドキュメントの更新</td>
<td>modified</td>
<td>67</td>
<td>4</td>
<td>71</td>
</tr>
<tr>
<td><a href="#item-639ccb">whisper-rest.md</a></td>
<td>minor update</td>
<td>Whisper用のREST APIに関するドキュメントの更新</td>
<td>modified</td>
<td>63</td>
<td>1</td>
<td>64</td>
</tr>
<tr>
<td><a href="#item-0adb87">index.yml</a></td>
<td>minor update</td>
<td>Azure OpenAI Serviceのドキュメントの更新</td>
<td>modified</td>
<td>3</td>
<td>3</td>
<td>6</td>
</tr>
<tr>
<td><a href="#item-97d507">overview.md</a></td>
<td>minor update</td>
<td>Azure OpenAI Serviceの概要の更新</td>
<td>modified</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td><a href="#item-7d1656">quickstart.md</a></td>
<td>minor update</td>
<td>Azure OpenAI Serviceのクイックスタートガイドの更新</td>
<td>modified</td>
<td>3</td>
<td>3</td>
<td>6</td>
</tr>
<tr>
<td><a href="#item-c344ad">text-to-speech-quickstart.md</a></td>
<td>minor update</td>
<td>Azure OpenAI Serviceのテキスト音声合成クイックスタートの更新</td>
<td>modified</td>
<td>8</td>
<td>53</td>
<td>61</td>
</tr>
<tr>
<td><a href="#item-c945af">toc.yml</a></td>
<td>minor update</td>
<td>OpenAIサービスの目次の更新</td>
<td>modified</td>
<td>3</td>
<td>3</td>
<td>6</td>
</tr>
<tr>
<td><a href="#item-53303b">whats-new.md</a></td>
<td>minor update</td>
<td>What’s New in OpenAIサービスの更新</td>
<td>modified</td>
<td>10</td>
<td>0</td>
<td>10</td>
</tr>
<tr>
<td><a href="#item-4cae3d">whisper-quickstart.md</a></td>
<td>breaking change</td>
<td>Whisperモデルのクイックスタートガイドの大幅な改訂</td>
<td>modified</td>
<td>9</td>
<td>61</td>
<td>70</td>
</tr>
</tbody>
</table>
<h1 id="modified-contents">Modified Contents</h1>
<h2
id="item-991388">articles/ai-services/openai/concepts/gpt-with-vision.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb1"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -20,31 +20,6 @@ To try out GPT-4 Turbo with Vision, see the [quickstart](/azure/ai-services/open</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a> The GPT-4 Turbo with Vision model answers general questions about what&#39;s present in the images or videos you upload.</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="st">-## Enhancements</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="st">-Enhancements let you incorporate other Azure AI services (such as Azure AI Vision) to add new functionality to the chat-with-vision experience.</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; To use Vision enhancement, you need a Computer Vision resource. It must be in the paid (S1) tier and in the same Azure region as your GPT-4 Turbo with Vision resource.</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Vision enhancements are not supported by the GPT-4 Turbo GA model. They are only available with the preview models.</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="st">-**Object grounding**: Azure AI Vision complements GPT-4 Turbo with Vision’s text response by identifying and locating salient objects in the input images. This lets the chat model give more accurate and detailed responses about the contents of the image.</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="st">-:::image type=&quot;content&quot; source=&quot;../media/concepts/gpt-v/object-grounding.png&quot; alt-text=&quot;Screenshot of an image with object grounding applied. Objects have bounding boxes with labels.&quot;:::</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="st">-:::image type=&quot;content&quot; source=&quot;../media/concepts/gpt-v/object-grounding-response.png&quot; alt-text=&quot;Screenshot of a chat response to an image prompt about an outfit. The response is an itemized list of clothing items seen in the image.&quot;:::</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="st">-**Optical Character Recognition (OCR)**: Azure AI Vision complements GPT-4 Turbo with Vision by providing high-quality OCR results as supplementary information to the chat model. It allows the model to produce higher quality responses for images with dense text, transformed images, and numbers-heavy financial documents, and increases the variety of languages the model can recognize in text.</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="st">-:::image type=&quot;content&quot; source=&quot;../media/concepts/gpt-v/receipts.png&quot; alt-text=&quot;Photo of several receipts.&quot;:::</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="st">-:::image type=&quot;content&quot; source=&quot;../media/concepts/gpt-v/ocr-response.png&quot; alt-text=&quot;Screenshot of the JSON response of an OCR call.&quot;:::</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="st">-**Video prompt**: The **video prompt** enhancement lets you use video clips as input for AI chat, enabling the model to generate summaries and answers about video content. It uses Azure AI Vision Video Retrieval to sample a set of frames from a video and create a transcript of the speech in the video.</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RW1eHRf]</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a> ## Special pricing information</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -59,15 +34,6 @@ Base Pricing for GPT-4 Turbo with Vision is:</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a> See the [Tokens section of the overview](/azure/ai-services/openai/overview#tokens) for information on how text and images translate to tokens.</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="st">-If you turn on Enhancements, additional usage applies for using GPT-4 Turbo with Vision with Azure AI Vision functionality.</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="st">-| Model        | Price        |</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="st">-|-----------------|-----------------|</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="st">-| + Enhanced add-on features for OCR | $1.5 per 1000 transactions |</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="st">-| + Enhanced add-on features for Object Detection | $1.5 per 1000 transactions |</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="st">-| + Enhanced add-on feature for “Video Retrieval” integration **&lt;sup&gt;1&lt;/sup&gt;** | Ingestion: $0.05 per minute of video &lt;br&gt;Transactions: $0.25 per 1000 queries of the Video Retrieval index |</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="st">-**&lt;sup&gt;1&lt;/sup&gt;** Processing videos involves the use of extra tokens to identify key frames for analysis. The number of these additional tokens will be roughly equivalent to the sum of the tokens in the text input, plus 700 tokens.</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a> ### Example image price calculation</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a> &gt; [!IMPORTANT]</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -108,9 +74,7 @@ This section describes the limitations of GPT-4 Turbo with Vision.</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a> ### Image support</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="st">-- **Limitation on image enhancements per chat session**: Enhancements cannot be applied to multiple images within a single chat call.</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a> - **Maximum input image size**: The maximum size for input images is restricted to 20 MB.</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="st">-- **Object grounding in enhancement API**: When the enhancement API is used for object grounding, and the model detects duplicates of an object, it will generate one bounding box and label for all the duplicates instead of separate ones for each.</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a> - **Low resolution accuracy**: When images are analyzed using the &quot;low resolution&quot; setting, it allows for faster responses and uses fewer input tokens for certain use cases. However, this could impact the accuracy of object and text recognition within the image.</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a> - **Image chat restriction**: When you upload images in Azure OpenAI Studio or the API, there is a limit of 10 images per chat call.</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary">Summary</h3>
<div class="sourceCode" id="cb2"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;GPT-4 Turbo with Visionの改善を削除しました&quot;</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation">Explanation</h3>
<p>この変更では、<code>gpt-with-vision.md</code>
ドキュメントにおけるいくつかの「改善」セクションが削除されました。具体的には、Azure
AI
Visionの機能とそれに関連する使用条件についての情報が削除されています。これには、オブジェクトグラウンディング、光学文字認識（OCR）、およびビデオプロンプトの拡張に関する内容が含まれます。これらの削除により、ドキュメントが簡潔になり、利用規約やサービスの詳細がより明確に理解できるようになっています。また、料金体系に関する情報も一部削除され、これによりユーザーにとって分かりやすい料金情報が提供されていると思われます。</p>
<h2
id="item-68e143">articles/ai-services/openai/concepts/provisioned-migration.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb3"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -79,7 +79,7 @@ We also recommend that customers using commitments now create their deployments</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a> See the following links for more information. The guidance for reservations and commitments is the same:</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a> * [Capacity Transparency](#self-service-migration)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="st">-* [Sizing reservations](../how-to/provisioned-throughput-onboarding.md#important-sizing-azure-openai-provisioned-reservations)</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="va">+* [Sizing reservations](../how-to/provisioned-throughput-onboarding.md#important-sizing-azure-openai-provisioned--global-provisioned-reservations)</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a> ## New hourly reservation payment model</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-1">Summary</h3>
<div class="sourceCode" id="cb4"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;予約のサイズに関するリンクを更新&quot;</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-1">Explanation</h3>
<p>この変更では、<code>provisioned-migration.md</code>
ドキュメントにおける「予約のサイズ」に関するリンクが更新されました。以前のリンクは「重要:
Azure OpenAI
プロビジョニング予約のサイズ」に関連しており、具体的には現在のリンクは「重要:
Azure OpenAI
グローバルプロビジョンド予約のサイズ」へと変更されています。これにより、ユーザーは最新の情報にアクセスできるようになり、プロビジョニング予約のサイズに関するガイダンスが明確になります。この変更は、ドキュメント全体の一貫性と正確性を保つために重要です。</p>
<h2
id="item-022e0c">articles/ai-services/openai/concepts/provisioned-throughput.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb5"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -17,23 +17,23 @@ recommendations: false</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a> The provisioned throughput capability allows you to specify the amount of throughput you require in a deployment. The service then allocates the necessary model processing capacity and ensures it&#39;s ready for you. Throughput is defined in terms of provisioned throughput units (PTU) which is a normalized way of representing the throughput for your deployment. Each model-version pair requires different amounts of PTU to deploy and provide different amounts of throughput per PTU. </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="st">-## What does the provisioned deployment type provide?</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="va">+## What do the provisioned and global provisioned deployment types provide?</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a> - **Predictable performance:** stable max latency and throughput for uniform workloads. </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a> - **Reserved processing capacity:** A deployment configures the amount of throughput. Once deployed, the throughput is available whether used or not.</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a> - **Cost savings:** High throughput workloads might provide cost savings vs token-based consumption.</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="st">-An Azure OpenAI Deployment is a unit of management for a specific OpenAI Model. A deployment provides customer access to a model for inference and integrates more features like Content Moderation ([See content moderation documentation](content-filter.md)).</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="va">+An Azure OpenAI Deployment is a unit of management for a specific OpenAI Model. A deployment provides customer access to a model for inference and integrates more features like Content Moderation ([See content moderation documentation](content-filter.md)). Global deployments are available in the same Azure OpenAI resources as non-global deployment types but allow you to leverage Azure&#39;s global infrastructure to dynamically route traffic to the data center with best availability for each request.</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a> ## What do you get?</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a> | Topic | Provisioned|</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a> |---|---|</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a> | What is it? | Provides guaranteed throughput at smaller increments than the existing provisioned offer. Deployments have a consistent max latency for a given model-version. |</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a> | Who is it for? | Customers who want guaranteed throughput with minimal latency variance. |</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="st">-| Quota | Provisioned-managed throughput Units for a given model. |</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="va">+| Quota | Provisioned Managed Throughput Unit or Global Provisioned Managed Throughput Unit assigned per region. Quota can be used across any available Azure OpenAI model.|</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a> | Latency | Max latency constrained from the model. Overall latency is a factor of call shape.  |</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="st">-| Utilization | Provisioned-managed Utilization measure provided in Azure Monitor. |</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="va">+| Utilization | Provisioned-managed Utilization V2 measure provided in Azure Monitor. |</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a> | Estimating size | Provided calculator in the studio &amp; benchmarking script. |</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a> ## What models and regions are available for provisioned throughput?</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -47,9 +47,9 @@ An Azure OpenAI Deployment is a unit of management for a specific OpenAI Model.</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a> ### Deployment types</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="st">-When creating a provisioned deployment in Azure OpenAI Studio, the deployment type on the Create Deployment dialog is Provisioned-Managed.</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="va">+When creating a provisioned deployment in Azure OpenAI Studio, the deployment type on the Create Deployment dialog is Provisioned-Managed. When creating a global provisioned managed deployment in Azure Open Studio, the deployment type on the Create Deployment dialog is Global Provisioned-Managed.</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a><span class="st">-When creating a provisioned deployment in Azure OpenAI via CLI or API, you need to set the `sku-name` to be Provisioned-Managed. The `sku-capacity` specifies the number of PTUs assigned to the deployment. </span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a><span class="va">+When creating a provisioned deployment in Azure OpenAI via CLI or API, you need to set the `sku-name` to be `ProvisionedManaged`. When creating a global provisioned deployment in Azure OpenAI via CLI or API, you need to set the `sku-name` to be `GlobalProvisionedManaged`. The `sku-capacity` specifies the number of PTUs assigned to the deployment. </span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a> ```azurecli</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a> az cognitiveservices account deployment create \</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -76,13 +76,13 @@ Unlike the Tokens Per Minute (TPM) quota used by other Azure OpenAI offerings, P</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a> :::image type=&quot;content&quot; source=&quot;../media/provisioned/model-independent-quota.png&quot; alt-text=&quot;Diagram of model independent quota with one pool of PTUs available to multiple Azure OpenAI models.&quot; lightbox=&quot;../media/provisioned/model-independent-quota.png&quot;:::</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="st">-The new quota shows up in Azure OpenAI Studio as a quota item named **Provisioned Managed Throughput Unit**. In the Studio Quota pane, expanding the quota item will show the deployments contributing to usage of the quota.</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a><span class="va">+For provisioned deployments, the new quota shows up in Azure OpenAI Studio as a quota item named **Provisioned Managed Throughput Unit**. For global provisioned managed deployments, the new quota shows up in the Azure OpenAI Studio as a quota item named **Global Provisioned Managed Throughput Unit**.  In the Studio Quota pane, expanding the quota item will show the deployments contributing to usage of each quota.</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a> :::image type=&quot;content&quot; source=&quot;../media/provisioned/ptu-quota-page.png&quot; alt-text=&quot;Screenshot of quota UI for Azure OpenAI provisioned.&quot; lightbox=&quot;../media/provisioned/ptu-quota-page.png&quot;:::</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a> #### Obtaining PTU Quota </span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a><span class="st">-PTU quota is available by default in many regions. If additional quota is required, customers can request additional quota via the Request Quota link to the right of the Provisioned Managed Throughput Unit quota item in Azure OpenAI Studio. The form allows the customer to request an increase in PTU quota for a specified region. The customer will receive an email at the included address once the request is approved, typically within two business days. </span></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a><span class="va">+PTU quota is available by default in many regions. If additional quota is required, customers can request additional quota via the Request Quota link to the right of the Provisioned Managed Throughput Unit or Global Provisioned Managed Throughput Unit quota items in Azure OpenAI Studio. The form allows the customer to request an increase in the specified PTU quota for a given region. The customer will receive an email at the included address once the request is approved, typically within two business days. </span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a> #### Per-Model PTU Minimums </span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -123,13 +123,13 @@ A few high-level considerations:</span></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a> ### How utilization performance works</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a><span class="st">-Provisioned deployments provide you with an allocated amount of model processing capacity to run a given model.</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a><span class="va">+Provisioned and global provisioned deployments provide you with an allocated amount of model processing capacity to run a given model.</span></span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a><span class="st">-In Provisioned-Managed deployments, when capacity is exceeded, the API will immediately return a 429 HTTP Status Error. This enables the user to make decisions on how to manage their traffic. Users can redirect requests to a separate deployment, to a standard pay-as-you-go instance, or leverage a retry strategy to manage a given request. The service will continue to return the 429 HTTP status code until the utilization drops below 100%.</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a><span class="va">+In Provisioned-Managed and Global Provisioned-Managed deployments, when capacity is exceeded, the API will immediately return a 429 HTTP Status Error. This enables the user to make decisions on how to manage their traffic. Users can redirect requests to a separate deployment, to a standard pay-as-you-go instance, or leverage a retry strategy to manage a given request. The service will continue to return the 429 HTTP status code until the utilization drops below 100%.</span></span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a> ### How can I monitor capacity?</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a><span class="st">-The [Provisioned-Managed Utilization V2 metric](../how-to/monitoring.md#azure-openai-metrics) in Azure Monitor measures a given deployments utilization on 1-minute increments. Provisioned-Managed deployments are optimized to ensure that accepted calls are processed with a consistent model processing time (actual end-to-end latency is dependent on a call&#39;s characteristics).  </span></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a><span class="va">+The [Provisioned-Managed Utilization V2 metric](../how-to/monitoring.md#azure-openai-metrics) in Azure Monitor measures a given deployments utilization on 1-minute increments. Provisioned-Managed and Global Provisioned-Managed deployments are optimized to ensure that accepted calls are processed with a consistent model processing time (actual end-to-end latency is dependent on a call&#39;s characteristics).  </span></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a> #### What should  I do when I receive a 429 response?</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a> The 429 response isn&#39;t an error, but instead part of the design for telling users that a given deployment is fully utilized at a point in time. By providing a fast-fail response, you have control over how to handle these situations in a way that best fits your application requirements.</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -140,9 +140,10 @@ The  `retry-after-ms` and `retry-after` headers in the response tell you the tim</span></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a> #### How does the service decide when to send a 429?</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a><span class="st">-In the Provisioned-Managed offering, each request is evaluated individually according to its prompt size, expected generation size, and model to determine its expected utilization. This is in contrast to pay-as-you-go deployments, which have a [custom rate limiting behavior](../how-to/quota.md) based on the estimated traffic load. For pay-as-you-go deployments this can lead to HTTP 429 errors being generated prior to defined quota values being exceeded if traffic is not evenly distributed.</span></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a><span class="va">+In the Provisioned-Managed and Global Provisioned-Managed offerings, each request is evaluated individually according to its prompt size, expected generation size, and model to determine its expected utilization. This is in contrast to pay-as-you-go deployments, which have a [custom rate limiting behavior](../how-to/quota.md) based on the estimated traffic load. For pay-as-you-go deployments this can lead to HTTP 429 errors being generated prior to defined quota values being exceeded if traffic is not evenly distributed.</span></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a><span class="va">+For Provisioned-Managed and Global Provisioned-Managed, we use a variation of the leaky bucket algorithm to maintain utilization below 100% while allowing some burstiness in the traffic. The high-level logic is as follows:</span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a><span class="st">-For Provisioned-Managed, we use a variation of the leaky bucket algorithm to maintain utilization below 100% while allowing some burstiness in the traffic. The high-level logic is as follows:</span></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a> 1. Each customer has a set amount of capacity they can utilize on a deployment</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a> 2. When a request is made:</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-2">Summary</h3>
<div class="sourceCode" id="cb6"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;プロビジョニングされたデプロイメントに関する情報を更新&quot;</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-2">Explanation</h3>
<p>この変更では、<code>provisioned-throughput.md</code>
ドキュメントにおけるプロビジョニングデプロイメントとグローバルプロビジョニングデプロイメントに関する情報が更新されました。主なポイントは、デプロイメントのタイプに関する説明が追加され、特に「グローバルプロビジョニングデプロイメント」が導入されています。この新しいデプロイメントタイプは、Azureのグローバルインフラストラクチャを利用して、リクエストごとに最適なデータセンターにトラフィックを動的にルーティングできることが強調されています。</p>
<p>また、ドキュメント内の多数の箇所で、プロビジョニングされたスループットユニット（PTU）の取り扱いや、API、CLIでのデプロイメント作成に関する詳細が整理され、明確に説明されています。この変更により、ユーザーが新しいデプロイメントタイプを利用する際の理解が深まり、実際の設定や利用方法についての情報が強化されました。</p>
<h2
id="item-79f39a">articles/ai-services/openai/how-to/completions.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb7"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,7 +1,7 @@</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="st">-title: &#39;How to generate text with Azure OpenAI Service&#39;</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="va">+title: &#39;How to generate text with the legacy completions API&#39;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure OpenAI</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="st">-description: Learn how to generate or manipulate text, including code by using a completion endpoint in Azure OpenAI Service.</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="va">+description: Learn how to generate or manipulate text, including code by using the legacy completion endpoint in Azure OpenAI Service.</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a> #services: cognitive-services</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -13,7 +13,7 @@ recommendations: false</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="st">-# Learn how to generate or manipulate text</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="va">+# Learn how to generate or manipulate text using the legacy completions API</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a> Azure OpenAI Service provides a **completion endpoint** that can be used for a wide variety of tasks. The endpoint supplies a simple yet powerful text-in, text-out interface to any [Azure OpenAI model](../concepts/models.md). To trigger the completion, you input some text as a prompt. The model generates the completion and attempts to match your context or pattern. Suppose you provide the prompt &quot;As Descartes said, I think, therefore&quot; to the API. For this prompt, Azure OpenAI returns the completion endpoint &quot; I am&quot; with high probability.</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-3">Summary</h3>
<div class="sourceCode" id="cb8"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;レガシーコンプリーションAPIに関するタイトルと説明の更新&quot;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-3">Explanation</h3>
<p>この変更では、<code>completions.md</code>
ドキュメントのタイトルと説明が更新され、レガシーコンプリーションAPIに特化した内容に改訂されました。具体的には、タイトルが「Azure
OpenAI
Serviceでのテキスト生成方法」から「レガシーコンプリーションAPIを使用したテキスト生成方法」に変更され、説明文も「Azure
OpenAI
Serviceのコンプリーションエンドポイントを使用して、テキストやコードを生成または操作する方法を学ぶ」から「レガシーコンプリーションエンドポイントを使用してテキストやコードを生成または操作する方法を学ぶ」に修正されています。</p>
<p>これにより、ユーザーは対象とするAPIがレガシーであることを明確に理解できるようになり、その使用に際しての期待や使い方に関する理解が深まります。変更点は、情報の正確性と明確性を向上させるための重要なステップといえます。</p>
<h2
id="item-210814">articles/ai-services/openai/how-to/deployment-types.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb9"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -13,34 +13,34 @@ ms.author: mbullwin</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a> # Azure OpenAI deployment types</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="st">-Azure OpenAI provides customers with choices on the hosting structure that fits their business and usage patterns. The service offers two main types of deployment: **standard** and **provisioned**. Standard is offered with a global deployment option, routing traffic globally to provide higher throughput. All deployments can perform the exact same inference operations, however the billing, scale and performance are substantially different. As part of your solution design, you will need to make two key decisions:</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="va">+Azure OpenAI provides customers with choices on the hosting structure that fits their business and usage patterns. The service offers two main types of deployment: **standard** and **provisioned**. Standard is offered with a global deployment option, routing traffic globally to provide higher throughput. Provisioned is also offered with a global deployment option, allowing customers to purchase and deploy provisioned throughput units across Azure global infrastructure. All deployments can perform the exact same inference operations, however the billing, scale and performance are substantially different. As part of your solution design, you will need to make two key decisions:</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a> - **Data residency needs**: global vs. regional resources  </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a> - **Call volume**: standard vs. provisioned</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a> ## Global versus regional deployment types</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="st">-For standard deployments you have an option of two types of configurations within your resource – **global** or **regional**. Global standard is the recommended starting point. </span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="va">+For standard and provisioned deployments, you have an option of two types of configurations within your resource – **global** or **regional**. Global standard is the recommended starting point. </span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="st">-Global deployments leverage Azure&#39;s global infrastructure, dynamically route customer traffic to the data center with best availability for the customer’s inference requests. This means you will get the higest initial throughput limits and best model availability with Global while still providing our uptime SLA and low latency.For high voulmne workloads above the specified usage tiers, you may experience increased latency variation. For customers that require the lower latency variance at large workload usage, we recommend purchasing provisioned throughput.</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="va">+Global deployments leverage Azure&#39;s global infrastructure, dynamically route customer traffic to the data center with best availability for the customer’s inference requests. This means you will get the highest initial throughput limits and best model availability with Global while still providing our uptime SLA and low latency. For high volume workloads above the specified usage tiers on standard and global standard, you may experience increased latency variation. For customers that require the lower latency variance at large workload usage, we recommend purchasing provisioned throughput.</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a> Our global deployments will be the first location for all new models and features. Customers with very large throughput requirements should consider our provisioned deployment offering.</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a> ## Deployment types</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a> Azure OpenAI offers three types of deployments. These provide a varied level of capabilities that provide trade-offs on: throughput, SLAs, and price. Below is a summary of the options followed by a deeper description of each.</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Offering** | **Global-Batch** | **Global-Standard** | **Standard** | **Provisioned**  |</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="st">-|---|:---|:---|:---|:---|</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Best suited for**      | Offline scoring &lt;br&gt;&lt;br&gt; Workloads that are not latency sensitive and can be completed in hours.&lt;br&gt;&lt;br&gt; For use cases that do not have data processing residency requirements.| Recommended starting place for customers. &lt;br&gt;&lt;br&gt;Global-Standard will have the higher default quota and larger number of models available than Standard. | For customers with data residency requirements. Optimized for low to medium volume. | Real-time scoring for large consistent volume. Includes the highest commitments and limits.|</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="st">-| **How it works**         | Offline processing via files |Traffic may be routed anywhere in the world | | |</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Getting started**      | [Global-Batch](./batch.md) | [Model deployment](./create-resource.md) | [Model deployment](./create-resource.md) | [Provisioned onboarding](./provisioned-throughput-onboarding.md) |</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Cost**                 | [Least expensive option](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) &lt;br&gt; 50% less cost compared to Global Standard prices. Access to all new models with larger quota allocations.  | [Global deployment pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) |  [Regional pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) | May experience cost savings for consistent usage |</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="st">-| **What you get**         |[Significant discount compared to Global Standard](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) | Easy access to all new models with highest default pay-per-call limits.&lt;br&gt;&lt;br&gt; Customers with high volume usage may see higher latency variability | Easy access with [SLA on availability](https://azure.microsoft.com/support/legal/sla/). Optimized for low to medium volume workloads with high burstiness. &lt;br&gt;&lt;br&gt;Customers with high consistent volume may experience greater latency variability. | Regional access with very high &amp; predictable throughput. Determine throughput per PTU using the provided [capacity calculator](./provisioned-throughput-onboarding.md#estimate-provisioned-throughput-and-cost) |</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="st">-| **What you don’t get**   |❌Real-time call performance &lt;br&gt;&lt;br&gt;❌Data processing guarantee&lt;br&gt; &lt;br&gt; Data stored at rest remains in the designated Azure geography, while data may be processed for inferencing in any Azure OpenAI location. [Learn more about data residency](https://azure.microsoft.com/explore/global-infrastructure/data-residency/)  |❌Data processing guarantee&lt;br&gt; &lt;br&gt; Data stored at rest remains in the designated Azure geography, while data may be processed for inferencing in any Azure OpenAI location. [Learn more about data residency](https://azure.microsoft.com/explore/global-infrastructure/data-residency/) | ❌High volume w/consistent low latency | ❌Pay-per-call flexibility |</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Per-call Latency**     | Not Applicable (file based async process) | Optimized for real-time calling &amp; low to medium volume usage. Customers with high volume usage may see higher latency variability. Threshold set per model | Optimized for real-time calling &amp; low to medium volume usage. Customers with high volume usage may see higher latency variability. Threshold set per model | Optimized for real-time. |</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Sku Name in code**     |  `GlobalBatch` |   `GlobalStandard`               | `Standard`   |      `ProvisionedManaged`       |</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Billing model**        |  Pay-per-token |Pay-per-token | Pay-per-token | Monthly Commitments |</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Offering** | **Global-Batch** | **Global-Standard**|  **Global-Provisioned**  | **Standard** | **Provisioned**  |</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="va">+|---|:---|:---| -------- |:---|:---|</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Best suited for**      | Offline scoring &lt;br&gt;&lt;br&gt; Workloads that are not latency sensitive and can be completed in hours.&lt;br&gt;&lt;br&gt; For use cases that do not have data processing residency requirements.|Recommended starting place for customers. &lt;br&gt;&lt;br&gt;Global-Standard will have the higher default quota and larger number of models available than Standard. |Real-time scoring for large consistent volume. Includes the highest commitments and limits.                                                                                               For use cases that do not have data residency requirements.| For customers with data residency requirements. Optimized for low to medium volume. |Real-time scoring for large consistent volume. Includes the highest commitments and limits.                                                                                          For use cases with data residency requirements|</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="va">+| **How it works**         | Offline processing via files |Traffic may be routed anywhere in the world |Traffic may be routed anywhere in the world| | |</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Getting started**      | [Global-Batch](./batch.md) | [Model deployment](./create-resource.md) |[Provisioned onboarding](/azure/ai-services/openai/how-to/provisioned-throughput-onboarding)| [Model deployment](./create-resource.md) | [Provisioned onboarding](./provisioned-throughput-onboarding.md) |</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Cost**                 | [Least expensive option](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) &lt;br&gt; 50% less cost compared to Global Standard prices. Access to all new models with larger quota allocations.  | [Global deployment pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) |May experience cost savings for consistent usage|  [Regional pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) |May experience cost savings for consistent usage |</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a><span class="va">+| **What you get**         |[Significant discount compared to Global Standard](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) | Easy access to all new models with highest default pay-per-call limits.&lt;br&gt;&lt;br&gt; Customers with high volume usage may see higher latency variability |Access to high &amp; predictable throughput across Azure global infrastructure. Determine throughput per PTU using the provided [capacity calculator](/azure/ai-services/openai/how-to/provisioned-throughput-onboarding). | Easy access with [SLA on availability](https://azure.microsoft.com/support/legal/sla/). Optimized for low to medium volume workloads with high burstiness. &lt;br&gt;&lt;br&gt;Customers with high consistent volume may experience greater latency variability. | Regional access with very high &amp; predictable throughput. Determine throughput per PTU using the provided [capacity calculator](./provisioned-throughput-onboarding.md#estimate-provisioned-throughput-and-cost) |</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="va">+| **What you don’t get**   |❌Real-time call performance &lt;br&gt;&lt;br&gt;❌Data processing guarantee&lt;br&gt; &lt;br&gt; Data stored at rest remains in the designated Azure geography, while data may be processed for inferencing in any Azure OpenAI location. [Learn more about data residency](https://azure.microsoft.com/explore/global-infrastructure/data-residency/)  |❌Data processing guarantee&lt;br&gt; &lt;br&gt; Data stored at rest remains in the designated Azure geography, while data may be processed for inferencing in any Azure OpenAI location. [Learn more about data residency](https://azure.microsoft.com/explore/global-infrastructure/data-residency/) |❌Pay-per-call flexibility &lt;br&gt; &lt;br&gt;❌Data processing guarantee&lt;br&gt; &lt;br&gt; Data stored at rest remains in the designated Azure geography, while data may be processed for inferencing in any Azure OpenAI location. [Learn more about data residency](https://azure.microsoft.com/explore/global-infrastructure/data-residency/)| ❌High volume w/consistent low latency | ❌Pay-per-call flexibility |</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Per-call Latency**     | Not Applicable (file based async process) | Optimized for real-time calling &amp; low to medium volume usage. Customers with high volume usage may see higher latency variability. Threshold set per model |Optimized for real-time calling &amp; high-volume usage. | Optimized for real-time calling &amp; low to medium volume usage. Customers with high volume usage may see higher latency variability. Threshold set per model |Optimized for real-time calling &amp; high-volume usage.|</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Sku Name in code**     |  `GlobalBatch` |   `GlobalStandard`               |`GlobalProvisionedManaged`| `Standard`   |      `ProvisionedManaged`       |</span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Billing model**        |  Pay-per-token |Pay-per-token |Hourly billing with optional purchase of monthly or yearly reservations| Pay-per-token |Hourly billing with optional purchase of monthly or yearly reservations|</span></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a> ## Provisioned</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -61,6 +61,13 @@ Global deployments are available in the same Azure OpenAI resources as non-globa</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a> Customers with high consistent volume may experience greater latency variability. The threshold is set per model. See the [quotas page to learn more](./quota.md).  For applications that require the lower latency variance at large workload usage, we recommend purchasing provisioned throughput.</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="va">+## Global provisioned</span></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!IMPORTANT]</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; Data stored at rest remains in the designated Azure geography, while data may be processed for inferencing in any Azure OpenAI location. [Learn more about data residency](https://azure.microsoft.com/explore/global-infrastructure/data-residency/).</span></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="va">+Global deployments are available in the same Azure OpenAI resources as non-global deployment types but allow you to leverage Azure&#39;s global infrastructure to dynamically route traffic to the data center with best availability for each request. Global provisioned deployments provide reserved model processing capacity for high and predictable throughput using Azure global infrastructure.  </span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a> ## Global batch</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a> &gt; [!IMPORTANT]</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -88,7 +95,7 @@ Key use cases include:</span></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a> Azure Policy helps to enforce organizational standards and to assess compliance at-scale. Through its compliance dashboard, it provides an aggregated view to evaluate the overall state of the environment, with the ability to drill down to the per-resource, per-policy granularity. It also helps to bring your resources to compliance through bulk remediation for existing resources and automatic remediation for new resources. [Learn more about Azure Policy and specific built-in controls for AI services](/azure/ai-services/security-controls-policy).</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a><span class="st">-You can use the following policy to disable access to Azure OpenAI global standard deployments.</span></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a><span class="va">+You can use the following policy to disable access to Azure OpenAI global standard deployments. To disable access to Azure global provisioned or global batch deployments, replace `GlobalStandard` with `GlobalProvisionedManaged` or `GlobalBatch` for the intended sku name. </span></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a> ```json</span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a> {</span></code></pre></div>
</details>
<h3 id="summary-4">Summary</h3>
<div class="sourceCode" id="cb10"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;デプロイメントタイプに関する情報の更新&quot;</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-4">Explanation</h3>
<p>この変更では、<code>deployment-types.md</code>
ドキュメントにおけるAzure
OpenAIのデプロイメントタイプに関する情報が更新されました。主な内容として、「プロビジョニングされたデプロイメント」が「グローバルプロビジョニング」という新しいカテゴリとして明確に区別され、特にその利点が強調されています。これにより、ユーザーはプロビジョニングされたスループットユニットの購入と使用が可能であることが明確になります。</p>
<p>具体的には、標準デプロイメントとプロビジョニングデプロイメントの両方の設定オプションが「グローバル」または「リージョナル」として選択できることが説明され、グローバルデプロイメントがAzureのグローバルインフラストラクチャを利用してトラフィックを動的にルーティングする方法についても詳述されました。また、異なるデプロイメントタイプに関する詳細な比較表が整理され、各デプロイメントの特性とコストに関する情報が更新されています。</p>
<p>この変更により、ユーザーは自身のビジネスニーズに最適なデプロイメントタイプを選択するための情報が充実し、また新しいオプションやその使用方法についても理解が深まります。</p>
<h2
id="item-4d8502">articles/ai-services/openai/how-to/gpt-with-vision.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb11"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -15,7 +15,7 @@ manager: nitinme</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a> GPT-4 Turbo with Vision is a large multimodal model (LMM) developed by OpenAI that can analyze images and provide textual responses to questions about them. It incorporates both natural language processing and visual understanding.</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="st">-The GPT-4 Turbo with Vision model answers general questions about what&#39;s present in images. You can also show it video if you use [Vision enhancement](#use-vision-enhancement-with-video).</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="va">+The GPT-4 Turbo with Vision model answers general questions about what&#39;s present in images.</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a> &gt; [!TIP]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a> &gt; To use GPT-4 Turbo with Vision, you call the Chat Completion API on a GPT-4 Turbo with Vision model that you have deployed. If you&#39;re not familiar with the Chat Completion API, see the [GPT-4 Turbo &amp; GPT-4 how-to guide](/azure/ai-services/openai/how-to/chatgpt?tabs=python&amp;pivots=programming-language-chat-completions).</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -249,143 +249,7 @@ The _detail_ parameter in the model offers three choices: `low`, `high`, or `aut</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a> For details on how the image parameters impact tokens used and pricing please see - [What is OpenAI? Image Tokens with GPT-4 Turbo with Vision](../overview.md#image-tokens-gpt-4-turbo-with-vision-and-gpt-4o)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="st">-## Use Vision enhancement with images</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="st">-GPT-4 Turbo with Vision provides exclusive access to Azure AI Services tailored enhancements. When combined with Azure AI Vision, it enhances your chat experience by providing the chat model with more detailed information about visible text in the image and the locations of objects.</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="st">-The **Optical character recognition (OCR)** integration allows the model to produce higher quality responses for dense text, transformed images, and number-heavy financial documents. It also covers a wider range of languages.</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="st">-The **object grounding** integration brings a new layer to data analysis and user interaction, as the feature can visually distinguish and highlight important elements in the images it processes.</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; To use the Vision enhancement with an Azure OpenAI resource, you need to specify a Computer Vision resource. It must be in the paid (S1) tier and in the same Azure region as your GPT-4 Turbo with Vision resource. If you&#39;re using an Azure AI Services resource, you don&#39;t need an additional Computer Vision resource.</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Vision enhancements are not supported by the GPT-4 Turbo GA model. They are only available with the preview models.</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!CAUTION]</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Azure AI enhancements for GPT-4 Turbo with Vision will be billed separately from the core functionalities. Each specific Azure AI enhancement for GPT-4 Turbo with Vision has its own distinct charges. For details, see the [special pricing information](../concepts/gpt-with-vision.md#special-pricing-information).</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [REST](#tab/rest)</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="st">-Send a POST request to `https://{RESOURCE_NAME}.openai.azure.com/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version=2024-02-15-preview` where </span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a><span class="st">-- RESOURCE_NAME is the name of your Azure OpenAI resource </span></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="st">-- DEPLOYMENT_NAME is the name of your GPT-4 Turbo with Vision model deployment </span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a><span class="st">-**Required headers**: </span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a><span class="st">-- `Content-Type`: application/json </span></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a><span class="st">-- `api-key`: {API_KEY} </span></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a><span class="st">-**Body**: </span></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a><span class="st">-The format is similar to that of the chat completions API for GPT-4, but the message content can be an array containing strings and images (either a valid HTTP or HTTPS URL to an image, or a base-64-encoded image).</span></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a><span class="st">-You must also include the `enhancements` and `dataSources` objects. `enhancements` represents the specific Vision enhancement features requested in the chat. It has a `grounding` and `ocr` property, which both have a boolean `enabled` property. Use these to request the OCR service and/or the object detection/grounding service. `dataSources` represents the Computer Vision resource data that&#39;s needed for Vision enhancement. It has a `type` property which should be `&quot;AzureComputerVision&quot;` and a `parameters` property. Set the `endpoint` and `key` to the endpoint URL and access key of your Computer Vision resource. </span></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Remember to set a `&quot;max_tokens&quot;` value, or the return output will be cut off.</span></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a><span class="st">-```json</span></span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a><span class="st">-{</span></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;enhancements&quot;: {</span></span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;ocr&quot;: {</span></span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a><span class="st">-              &quot;enabled&quot;: true</span></span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a><span class="st">-            },</span></span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;grounding&quot;: {</span></span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a><span class="st">-              &quot;enabled&quot;: true</span></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a><span class="st">-    },</span></span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;dataSources&quot;: [</span></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a><span class="st">-    {</span></span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;type&quot;: &quot;AzureComputerVision&quot;,</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;parameters&quot;: {</span></span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;endpoint&quot;: &quot;&lt;your_computer_vision_endpoint&gt;&quot;,</span></span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;key&quot;: &quot;&lt;your_computer_vision_key&gt;&quot;</span></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a><span class="st">-        }</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a><span class="st">-    }],</span></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;messages&quot;: [</span></span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a><span class="st">-        {</span></span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;role&quot;: &quot;system&quot;,</span></span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;content&quot;: &quot;You are a helpful assistant.&quot;</span></span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a><span class="st">-        },</span></span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a><span class="st">-        {</span></span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;role&quot;: &quot;user&quot;,</span></span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;content&quot;: [</span></span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a><span class="st">-               {</span></span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a><span class="st">-                   &quot;type&quot;: &quot;text&quot;,</span></span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a><span class="st">-                   &quot;text&quot;: &quot;Describe this picture:&quot;</span></span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a><span class="st">-               },</span></span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a><span class="st">-               {</span></span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a><span class="st">-                   &quot;type&quot;: &quot;image_url&quot;,</span></span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a><span class="st">-                   &quot;image_url&quot;: {</span></span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a><span class="st">-                        &quot;url&quot;:&quot;&lt;image URL&gt;&quot; </span></span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a><span class="st">-                    }</span></span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb11-88"><a href="#cb11-88" aria-hidden="true" tabindex="-1"></a><span class="st">-           ] </span></span>
<span id="cb11-89"><a href="#cb11-89" aria-hidden="true" tabindex="-1"></a><span class="st">-        }</span></span>
<span id="cb11-90"><a href="#cb11-90" aria-hidden="true" tabindex="-1"></a><span class="st">-    ],</span></span>
<span id="cb11-91"><a href="#cb11-91" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;max_tokens&quot;: 100, </span></span>
<span id="cb11-92"><a href="#cb11-92" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;stream&quot;: false </span></span>
<span id="cb11-93"><a href="#cb11-93" aria-hidden="true" tabindex="-1"></a><span class="st">-} </span></span>
<span id="cb11-94"><a href="#cb11-94" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb11-95"><a href="#cb11-95" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-96"><a href="#cb11-96" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Python](#tab/python)</span></span>
<span id="cb11-97"><a href="#cb11-97" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-98"><a href="#cb11-98" aria-hidden="true" tabindex="-1"></a><span class="st">-You call the same method as in the previous step, but include the new *extra_body* parameter. It contains the `enhancements` and `dataSources` fields. </span></span>
<span id="cb11-99"><a href="#cb11-99" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-100"><a href="#cb11-100" aria-hidden="true" tabindex="-1"></a><span class="st">-`enhancements` represents the specific Vision enhancement features requested in the chat. It has a `grounding` and `ocr` field, which both have a boolean `enabled` property. Use these to request the OCR service and/or the object detection/grounding service. </span></span>
<span id="cb11-101"><a href="#cb11-101" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-102"><a href="#cb11-102" aria-hidden="true" tabindex="-1"></a><span class="st">-`dataSources` represents the Computer Vision resource data that&#39;s needed for Vision enhancement. It has a `type` field which should be `&quot;AzureComputerVision&quot;` and a `parameters` field. Set the `endpoint` and `key` to the endpoint URL and access key of your Computer Vision resource. R</span></span>
<span id="cb11-103"><a href="#cb11-103" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-104"><a href="#cb11-104" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb11-105"><a href="#cb11-105" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Remember to set a `&quot;max_tokens&quot;` value, or the return output will be cut off.</span></span>
<span id="cb11-106"><a href="#cb11-106" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-107"><a href="#cb11-107" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-108"><a href="#cb11-108" aria-hidden="true" tabindex="-1"></a><span class="st">-```python</span></span>
<span id="cb11-109"><a href="#cb11-109" aria-hidden="true" tabindex="-1"></a><span class="st">-response = client.chat.completions.create(</span></span>
<span id="cb11-110"><a href="#cb11-110" aria-hidden="true" tabindex="-1"></a><span class="st">-    model=deployment_name,</span></span>
<span id="cb11-111"><a href="#cb11-111" aria-hidden="true" tabindex="-1"></a><span class="st">-    messages=[</span></span>
<span id="cb11-112"><a href="#cb11-112" aria-hidden="true" tabindex="-1"></a><span class="st">-        { &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot; },</span></span>
<span id="cb11-113"><a href="#cb11-113" aria-hidden="true" tabindex="-1"></a><span class="st">-        { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [  </span></span>
<span id="cb11-114"><a href="#cb11-114" aria-hidden="true" tabindex="-1"></a><span class="st">-            { </span></span>
<span id="cb11-115"><a href="#cb11-115" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;type&quot;: &quot;text&quot;, </span></span>
<span id="cb11-116"><a href="#cb11-116" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;text&quot;: &quot;Describe this picture:&quot; </span></span>
<span id="cb11-117"><a href="#cb11-117" aria-hidden="true" tabindex="-1"></a><span class="st">-            },</span></span>
<span id="cb11-118"><a href="#cb11-118" aria-hidden="true" tabindex="-1"></a><span class="st">-            { </span></span>
<span id="cb11-119"><a href="#cb11-119" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;type&quot;: &quot;image_url&quot;,</span></span>
<span id="cb11-120"><a href="#cb11-120" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;image_url&quot;: {</span></span>
<span id="cb11-121"><a href="#cb11-121" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;url&quot;: &quot;&lt;image URL&gt;&quot;</span></span>
<span id="cb11-122"><a href="#cb11-122" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb11-123"><a href="#cb11-123" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb11-124"><a href="#cb11-124" aria-hidden="true" tabindex="-1"></a><span class="st">-        ] } </span></span>
<span id="cb11-125"><a href="#cb11-125" aria-hidden="true" tabindex="-1"></a><span class="st">-    ],</span></span>
<span id="cb11-126"><a href="#cb11-126" aria-hidden="true" tabindex="-1"></a><span class="st">-    extra_body={</span></span>
<span id="cb11-127"><a href="#cb11-127" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;dataSources&quot;: [</span></span>
<span id="cb11-128"><a href="#cb11-128" aria-hidden="true" tabindex="-1"></a><span class="st">-            {</span></span>
<span id="cb11-129"><a href="#cb11-129" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;type&quot;: &quot;AzureComputerVision&quot;,</span></span>
<span id="cb11-130"><a href="#cb11-130" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;parameters&quot;: {</span></span>
<span id="cb11-131"><a href="#cb11-131" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;endpoint&quot;: &quot;&lt;your_computer_vision_endpoint&gt;&quot;,</span></span>
<span id="cb11-132"><a href="#cb11-132" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;key&quot;: &quot;&lt;your_computer_vision_key&gt;&quot;</span></span>
<span id="cb11-133"><a href="#cb11-133" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb11-134"><a href="#cb11-134" aria-hidden="true" tabindex="-1"></a><span class="st">-            }],</span></span>
<span id="cb11-135"><a href="#cb11-135" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;enhancements&quot;: {</span></span>
<span id="cb11-136"><a href="#cb11-136" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;ocr&quot;: {</span></span>
<span id="cb11-137"><a href="#cb11-137" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;enabled&quot;: True</span></span>
<span id="cb11-138"><a href="#cb11-138" aria-hidden="true" tabindex="-1"></a><span class="st">-            },</span></span>
<span id="cb11-139"><a href="#cb11-139" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;grounding&quot;: {</span></span>
<span id="cb11-140"><a href="#cb11-140" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;enabled&quot;: True</span></span>
<span id="cb11-141"><a href="#cb11-141" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb11-142"><a href="#cb11-142" aria-hidden="true" tabindex="-1"></a><span class="st">-        }</span></span>
<span id="cb11-143"><a href="#cb11-143" aria-hidden="true" tabindex="-1"></a><span class="st">-    },</span></span>
<span id="cb11-144"><a href="#cb11-144" aria-hidden="true" tabindex="-1"></a><span class="st">-    max_tokens=2000</span></span>
<span id="cb11-145"><a href="#cb11-145" aria-hidden="true" tabindex="-1"></a><span class="st">-)</span></span>
<span id="cb11-146"><a href="#cb11-146" aria-hidden="true" tabindex="-1"></a><span class="st">-print(response)</span></span>
<span id="cb11-147"><a href="#cb11-147" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb11-148"><a href="#cb11-148" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-149"><a href="#cb11-149" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-150"><a href="#cb11-150" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb11-151"><a href="#cb11-151" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-152"><a href="#cb11-152" aria-hidden="true" tabindex="-1"></a> ### Output</span>
<span id="cb11-153"><a href="#cb11-153" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-154"><a href="#cb11-154" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -409,28 +273,6 @@ The chat responses you receive from the model should now include enhanced inform</span></span>
<span id="cb11-155"><a href="#cb11-155" aria-hidden="true" tabindex="-1"></a>             {</span>
<span id="cb11-156"><a href="#cb11-156" aria-hidden="true" tabindex="-1"></a>                 &quot;role&quot;: &quot;assistant&quot;,</span>
<span id="cb11-157"><a href="#cb11-157" aria-hidden="true" tabindex="-1"></a>                 &quot;content&quot;: &quot;The image shows a close-up of an individual with dark hair and what appears to be a short haircut. The person has visible ears and a bit of their neckline. The background is a neutral light color, providing a contrast to the dark hair.&quot;</span>
<span id="cb11-158"><a href="#cb11-158" aria-hidden="true" tabindex="-1"></a><span class="st">-            },</span></span>
<span id="cb11-159"><a href="#cb11-159" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;enhancements&quot;:</span></span>
<span id="cb11-160"><a href="#cb11-160" aria-hidden="true" tabindex="-1"></a><span class="st">-            {</span></span>
<span id="cb11-161"><a href="#cb11-161" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;grounding&quot;:</span></span>
<span id="cb11-162"><a href="#cb11-162" aria-hidden="true" tabindex="-1"></a><span class="st">-                {</span></span>
<span id="cb11-163"><a href="#cb11-163" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;lines&quot;:</span></span>
<span id="cb11-164"><a href="#cb11-164" aria-hidden="true" tabindex="-1"></a><span class="st">-                    [</span></span>
<span id="cb11-165"><a href="#cb11-165" aria-hidden="true" tabindex="-1"></a><span class="st">-                        {</span></span>
<span id="cb11-166"><a href="#cb11-166" aria-hidden="true" tabindex="-1"></a><span class="st">-                            &quot;text&quot;: &quot;The image shows a close-up of an individual with dark hair and what appears to be a short haircut. The person has visible ears and a bit of their neckline. The background is a neutral light color, providing a contrast to the dark hair.&quot;,</span></span>
<span id="cb11-167"><a href="#cb11-167" aria-hidden="true" tabindex="-1"></a><span class="st">-                            &quot;spans&quot;:</span></span>
<span id="cb11-168"><a href="#cb11-168" aria-hidden="true" tabindex="-1"></a><span class="st">-                            [</span></span>
<span id="cb11-169"><a href="#cb11-169" aria-hidden="true" tabindex="-1"></a><span class="st">-                                {</span></span>
<span id="cb11-170"><a href="#cb11-170" aria-hidden="true" tabindex="-1"></a><span class="st">-                                    &quot;text&quot;: &quot;the person&quot;,</span></span>
<span id="cb11-171"><a href="#cb11-171" aria-hidden="true" tabindex="-1"></a><span class="st">-                                    &quot;length&quot;: 10,</span></span>
<span id="cb11-172"><a href="#cb11-172" aria-hidden="true" tabindex="-1"></a><span class="st">-                                    &quot;offset&quot;: 99,</span></span>
<span id="cb11-173"><a href="#cb11-173" aria-hidden="true" tabindex="-1"></a><span class="st">-                                    &quot;polygon&quot;: [{&quot;x&quot;:0.11950000375509262,&quot;y&quot;:0.4124999940395355},{&quot;x&quot;:0.8034999370574951,&quot;y&quot;:0.4124999940395355},{&quot;x&quot;:0.8034999370574951,&quot;y&quot;:0.6434999704360962},{&quot;x&quot;:0.11950000375509262,&quot;y&quot;:0.6434999704360962}]</span></span>
<span id="cb11-174"><a href="#cb11-174" aria-hidden="true" tabindex="-1"></a><span class="st">-                                }</span></span>
<span id="cb11-175"><a href="#cb11-175" aria-hidden="true" tabindex="-1"></a><span class="st">-                            ]</span></span>
<span id="cb11-176"><a href="#cb11-176" aria-hidden="true" tabindex="-1"></a><span class="st">-                        }</span></span>
<span id="cb11-177"><a href="#cb11-177" aria-hidden="true" tabindex="-1"></a><span class="st">-                    ],</span></span>
<span id="cb11-178"><a href="#cb11-178" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;status&quot;: &quot;Success&quot;</span></span>
<span id="cb11-179"><a href="#cb11-179" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb11-180"><a href="#cb11-180" aria-hidden="true" tabindex="-1"></a>             }</span>
<span id="cb11-181"><a href="#cb11-181" aria-hidden="true" tabindex="-1"></a>         }</span>
<span id="cb11-182"><a href="#cb11-182" aria-hidden="true" tabindex="-1"></a>     ],</span>
<span id="cb11-183"><a href="#cb11-183" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -448,61 +290,7 @@ Every response includes a `&quot;finish_reason&quot;` field. It has the following possible</span></span>
<span id="cb11-184"><a href="#cb11-184" aria-hidden="true" tabindex="-1"></a> - `length`: Incomplete model output due to the `max_tokens` input parameter or model&#39;s token limit.</span>
<span id="cb11-185"><a href="#cb11-185" aria-hidden="true" tabindex="-1"></a> - `content_filter`: Omitted content due to a flag from our content filters.</span>
<span id="cb11-186"><a href="#cb11-186" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-187"><a href="#cb11-187" aria-hidden="true" tabindex="-1"></a><span class="st">-## Use Vision enhancement with video</span></span>
<span id="cb11-188"><a href="#cb11-188" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-189"><a href="#cb11-189" aria-hidden="true" tabindex="-1"></a><span class="st">-GPT-4 Turbo with Vision provides exclusive access to Azure AI Services tailored enhancements. The **video prompt** integration uses Azure AI Vision video retrieval to sample a set of frames from a video and create a transcript of the speech in the video. It enables the AI model to give summaries and answers about video content.</span></span>
<span id="cb11-190"><a href="#cb11-190" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-191"><a href="#cb11-191" aria-hidden="true" tabindex="-1"></a><span class="st">-Follow these steps to set up a video retrieval system and integrate it with your AI chat model.</span></span>
<span id="cb11-192"><a href="#cb11-192" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-193"><a href="#cb11-193" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb11-194"><a href="#cb11-194" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; To use the Vision enhancement with an Azure OpenAI resource, you need to specify a Computer Vision resource. It must be in the paid (S1) tier and in the same Azure region as your GPT-4 Turbo with Vision resource. If you&#39;re using an Azure AI Services resource, you don&#39;t need an additional Computer Vision resource.</span></span>
<span id="cb11-195"><a href="#cb11-195" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-196"><a href="#cb11-196" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb11-197"><a href="#cb11-197" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Vision enhancements are not supported by the GPT-4 Turbo GA model. They are only available with the preview models.</span></span>
<span id="cb11-198"><a href="#cb11-198" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-199"><a href="#cb11-199" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!CAUTION]</span></span>
<span id="cb11-200"><a href="#cb11-200" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Azure AI enhancements for GPT-4 Turbo with Vision will be billed separately from the core functionalities. Each specific Azure AI enhancement for GPT-4 Turbo with Vision has its own distinct charges. For details, see the [special pricing information](../concepts/gpt-with-vision.md#special-pricing-information).</span></span>
<span id="cb11-201"><a href="#cb11-201" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-202"><a href="#cb11-202" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!TIP]</span></span>
<span id="cb11-203"><a href="#cb11-203" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; If you prefer, you can carry out the below steps using a Jupyter notebook instead: [Video chat completions notebook](https://github.com/Azure-Samples/azureai-samples/blob/main/scenarios/GPT-4V/video/video_chatcompletions_example_restapi.ipynb). </span></span>
<span id="cb11-204"><a href="#cb11-204" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-205"><a href="#cb11-205" aria-hidden="true" tabindex="-1"></a><span class="st">-### Upload videos to Azure Blob Storage</span></span>
<span id="cb11-206"><a href="#cb11-206" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-207"><a href="#cb11-207" aria-hidden="true" tabindex="-1"></a><span class="st">-You need to upload your videos to an Azure Blob Storage container. [Create a new storage account](https://ms.portal.azure.com/#create/Microsoft.StorageAccount) if you don&#39;t have one already.</span></span>
<span id="cb11-208"><a href="#cb11-208" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-209"><a href="#cb11-209" aria-hidden="true" tabindex="-1"></a><span class="st">-Once your videos are uploaded, you can get their SAS URLs, which you use to access them in later steps.</span></span>
<span id="cb11-210"><a href="#cb11-210" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-211"><a href="#cb11-211" aria-hidden="true" tabindex="-1"></a><span class="st">-#### Ensure proper read access</span></span>
<span id="cb11-212"><a href="#cb11-212" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-213"><a href="#cb11-213" aria-hidden="true" tabindex="-1"></a><span class="st">-Depending on your authentication method, you may need to do some extra steps to grant access to the Azure Blob Storage container. If you&#39;re using an Azure AI Services resource instead of an Azure OpenAI resource, you need to use Managed Identities to grant it **read** access to Azure Blob Storage:</span></span>
<span id="cb11-214"><a href="#cb11-214" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-215"><a href="#cb11-215" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [using System assigned identities](#tab/system-assigned)</span></span>
<span id="cb11-216"><a href="#cb11-216" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-217"><a href="#cb11-217" aria-hidden="true" tabindex="-1"></a><span class="st">-Enable System assigned identities on your Azure AI Services resource by following these steps:</span></span>
<span id="cb11-218"><a href="#cb11-218" aria-hidden="true" tabindex="-1"></a><span class="st">-1. From your AI Services resource in Azure portal select **Resource Management** -&gt; **Identity** and toggle the status to **ON**.</span></span>
<span id="cb11-219"><a href="#cb11-219" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Assign **Storage Blob Data Read** access to the AI Services resource: From the **Identity** page, select **Azure role assignments**, and then **Add role assignment** with the following settings:</span></span>
<span id="cb11-220"><a href="#cb11-220" aria-hidden="true" tabindex="-1"></a><span class="st">-    - scope: storage</span></span>
<span id="cb11-221"><a href="#cb11-221" aria-hidden="true" tabindex="-1"></a><span class="st">-    - subscription: {your subscription}</span></span>
<span id="cb11-222"><a href="#cb11-222" aria-hidden="true" tabindex="-1"></a><span class="st">-    - Resource: {select the Azure Blob Storage resource}</span></span>
<span id="cb11-223"><a href="#cb11-223" aria-hidden="true" tabindex="-1"></a><span class="st">-    - Role: Storage Blob Data Reader</span></span>
<span id="cb11-224"><a href="#cb11-224" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Save your settings.</span></span>
<span id="cb11-225"><a href="#cb11-225" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-226"><a href="#cb11-226" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [using User assigned identities](#tab/user-assigned)</span></span>
<span id="cb11-227"><a href="#cb11-227" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-228"><a href="#cb11-228" aria-hidden="true" tabindex="-1"></a><span class="st">-To use a User assigned identity on your Azure AI Services resource, follow these steps:</span></span>
<span id="cb11-229"><a href="#cb11-229" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Create a new Managed Identity resource in the Azure portal.</span></span>
<span id="cb11-230"><a href="#cb11-230" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Navigate to the new resource, then to **Azure Role Assignments**.</span></span>
<span id="cb11-231"><a href="#cb11-231" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Add a **New Role Assignment** with the following settings:</span></span>
<span id="cb11-232"><a href="#cb11-232" aria-hidden="true" tabindex="-1"></a><span class="st">-    - scope: storage</span></span>
<span id="cb11-233"><a href="#cb11-233" aria-hidden="true" tabindex="-1"></a><span class="st">-    - subscription: {your subscription}</span></span>
<span id="cb11-234"><a href="#cb11-234" aria-hidden="true" tabindex="-1"></a><span class="st">-    - Resource: {select the Azure Blob Storage resource}</span></span>
<span id="cb11-235"><a href="#cb11-235" aria-hidden="true" tabindex="-1"></a><span class="st">-    - Role: Storage Blob Data Reader</span></span>
<span id="cb11-236"><a href="#cb11-236" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Save your new configuration.</span></span>
<span id="cb11-237"><a href="#cb11-237" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Navigate to your AI Services resource&#39;s **Identity** page.</span></span>
<span id="cb11-238"><a href="#cb11-238" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Select the **User Assigned** Tab, then click **+Add** to select the newly created Managed Identity.</span></span>
<span id="cb11-239"><a href="#cb11-239" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Save your configuration.</span></span>
<span id="cb11-240"><a href="#cb11-240" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-241"><a href="#cb11-241" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb11-242"><a href="#cb11-242" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-243"><a href="#cb11-243" aria-hidden="true" tabindex="-1"></a> ### Create a video retrieval index</span>
<span id="cb11-244"><a href="#cb11-244" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-245"><a href="#cb11-245" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -579,207 +367,6 @@ To use a User assigned identity on your Azure AI Services resource, follow these</span></span>
<span id="cb11-246"><a href="#cb11-246" aria-hidden="true" tabindex="-1"></a>     curl.exe -v -X GET &quot;https://&lt;YOUR_ENDPOINT_URL&gt;/computervision/retrieval/indexes/my-video-index/ingestions?api-version=2023-05-01-preview&amp;$top=20&quot; -H &quot;ocp-apim-subscription-key: &lt;YOUR_SUBSCRIPTION_KEY&gt;&quot;</span>
<span id="cb11-247"><a href="#cb11-247" aria-hidden="true" tabindex="-1"></a>     ```</span>
<span id="cb11-248"><a href="#cb11-248" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-249"><a href="#cb11-249" aria-hidden="true" tabindex="-1"></a><span class="st">-### Integrate your video index with GPT-4 Turbo with Vision</span></span>
<span id="cb11-250"><a href="#cb11-250" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-251"><a href="#cb11-251" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [REST](#tab/rest)</span></span>
<span id="cb11-252"><a href="#cb11-252" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-253"><a href="#cb11-253" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Prepare a POST request to `https://{RESOURCE_NAME}.openai.azure.com/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version=2024-02-15-preview` where </span></span>
<span id="cb11-254"><a href="#cb11-254" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-255"><a href="#cb11-255" aria-hidden="true" tabindex="-1"></a><span class="st">-    - RESOURCE_NAME is the name of your Azure OpenAI resource </span></span>
<span id="cb11-256"><a href="#cb11-256" aria-hidden="true" tabindex="-1"></a><span class="st">-    - DEPLOYMENT_NAME is the name of your GPT-4 Vision model deployment </span></span>
<span id="cb11-257"><a href="#cb11-257" aria-hidden="true" tabindex="-1"></a><span class="st">-        </span></span>
<span id="cb11-258"><a href="#cb11-258" aria-hidden="true" tabindex="-1"></a><span class="st">-    **Required headers**: </span></span>
<span id="cb11-259"><a href="#cb11-259" aria-hidden="true" tabindex="-1"></a><span class="st">-    - `Content-Type`: application/json </span></span>
<span id="cb11-260"><a href="#cb11-260" aria-hidden="true" tabindex="-1"></a><span class="st">-    - `api-key`: {API_KEY} </span></span>
<span id="cb11-261"><a href="#cb11-261" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Add the following JSON structure in the request body:</span></span>
<span id="cb11-262"><a href="#cb11-262" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```json</span></span>
<span id="cb11-263"><a href="#cb11-263" aria-hidden="true" tabindex="-1"></a><span class="st">-    {</span></span>
<span id="cb11-264"><a href="#cb11-264" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;enhancements&quot;: {</span></span>
<span id="cb11-265"><a href="#cb11-265" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;video&quot;: {</span></span>
<span id="cb11-266"><a href="#cb11-266" aria-hidden="true" tabindex="-1"></a><span class="st">-                  &quot;enabled&quot;: true</span></span>
<span id="cb11-267"><a href="#cb11-267" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb11-268"><a href="#cb11-268" aria-hidden="true" tabindex="-1"></a><span class="st">-        },</span></span>
<span id="cb11-269"><a href="#cb11-269" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;dataSources&quot;: [</span></span>
<span id="cb11-270"><a href="#cb11-270" aria-hidden="true" tabindex="-1"></a><span class="st">-        {</span></span>
<span id="cb11-271"><a href="#cb11-271" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;type&quot;: &quot;AzureComputerVisionVideoIndex&quot;,</span></span>
<span id="cb11-272"><a href="#cb11-272" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;parameters&quot;: {</span></span>
<span id="cb11-273"><a href="#cb11-273" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;computerVisionBaseUrl&quot;: &quot;&lt;your_computer_vision_endpoint&gt;&quot;,</span></span>
<span id="cb11-274"><a href="#cb11-274" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;computerVisionApiKey&quot;: &quot;&lt;your_computer_vision_key&gt;&quot;,</span></span>
<span id="cb11-275"><a href="#cb11-275" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;indexName&quot;: &quot;&lt;name_of_your_index&gt;&quot;,</span></span>
<span id="cb11-276"><a href="#cb11-276" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;videoUrls&quot;: [&quot;&lt;your_video_SAS_URL&gt;&quot;]</span></span>
<span id="cb11-277"><a href="#cb11-277" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb11-278"><a href="#cb11-278" aria-hidden="true" tabindex="-1"></a><span class="st">-        }],</span></span>
<span id="cb11-279"><a href="#cb11-279" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;messages&quot;: [ </span></span>
<span id="cb11-280"><a href="#cb11-280" aria-hidden="true" tabindex="-1"></a><span class="st">-            {</span></span>
<span id="cb11-281"><a href="#cb11-281" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;role&quot;: &quot;system&quot;, </span></span>
<span id="cb11-282"><a href="#cb11-282" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;content&quot;: &quot;You are a helpful assistant.&quot; </span></span>
<span id="cb11-283"><a href="#cb11-283" aria-hidden="true" tabindex="-1"></a><span class="st">-            },</span></span>
<span id="cb11-284"><a href="#cb11-284" aria-hidden="true" tabindex="-1"></a><span class="st">-            {</span></span>
<span id="cb11-285"><a href="#cb11-285" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;role&quot;: &quot;user&quot;,</span></span>
<span id="cb11-286"><a href="#cb11-286" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;content&quot;: [</span></span>
<span id="cb11-287"><a href="#cb11-287" aria-hidden="true" tabindex="-1"></a><span class="st">-                        {</span></span>
<span id="cb11-288"><a href="#cb11-288" aria-hidden="true" tabindex="-1"></a><span class="st">-                            &quot;type&quot;: &quot;acv_document_id&quot;,</span></span>
<span id="cb11-289"><a href="#cb11-289" aria-hidden="true" tabindex="-1"></a><span class="st">-                            &quot;acv_document_id&quot;: &quot;&lt;your_video_ID&gt;&quot;</span></span>
<span id="cb11-290"><a href="#cb11-290" aria-hidden="true" tabindex="-1"></a><span class="st">-                        },</span></span>
<span id="cb11-291"><a href="#cb11-291" aria-hidden="true" tabindex="-1"></a><span class="st">-                        {</span></span>
<span id="cb11-292"><a href="#cb11-292" aria-hidden="true" tabindex="-1"></a><span class="st">-                            &quot;type&quot;: &quot;text&quot;,</span></span>
<span id="cb11-293"><a href="#cb11-293" aria-hidden="true" tabindex="-1"></a><span class="st">-                            &quot;text&quot;: &quot;Describe this video:&quot;</span></span>
<span id="cb11-294"><a href="#cb11-294" aria-hidden="true" tabindex="-1"></a><span class="st">-                        }</span></span>
<span id="cb11-295"><a href="#cb11-295" aria-hidden="true" tabindex="-1"></a><span class="st">-                    ]</span></span>
<span id="cb11-296"><a href="#cb11-296" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb11-297"><a href="#cb11-297" aria-hidden="true" tabindex="-1"></a><span class="st">-        ],</span></span>
<span id="cb11-298"><a href="#cb11-298" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;max_tokens&quot;: 100, </span></span>
<span id="cb11-299"><a href="#cb11-299" aria-hidden="true" tabindex="-1"></a><span class="st">-    } </span></span>
<span id="cb11-300"><a href="#cb11-300" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```</span></span>
<span id="cb11-301"><a href="#cb11-301" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-302"><a href="#cb11-302" aria-hidden="true" tabindex="-1"></a><span class="st">-    The request includes the `enhancements` and `dataSources` objects. `enhancements` represents the specific Vision enhancement features requested in the chat. `dataSources` represents the Computer Vision resource data that&#39;s needed for Vision enhancement. It has a `type` property which should be `&quot;AzureComputerVisionVideoIndex&quot;` and a `parameters` property which contains your AI Vision and video information.</span></span>
<span id="cb11-303"><a href="#cb11-303" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Fill in all the `&lt;placeholder&gt;` fields above with your own information: enter the endpoint URLs and keys of your OpenAI and AI Vision resources where appropriate, and retrieve the video index information from the earlier step.</span></span>
<span id="cb11-304"><a href="#cb11-304" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Send the POST request to the API endpoint. It should contain your OpenAI and AI Vision credentials, the name of your video index, and the ID and SAS URL of a single video.</span></span>
<span id="cb11-305"><a href="#cb11-305" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-306"><a href="#cb11-306" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Python](#tab/python)</span></span>
<span id="cb11-307"><a href="#cb11-307" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-308"><a href="#cb11-308" aria-hidden="true" tabindex="-1"></a><span class="st">-In your Python script, call the client&#39;s **create** method as in the previous sections, but include the *extra_body* parameter. Here, it contains the `enhancements` and `data_sources` fields. `enhancements` represents the specific Vision enhancement features requested in the chat. It has a `video` field, which has a boolean `enabled` property. Use this to request the video retrieval service. </span></span>
<span id="cb11-309"><a href="#cb11-309" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-310"><a href="#cb11-310" aria-hidden="true" tabindex="-1"></a><span class="st">-`data_sources` represents the external resource data that&#39;s needed for Vision enhancement. It has a `type` field which should be `&quot;AzureComputerVisionVideoIndex&quot;` and a `parameters` field. </span></span>
<span id="cb11-311"><a href="#cb11-311" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-312"><a href="#cb11-312" aria-hidden="true" tabindex="-1"></a><span class="st">-Set the `computerVisionBaseUrl` and `computerVisionApiKey` to the endpoint URL and access key of your Computer Vision resource. Set `indexName` to the name of your video index. Set `videoUrls` to a list of SAS URLs of your videos. </span></span>
<span id="cb11-313"><a href="#cb11-313" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-314"><a href="#cb11-314" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb11-315"><a href="#cb11-315" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Remember to set a `&quot;max_tokens&quot;` value, or the return output will be cut off.</span></span>
<span id="cb11-316"><a href="#cb11-316" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-317"><a href="#cb11-317" aria-hidden="true" tabindex="-1"></a><span class="st">-```python</span></span>
<span id="cb11-318"><a href="#cb11-318" aria-hidden="true" tabindex="-1"></a><span class="st">-response = client.chat.completions.create(</span></span>
<span id="cb11-319"><a href="#cb11-319" aria-hidden="true" tabindex="-1"></a><span class="st">-    model=deployment_name,</span></span>
<span id="cb11-320"><a href="#cb11-320" aria-hidden="true" tabindex="-1"></a><span class="st">-    messages=[</span></span>
<span id="cb11-321"><a href="#cb11-321" aria-hidden="true" tabindex="-1"></a><span class="st">-        { &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot; },</span></span>
<span id="cb11-322"><a href="#cb11-322" aria-hidden="true" tabindex="-1"></a><span class="st">-        { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [  </span></span>
<span id="cb11-323"><a href="#cb11-323" aria-hidden="true" tabindex="-1"></a><span class="st">-            {</span></span>
<span id="cb11-324"><a href="#cb11-324" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;type&quot;: &quot;acv_document_id&quot;,</span></span>
<span id="cb11-325"><a href="#cb11-325" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;acv_document_id&quot;: &quot;&lt;your_video_ID&gt;&quot;</span></span>
<span id="cb11-326"><a href="#cb11-326" aria-hidden="true" tabindex="-1"></a><span class="st">-            },</span></span>
<span id="cb11-327"><a href="#cb11-327" aria-hidden="true" tabindex="-1"></a><span class="st">-            { </span></span>
<span id="cb11-328"><a href="#cb11-328" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;type&quot;: &quot;text&quot;, </span></span>
<span id="cb11-329"><a href="#cb11-329" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;text&quot;: &quot;Describe this video:&quot; </span></span>
<span id="cb11-330"><a href="#cb11-330" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb11-331"><a href="#cb11-331" aria-hidden="true" tabindex="-1"></a><span class="st">-        ] } </span></span>
<span id="cb11-332"><a href="#cb11-332" aria-hidden="true" tabindex="-1"></a><span class="st">-    ],</span></span>
<span id="cb11-333"><a href="#cb11-333" aria-hidden="true" tabindex="-1"></a><span class="st">-    extra_body={</span></span>
<span id="cb11-334"><a href="#cb11-334" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;data_sources&quot;: [</span></span>
<span id="cb11-335"><a href="#cb11-335" aria-hidden="true" tabindex="-1"></a><span class="st">-            {</span></span>
<span id="cb11-336"><a href="#cb11-336" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;type&quot;: &quot;AzureComputerVisionVideoIndex&quot;,</span></span>
<span id="cb11-337"><a href="#cb11-337" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;parameters&quot;: {</span></span>
<span id="cb11-338"><a href="#cb11-338" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;computerVisionBaseUrl&quot;: &quot;&lt;your_computer_vision_endpoint&gt;&quot;, # your endpoint should look like the following https://YOUR_RESOURCE_NAME.cognitiveservices.azure.com/computervision</span></span>
<span id="cb11-339"><a href="#cb11-339" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;computerVisionApiKey&quot;: &quot;&lt;your_computer_vision_key&gt;&quot;,</span></span>
<span id="cb11-340"><a href="#cb11-340" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;indexName&quot;: &quot;&lt;name_of_your_index&gt;&quot;,</span></span>
<span id="cb11-341"><a href="#cb11-341" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;videoUrls&quot;: [&quot;&lt;your_video_SAS_URL&gt;&quot;]</span></span>
<span id="cb11-342"><a href="#cb11-342" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb11-343"><a href="#cb11-343" aria-hidden="true" tabindex="-1"></a><span class="st">-            }],</span></span>
<span id="cb11-344"><a href="#cb11-344" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;enhancements&quot;: {</span></span>
<span id="cb11-345"><a href="#cb11-345" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;video&quot;: {</span></span>
<span id="cb11-346"><a href="#cb11-346" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;enabled&quot;: True</span></span>
<span id="cb11-347"><a href="#cb11-347" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb11-348"><a href="#cb11-348" aria-hidden="true" tabindex="-1"></a><span class="st">-        }</span></span>
<span id="cb11-349"><a href="#cb11-349" aria-hidden="true" tabindex="-1"></a><span class="st">-    },</span></span>
<span id="cb11-350"><a href="#cb11-350" aria-hidden="true" tabindex="-1"></a><span class="st">-    max_tokens=100</span></span>
<span id="cb11-351"><a href="#cb11-351" aria-hidden="true" tabindex="-1"></a><span class="st">-)</span></span>
<span id="cb11-352"><a href="#cb11-352" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-353"><a href="#cb11-353" aria-hidden="true" tabindex="-1"></a><span class="st">-print(response)</span></span>
<span id="cb11-354"><a href="#cb11-354" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb11-355"><a href="#cb11-355" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb11-356"><a href="#cb11-356" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-357"><a href="#cb11-357" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb11-358"><a href="#cb11-358" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; The `&quot;data_sources&quot;` object&#39;s content varies depending on which Azure resource type and authentication method you&#39;re using. See the following reference:</span></span>
<span id="cb11-359"><a href="#cb11-359" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; </span></span>
<span id="cb11-360"><a href="#cb11-360" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; #### [Azure OpenAI resource](#tab/resource)</span></span>
<span id="cb11-361"><a href="#cb11-361" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; </span></span>
<span id="cb11-362"><a href="#cb11-362" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; ```json</span></span>
<span id="cb11-363"><a href="#cb11-363" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; &quot;data_sources&quot;: [</span></span>
<span id="cb11-364"><a href="#cb11-364" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; {</span></span>
<span id="cb11-365"><a href="#cb11-365" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;type&quot;: &quot;AzureComputerVisionVideoIndex&quot;,</span></span>
<span id="cb11-366"><a href="#cb11-366" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;parameters&quot;: {</span></span>
<span id="cb11-367"><a href="#cb11-367" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;endpoint&quot;: &quot;&lt;your_computer_vision_endpoint&gt;&quot;,</span></span>
<span id="cb11-368"><a href="#cb11-368" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;computerVisionApiKey&quot;: &quot;&lt;your_computer_vision_key&gt;&quot;,</span></span>
<span id="cb11-369"><a href="#cb11-369" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;indexName&quot;: &quot;&lt;name_of_your_index&gt;&quot;,</span></span>
<span id="cb11-370"><a href="#cb11-370" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;videoUrls&quot;: [&quot;&lt;your_video_SAS_URL&gt;&quot;]</span></span>
<span id="cb11-371"><a href="#cb11-371" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     }</span></span>
<span id="cb11-372"><a href="#cb11-372" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; }],</span></span>
<span id="cb11-373"><a href="#cb11-373" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; ```</span></span>
<span id="cb11-374"><a href="#cb11-374" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; </span></span>
<span id="cb11-375"><a href="#cb11-375" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; #### [Azure AIServices resource + SAS authentication](#tab/resource-sas)</span></span>
<span id="cb11-376"><a href="#cb11-376" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; </span></span>
<span id="cb11-377"><a href="#cb11-377" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; ```json</span></span>
<span id="cb11-378"><a href="#cb11-378" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; &quot;data_sources&quot;: [</span></span>
<span id="cb11-379"><a href="#cb11-379" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; {</span></span>
<span id="cb11-380"><a href="#cb11-380" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;type&quot;: &quot;AzureComputerVisionVideoIndex&quot;,</span></span>
<span id="cb11-381"><a href="#cb11-381" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;parameters&quot;: {</span></span>
<span id="cb11-382"><a href="#cb11-382" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;indexName&quot;: &quot;&lt;name_of_your_index&gt;&quot;,</span></span>
<span id="cb11-383"><a href="#cb11-383" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;videoUrls&quot;: [&quot;&lt;your_video_SAS_URL&gt;&quot;]</span></span>
<span id="cb11-384"><a href="#cb11-384" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     }</span></span>
<span id="cb11-385"><a href="#cb11-385" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; }],</span></span>
<span id="cb11-386"><a href="#cb11-386" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; ```  </span></span>
<span id="cb11-387"><a href="#cb11-387" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; </span></span>
<span id="cb11-388"><a href="#cb11-388" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; #### [Azure AIServices resource + Managed Identities](#tab/resource-mi)</span></span>
<span id="cb11-389"><a href="#cb11-389" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; </span></span>
<span id="cb11-390"><a href="#cb11-390" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; ```json</span></span>
<span id="cb11-391"><a href="#cb11-391" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; &quot;data_sources&quot;: [</span></span>
<span id="cb11-392"><a href="#cb11-392" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; {</span></span>
<span id="cb11-393"><a href="#cb11-393" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;type&quot;: &quot;AzureComputerVisionVideoIndex&quot;,</span></span>
<span id="cb11-394"><a href="#cb11-394" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     &quot;parameters&quot;: {</span></span>
<span id="cb11-395"><a href="#cb11-395" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;         &quot;indexName&quot;: &quot;&lt;name_of_your_index&gt;&quot;,</span></span>
<span id="cb11-396"><a href="#cb11-396" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;         &quot;documentAuthenticationKind&quot;: &quot;managedidentity&quot;,</span></span>
<span id="cb11-397"><a href="#cb11-397" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt;     }</span></span>
<span id="cb11-398"><a href="#cb11-398" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; }],</span></span>
<span id="cb11-399"><a href="#cb11-399" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; ```  </span></span>
<span id="cb11-400"><a href="#cb11-400" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; ---</span></span>
<span id="cb11-401"><a href="#cb11-401" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-402"><a href="#cb11-402" aria-hidden="true" tabindex="-1"></a><span class="st">-### Output</span></span>
<span id="cb11-403"><a href="#cb11-403" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-404"><a href="#cb11-404" aria-hidden="true" tabindex="-1"></a><span class="st">-The chat responses you receive from the model should include information about the video. The API response should look like the following.</span></span>
<span id="cb11-405"><a href="#cb11-405" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-406"><a href="#cb11-406" aria-hidden="true" tabindex="-1"></a><span class="st">-```json</span></span>
<span id="cb11-407"><a href="#cb11-407" aria-hidden="true" tabindex="-1"></a><span class="st">-{</span></span>
<span id="cb11-408"><a href="#cb11-408" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;id&quot;: &quot;chatcmpl-8V4J2cFo7TWO7rIfs47XuDzTKvbct&quot;,</span></span>
<span id="cb11-409"><a href="#cb11-409" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;object&quot;: &quot;chat.completion&quot;,</span></span>
<span id="cb11-410"><a href="#cb11-410" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;created&quot;: 1702415412,</span></span>
<span id="cb11-411"><a href="#cb11-411" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;model&quot;: &quot;gpt-4&quot;,</span></span>
<span id="cb11-412"><a href="#cb11-412" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;choices&quot;:</span></span>
<span id="cb11-413"><a href="#cb11-413" aria-hidden="true" tabindex="-1"></a><span class="st">-    [</span></span>
<span id="cb11-414"><a href="#cb11-414" aria-hidden="true" tabindex="-1"></a><span class="st">-        {</span></span>
<span id="cb11-415"><a href="#cb11-415" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;finish_reason&quot;:&quot;stop&quot;,</span></span>
<span id="cb11-416"><a href="#cb11-416" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;index&quot;: 0,</span></span>
<span id="cb11-417"><a href="#cb11-417" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;message&quot;:</span></span>
<span id="cb11-418"><a href="#cb11-418" aria-hidden="true" tabindex="-1"></a><span class="st">-            {</span></span>
<span id="cb11-419"><a href="#cb11-419" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;role&quot;: &quot;assistant&quot;,</span></span>
<span id="cb11-420"><a href="#cb11-420" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;content&quot;: &quot;The advertisement video opens with a blurred background that suggests a serene and aesthetically pleasing environment, possibly a workspace with a nature view. As the video progresses, a series of frames showcase a digital interface with search bars and prompts like \&quot;Inspire new ideas,\&quot; \&quot;Research a topic,\&quot; and \&quot;Organize my plans,\&quot; suggesting features of a software or application designed to assist with productivity and creativity.\n\nThe color palette is soft and varied, featuring pastel blues, pinks, and purples, creating a calm and inviting atmosphere. The backgrounds of some frames are adorned with abstract, organically shaped elements and animations, adding to the sense of innovation and modernity.\n\nMidway through the video, the focus shifts to what appears to be a browser or software interface with the phrase \&quot;Screens simulated, subject to change; feature availability and timing may vary,\&quot; indicating the product is in development and that the visuals are illustrative of its capabilities.\n\nThe use of text prompts continues with \&quot;Help me relax,\&quot; followed by a demonstration of a &#39;dark mode&#39; feature, providing a glimpse into the software&#39;s versatility and user-friendly design.\n\nThe video concludes by revealing the product name, \&quot;Copilot,\&quot; and positioning it as \&quot;Your everyday AI companion,\&quot; implying the use of artificial intelligence to enhance daily tasks. The final frames feature the Microsoft logo, associating the product with the well-known technology company.\n\nIn summary, the advertisement video is for a Microsoft product named \&quot;Copilot,\&quot; which seems to be an AI-powered software tool aimed at improving productivity, creativity, and organization for its users. The video conveys a message of innovation, ease, and support in daily digital interactions through a visually appealing and calming presentation.&quot;</span></span>
<span id="cb11-421"><a href="#cb11-421" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb11-422"><a href="#cb11-422" aria-hidden="true" tabindex="-1"></a><span class="st">-        }</span></span>
<span id="cb11-423"><a href="#cb11-423" aria-hidden="true" tabindex="-1"></a><span class="st">-    ],</span></span>
<span id="cb11-424"><a href="#cb11-424" aria-hidden="true" tabindex="-1"></a><span class="st">-    &quot;usage&quot;:</span></span>
<span id="cb11-425"><a href="#cb11-425" aria-hidden="true" tabindex="-1"></a><span class="st">-    {</span></span>
<span id="cb11-426"><a href="#cb11-426" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;prompt_tokens&quot;: 2068,</span></span>
<span id="cb11-427"><a href="#cb11-427" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;completion_tokens&quot;: 341,</span></span>
<span id="cb11-428"><a href="#cb11-428" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;total_tokens&quot;: 2409</span></span>
<span id="cb11-429"><a href="#cb11-429" aria-hidden="true" tabindex="-1"></a><span class="st">-    }</span></span>
<span id="cb11-430"><a href="#cb11-430" aria-hidden="true" tabindex="-1"></a><span class="st">-}</span></span>
<span id="cb11-431"><a href="#cb11-431" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb11-432"><a href="#cb11-432" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-433"><a href="#cb11-433" aria-hidden="true" tabindex="-1"></a><span class="st">-Every response includes a `&quot;finish_reason&quot;` field. It has the following possible values:</span></span>
<span id="cb11-434"><a href="#cb11-434" aria-hidden="true" tabindex="-1"></a><span class="st">-- `stop`: API returned complete model output.</span></span>
<span id="cb11-435"><a href="#cb11-435" aria-hidden="true" tabindex="-1"></a><span class="st">-- `length`: Incomplete model output due to the `max_tokens` input parameter or model&#39;s token limit.</span></span>
<span id="cb11-436"><a href="#cb11-436" aria-hidden="true" tabindex="-1"></a><span class="st">-- `content_filter`: Omitted content due to a flag from our content filters.</span></span>
<span id="cb11-437"><a href="#cb11-437" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-438"><a href="#cb11-438" aria-hidden="true" tabindex="-1"></a><span class="st">-### Pricing example for Video prompts</span></span>
<span id="cb11-439"><a href="#cb11-439" aria-hidden="true" tabindex="-1"></a><span class="st">-The pricing for GPT-4 Turbo with Vision is dynamic and depends on the specific features and inputs used. For a comprehensive view of Azure OpenAI pricing see [Azure OpenAI Pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/).</span></span>
<span id="cb11-440"><a href="#cb11-440" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-441"><a href="#cb11-441" aria-hidden="true" tabindex="-1"></a><span class="st">-The base charges and additional features are outlined below:</span></span>
<span id="cb11-442"><a href="#cb11-442" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb11-443"><a href="#cb11-443" aria-hidden="true" tabindex="-1"></a><span class="st">-Base Pricing for GPT-4 Turbo with Vision is:</span></span>
<span id="cb11-444"><a href="#cb11-444" aria-hidden="true" tabindex="-1"></a><span class="st">-- Input: $0.01 per 1000 tokens</span></span>
<span id="cb11-445"><a href="#cb11-445" aria-hidden="true" tabindex="-1"></a><span class="st">-- Output: $0.03 per 1000 tokens</span></span>
<span id="cb11-446"><a href="#cb11-446" aria-hidden="true" tabindex="-1"></a><span class="st">-  </span></span>
<span id="cb11-447"><a href="#cb11-447" aria-hidden="true" tabindex="-1"></a><span class="st">-Video prompt integration with Video Retrieval Add-on:</span></span>
<span id="cb11-448"><a href="#cb11-448" aria-hidden="true" tabindex="-1"></a><span class="st">-- Ingestion: $0.05 per minute of video</span></span>
<span id="cb11-449"><a href="#cb11-449" aria-hidden="true" tabindex="-1"></a><span class="st">-- Transactions: $0.25 per 1000 queries of the Video Retrieval</span></span>
<span id="cb11-450"><a href="#cb11-450" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb11-451"><a href="#cb11-451" aria-hidden="true" tabindex="-1"></a> ## Next steps</span>
<span id="cb11-452"><a href="#cb11-452" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-5">Summary</h3>
<div class="sourceCode" id="cb12"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;breaking change&quot;</span><span class="fu">,</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Visionエンハンスメントおよびビデオプロンプトの機能削除&quot;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-5">Explanation</h3>
<p>この変更では、<code>gpt-with-vision.md</code>
ドキュメントから大部分の内容が削除され、GPT-4 Turbo with
Visionの機能に関する重要な情報が大幅に削減されました。具体的には、画像やビデオにおける「Visionエンハンスメント」機能に関連する説明や設定手順が削除され、ドキュメントは非常に簡素化されています。</p>
<p>削除されたセクションには、オプティカルキャラクター認識（OCR）やオブジェクトグラウンディングの統合、ビデオプロンプトによる機能拡張、画像やビデオを扱うためのAPIリクエストの詳細な例が含まれていました。これにより、ユーザーはこれらの機能を以前の方法で利用することができなくなります。この変更は、利用できる機能の理解に影響を与えるため、ユーザーは新たな導入方法や別の機能を探求する必要があるかもしれません。</p>
<p>この更新は、特に従来のガイドラインやサンプルコードを参照している開発者にとって重要であり、従来のアプローチが変更されたことによる混乱を招く可能性があります。</p>
<h2
id="item-c8df1c">articles/ai-services/openai/how-to/provisioned-get-started.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb13"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -37,40 +37,40 @@ Creating a new deployment requires available (unused) quota to cover the desired</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a> Then 200 PTUs of quota are considered used, and there are 300 PTUs available for use to create new deployments. </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="st">-A default amount of PTU quota is assigned to all subscriptions in several regions. You can view the quota available to you in a region by visiting the Quotas blade in Azure OpenAI Studio and selecting the desired subscription and region. For example, the screenshot below shows a quota limit of 500 PTUs in West US for the selected subscription. Note that you might see lower values of available default quotas. </span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="st">- </span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="va">+A default amount of provisioned and global provisioned quota is assigned to all subscriptions in several regions. You can view the quota available to you in a region by visiting the Quotas blade in Azure OpenAI Studio and selecting the desired subscription and region. For example, the screenshot below shows a quota limit of 500 PTUs in West US for the selected subscription. Note that you might see lower values of available default quotas. </span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a> :::image type=&quot;content&quot; source=&quot;../media/provisioned/available-quota.png&quot; alt-text=&quot;A screenshot of the available quota in Azure OpenAI studio.&quot; lightbox=&quot;../media/provisioned/available-quota.png&quot;:::</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a> Additional quota can be requested by clicking the Request Quota link to the right of the “Usage/Limit” column.  (This is off-screen in the screenshot above). </span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a> ## Create an Azure OpenAI resource </span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="st">-Provisioned Throughput deployments are created via Azure OpenAI resource objects within Azure. You must have an Azure OpenAI resource in each region where you intend to create a deployment. Use the Azure portal to [create a resource](./create-resource.md) in a region with available quota, if required.  </span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="va">+Provisioned and global provisioned deployments are created via Azure OpenAI resource objects within Azure. You must have an Azure OpenAI resource in each region where you intend to create a deployment. Use the Azure portal to [create a resource](./create-resource.md) in a region with available quota, if required.  </span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a> &gt; [!NOTE]</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Azure OpenAI resources can support multiple types of Azure OpenAI deployments at the same time.  It is not necessary to dedicate new resources for your provisioned deployments. </span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="st">-## Create your provisioned deployment - capacity is available</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; Azure OpenAI resources can support multiple types of Azure OpenAI deployments at the same time.  It is not necessary to dedicate new resources for your provisioned or global provisioned deployments. </span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create your provisioned or global provisioned deployment - capacity is available</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="st">-After you purchase a commitment on your quota, you can create a deployment. To create a provisioned deployment, you can follow these steps; the choices described reflect the entries shown in the screenshot. </span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="va">+once you have verified your quota, you can create a deployment. To create a provisioned deployment, you can follow these steps; the choices described reflect the entries shown in the screenshot. </span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a> :::image type=&quot;content&quot; source=&quot;../media/provisioned/deployment-screen.png&quot; alt-text=&quot;Screenshot of the Azure OpenAI Studio deployment page for a provisioned deployment.&quot; lightbox=&quot;../media/provisioned/deployment-screen.png&quot;:::</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a> 1. Sign into the [Azure OpenAI Studio](https://oai.azure.com)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="st">-2. Choose the subscription that was enabled for provisioned deployments &amp; select the desired resource in a region where you have the quota.</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Choose the subscription that was enabled for provisioned and global provisioned deployments &amp; select the desired resource in a region where you have the quota.</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a> 3. Under **Management** in the left-nav select **Deployments**.</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a> 4. Select Create new deployment and configure the following fields. Expand the **advanced options** drop-down menu.</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a> 5. Fill out the values in each field. Here&#39;s an example:</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a> | Field | Description |    Example |</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="st">-|--|--|--| </span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="va">+|--|--|--|</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a> | Select a model|  Choose the specific model you wish to deploy.   | GPT-4 |</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a> | Model version |  Choose the version of the model to deploy.   | 0613 |</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a> | Deployment Name   | The deployment name is used in your code to call the model by using the client libraries and the REST APIs.  | gpt-4|</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a> | Content filter   | Specify the filtering policy to apply to the deployment. Learn more on our [Content Filtering](../concepts/content-filter.md) how-to. |   Default |</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a><span class="st">-| Deployment Type  |This impacts the throughput and performance. Choose Provisioned-Managed for your provisioned deployment    | Provisioned-Managed |</span></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a><span class="va">+| Deployment Type  |This impacts the throughput and performance. Choose Provisioned-Managed or Global Provisioned-Managed for your deployment  | Provisioned-Managed |</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a> | Provisioned Throughput Units |   Choose the amount of throughput you wish to include in the deployment. |    100 |</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a> Important things to note: </span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -87,7 +87,7 @@ The image below shows the pricing confirmation you will see. The price shown is</span></span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a> :::image type=&quot;content&quot; source=&quot;../media/provisioned/confirm-pricing.png&quot; alt-text=&quot;Screenshot showing the pricing confirmation screen.&quot; lightbox=&quot;../media/provisioned/confirm-pricing.png&quot;:::</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="st">-If you wish to create your deployment programmatically, you can do so with the following Azure CLI command. Update the `sku-capacity` with the desired number of provisioned throughput units.</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a><span class="va">+If you wish to create your deployment programmatically, you can do so with the following Azure CLI command. To specify the deployment type, modify the `sku-name` to `ProvisionedManaged` or `GlobalProvisionedManaged` based on the intended deployment type. Update the `sku-capacity` with the desired number of provisioned throughput units.</span></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a> ```cli</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a> az cognitiveservices account deployment create \</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -101,9 +101,9 @@ az cognitiveservices account deployment create \</span></span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a> --sku-name ProvisionedManaged</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a> ```</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a><span class="st">-REST, ARM template, Bicep, and Terraform can also be used to create deployments. See the section on automating deployments in the [Managing Quota](quota.md?tabs=rest#automate-deployment) how-to guide and replace the `sku.name` with &quot;ProvisionedManaged&quot; rather than &quot;Standard.&quot;</span></span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a><span class="va">+REST, ARM template, Bicep, and Terraform can also be used to create deployments. See the section on automating deployments in the [Managing Quota](quota.md?tabs=rest#automate-deployment) how-to guide and replace the `sku.name` with &quot;ProvisionedManaged&quot; or &quot;GlobalProvisionedManaged&quot; rather than &quot;Standard.&quot;</span></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a><span class="st">-## Create your provisioned deployment – Capacity is not available </span></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create your provisioned or global provisioned deployment – Capacity is not available</span></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a> Due to the dynamic nature of capacity availability, it is possible that the region of your selected resource might not have the service capacity to create the deployment of the specified model, version, and number of PTUs. </span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-6">Summary</h3>
<div class="sourceCode" id="cb14"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;グローバルプロビジョンドデプロイメントに関する説明の追加&quot;</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-6">Explanation</h3>
<p>この変更では、<code>provisioned-get-started.md</code>
ドキュメントにおいて、プロビジョンドデプロイメントとグローバルプロビジョンドデプロイメントに関する説明が統合されました。具体的な更新内容として、プロビジョンドデプロイメントに関する指示が、両方のデプロイメントタイプに対応する形で書き換えられた点が挙げられます。</p>
<p>変更の主なポイントは以下の通りです：</p>
<ol class="incremental" type="1">
<li><p><strong>Quotaの表現</strong>:
標準のプロビジョンドクォータに加え、「グローバルプロビジョンドクォータ」にも言及があり、ユーザーがどちらのデプロイメントタイプを利用できるかの理解を深める助けとなります。</p></li>
<li><p><strong>デプロイメントの作成手順</strong>:
デプロイメントの作成手順が改訂され、選択肢に「グローバルプロビジョンドデプロイメント」が追加されました。これにより、ユーザーは特定のクォータを確認した後、より柔軟にデプロイメントを選択できるようになります。</p></li>
<li><p><strong>CLIコマンドの修正</strong>:
プログラムからデプロイメントを作成するためのCLIコマンドが、一括管理される「ProvisionedManaged」または「GlobalProvisionedManaged」を指定できるように更新されました。</p></li>
</ol>
<p>これらの改善により、ユーザーが自身のニーズに応じた適切なデプロイメントを選択しやすくなり、そして利用可能なリソースに基づいた正確な情報提供が行われるようになります。</p>
<h2
id="item-3eb72b">articles/ai-services/openai/how-to/provisioned-throughput-onboarding.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb15"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -27,7 +27,7 @@ You should consider switching from pay-as-you-go to provisioned throughput when</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a> &gt; [!NOTE]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a> &gt; In function calling and agent use cases, token usage can be variable. You should understand your expected Tokens Per Minute (TPM) usage in detail prior to migrating workloads to PTU.</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="st">-## Sizing and estimation: provisioned managed only</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="va">+## Sizing and estimation: provisioned and global provisioned</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a> Determining the right amount of provisioned throughput, or PTUs, you require for your workload is an essential step to optimizing performance and cost. This section describes how to use the Azure OpenAI capacity planning tool. The tool provides you with an estimate of the required PTU to meet the needs of your workload.</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -56,38 +56,37 @@ The values in the output column are the estimated value of PTU units required fo</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a> ## Understanding the Provisioned Throughput Purchase Model </span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="st">-Azure OpenAI Provisioned is purchased on-demand at an hourly basis based on the number of deployed PTUs, with substantial term discount available via the purchase of Azure Reservations.   </span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="va">+Azure OpenAI Provisioned and Global Provisiones are purchased on-demand at an hourly basis based on the number of deployed PTUs, with substantial term discount available via the purchase of Azure Reservations.   </span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="st">-The hourly model is useful for short-term deployment needs, such as validating new models or acquiring capacity for a hackathon.  However, the discounts provided by the Azure Reservation for Azure OpenAI Provisioned are considerable and most customers with consistent long-term usage will find a reserved model to be a better value proposition. </span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="va">+The hourly model is useful for short-term deployment needs, such as validating new models or acquiring capacity for a hackathon.  However, the discounts provided by the Azure Reservation for Azure OpenAI Provisioned and Global Provisioned are considerable and most customers with consistent long-term usage will find a reserved model to be a better value proposition. </span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a> &gt; [!NOTE]</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a> &gt; Azure OpenAI Provisioned customers onboarded prior to the August self-service update use a purchase model called the Commitment model.  These customers can continue to use this older purchase model alongside the Hourly/reservation purchase model.  The Commitment model is not available for new customers.  For details on the Commitment purchase model and options for coexistence and migration, please see the [Azure OpenAI Provisioned August Update](../concepts/provisioned-migration.md).</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a> ## Hourly Usage  </span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="st">-Provisioned Throughput deployments are charged an hourly rate ($/PTU/hr) on the number of PTUs that have been deployed.  For example, a 300 PTU deployment will be charged the hourly rate times 300.  All Azure OpenAI pricing is available in the Azure Pricing Calculator. </span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="va">+Provisioned and Global Provisioned deployments are charged an hourly rate ($/PTU/hr) on the number of PTUs that have been deployed.  For example, a 300 PTU deployment will be charged the hourly rate times 300.  All Azure OpenAI pricing is available in the Azure Pricing Calculator. </span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a> If a deployment exists for a partial hour, it will receive a prorated charge based on the number of minutes it was deployed during the hour.  For example, a deployment that exists for 15 minutes during an hour will receive 1/4th the hourly charge.  </span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a> If the deployment size is changed, the costs of the deployment will adjust to match the new number of PTUs.   </span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a> :::image type=&quot;content&quot; source=&quot;../media/provisioned/hourly-billing.png&quot; alt-text=&quot;A diagram showing hourly billing.&quot; lightbox=&quot;../media/provisioned/hourly-billing.png&quot;:::</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a><span class="st">-Paying for provisioned deployments on an hourly basis is ideal for short-term deployment scenarios.  For example: Quality and performance benchmarking of new models, or temporarily increasing PTU capacity to cover an event such as a hackathon.  </span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="va">+Paying for provisioned and global provisioned deployments on an hourly basis is ideal for short-term deployment scenarios.  For example: Quality and performance benchmarking of new models, or temporarily increasing PTU capacity to cover an event such as a hackathon.  </span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a><span class="st">-Customers that require long-term usage of provisioned deployments, however, might pay significantly less per month by purchasing a term discount via an Azure Reservation as discussed in the next section. </span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a><span class="va">+Customers that require long-term usage of provisioned and global provisioned deployments, however, might pay significantly less per month by purchasing a term discount via an Azure Reservation as discussed in the next section. </span></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a> &gt; [!NOTE]</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a> &gt; It is not recommended to scale production deployments according to incoming traffic and pay for them purely on an hourly basis. There are two reasons for this:</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a> &gt; * The cost savings achieved by purchasing an Azure Reservation for Azure OpenAI Provisioned are significant, and it will be less expensive in many cases to maintain a deployment sized for full production volume paid for via a reservation than it would be to scale the deployment with incoming traffic.</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a> &gt; * Having unused provisioned quota (PTUs) does not guarentee that capacity will be available to support increasing the size of the deployment when required. Quota limits the maximum number of PTUs that can be deployed, but it is not a capacity guarantee. Provisioned capacity for each region and modal dynamically changes throughout the day and might not be available when required. As a result, it is recommended to maintain a permanant deployment to cover your traffic needs (paid for via a reservation).</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a> &gt; * Charges for deployments on a deleted resource will continue until the resource is purged.  To prevent this, delete a resource’s deployment before deleting the resource.  For more information, see [Recover or purge deleted Azure AI services resources](../../recover-purge-resources.md). </span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a><span class="st">-## Azure Reservations for Azure OpenAI Provisioned   </span></span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a><span class="va">+## Azure Reservations for Azure OpenAI Provisioned and Global Provisioned</span></span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a><span class="st">-Discounts on top of the hourly usage price can be obtained by purchasing an Azure Reservation for Azure OpenAI Provisioned. An Azure Reservation is a term-discounting mechanism shared by many Azure products. For example, Compute and Cosmos DB. For Azure OpenAI Provisioned, the reservation provides a discount for committing to payment for fixed number of PTUs for a one-month or one-year period.  </span></span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a><span class="va">+Discounts on top of the hourly usage price can be obtained by purchasing an Azure Reservation for Azure OpenAI Provisioned and Global Provisioned. An Azure Reservation is a term-discounting mechanism shared by many Azure products. For example, Compute and Cosmos DB. For Azure OpenAI Provisioned and Global Provisioned, the reservation provides a discount for committing to payment for fixed number of PTUs for a one-month or one-year period.  </span></span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a><span class="st">-* Azure Reservations are purchased via the Azure portal, not Azure OpenAI Studio  Link to Azure reservation portal. </span></span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a><span class="va">+* Azure Reservations are purchased via the Azure portal, not Azure OpenAI Studio Link to Azure reservation portal. </span></span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a> * Reservations are purchased regionally and can be flexibly scoped to cover usage from a group of deployments. Reservation scopes include: </span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -110,7 +109,7 @@ Discounts on top of the hourly usage price can be obtained by purchasing an Azur</span></span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a> &gt;</span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a> &gt; * The Azure role and tenant policy requirements to purchase a reservation are different than those required to create a deployment or Azure OpenAI resource.  Verify authorization to purchase reservations in advance of needing to do so. See Azure OpenAI [Provisioned reservation documentation](https://aka.ms/oai/docs/ptum-reservations) for more details.</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a><span class="st">-## Important: Sizing Azure OpenAI Provisioned Reservations </span></span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a><span class="va">+## Important: Sizing Azure OpenAI Provisioned &amp; Global Provisioned Reservations</span></span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a> The PTU amounts in reservation purchases are independent of PTUs allocated in quota or used in deployments. It is possible to purchase a reservation for more PTUs than you have in quota, or can deploy for the desired region, model, or version.   Credits for over-purchasing a reservation are limited, and customers must take steps to ensure they maintain their reservation sizes in line with their deployed PTUs.  </span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a>  </span></code></pre></div>
</details>
<h3 id="summary-7">Summary</h3>
<div class="sourceCode" id="cb16"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;グローバルプロビジョンドに関するコンテンツの追加&quot;</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-7">Explanation</h3>
<p>この変更では、<code>provisioned-throughput-onboarding.md</code>
ドキュメントにおいて、プロビジョンド・スループットの概念が拡張され、グローバルプロビジョンドに関する情報が統合されました。主な更新内容は次の通りです。</p>
<ol class="incremental" type="1">
<li><p><strong>セクションタイトルの変更</strong>:
サイズと見積もり、購入モデル、使用料金、Azure予約などの各セクションのタイトルが「プロビジョンド」のみから「プロビジョンドおよびグローバルプロビジョンド」に変更され、両方のデプロイメントタイプに関する情報が含まれることを明示しています。</p></li>
<li><p><strong>料金と購入モデルの統一</strong>:
プロビジョンドおよびグローバルプロビジョンドのどちらも、デプロイメントに応じて固定のPTU（プロビジョンド・スループット単位）が必要で、その料金体系が統一されて記載されています。</p></li>
<li><p><strong>セクションの詳細の更新</strong>:
Azure予約についての説明も更新され、両方のデプロイメントタイプに対する長期的な使用に関する割引情報が反映されています。この変更により、ユーザーは各種デプロイメントのコストを評価しやすくなります。</p></li>
<li><p><strong>重要な注意点の追加</strong>:
グローバルプロビジョンドに関連する購入やサイズ調整に関する注意点。特に、予約の
PTU
が使用される際に、デプロイメントに対して過剰に購入することが可能であること、この部分に関する詳細な説明が強調されています。</p></li>
</ol>
<p>これにより、ユーザーはプロビジョンドとグローバルプロビジョンド両方のデプロイメントオプションを理解し、適切に利用計画を立てられるようになります。</p>
<h2
id="item-366276">articles/ai-services/openai/includes/gpt-v-python.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb17"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -21,7 +21,6 @@ Use this article to get started using the Azure OpenAI Python SDK to deploy and</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a> - &lt;a href=&quot;https://www.python.org/&quot; target=&quot;_blank&quot;&gt;Python 3.8 or later version&lt;/a&gt;.</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a> - The following Python libraries: `os`</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a> - An Azure OpenAI Service resource with a GPT-4 Turbo with Vision model deployed. See [GPT-4 and GPT-4 Turbo Preview model availability](../concepts/models.md#gpt-4-and-gpt-4-turbo-model-availability) for available regions. For more information about resource creation, see the [resource deployment guide](/azure/ai-services/openai/how-to/create-resource).</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="st">-- For Vision enhancement (optional): An Azure Computer Vision resource in the same region as your Azure OpenAI resource, in the paid (S1) tier.</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a> ## Set up </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -44,7 +43,6 @@ pip install openai</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a> Create a new Python file named _quickstart.py_. Open the new file in your preferred editor or IDE.</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Image prompts](#tab/image)</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a> 1. Replace the contents of _quickstart.py_ with the following code. </span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -98,95 +96,6 @@ Create a new Python file named _quickstart.py_. Open the new file in your prefer</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>     python quickstart.py</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>     ```</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Image prompt enhancements](#tab/enhanced)</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="st">-GPT-4 Turbo with Vision provides exclusive access to Azure AI Services tailored enhancements. When combined with Azure AI Vision, it enhances your chat experience by providing the chat model with more detailed information about visible text in the image and the locations of objects.</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="st">-The **Optical Character Recognition (OCR)** integration allows the model to produce higher quality responses for dense text, transformed images, and number-heavy financial documents. It also covers a wider range of languages.</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="st">-The **object grounding** integration brings a new layer to data analysis and user interaction, as the feature can visually distinguish and highlight important elements in the images it processes.</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!CAUTION]</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Azure AI enhancements for GPT-4 Turbo with Vision will be billed separately from the core functionalities. Each specific Azure AI enhancement for GPT-4 Turbo with Vision has its own distinct charges. For details, see the [special pricing information](../concepts/gpt-with-vision.md#special-pricing-information).</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Vision enhancements are not supported by the GPT-4 Turbo GA model. They are only available with the preview models.</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Replace the contents of _quickstart.py_ with the following code. </span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```python</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a><span class="st">-    from openai import AzureOpenAI</span></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a><span class="st">-    api_base = os.getenv(&quot;AZURE_OPENAI_ENDPOINT&quot;)</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a><span class="st">-    api_key= os.getenv(&quot;AZURE_OPENAI_API_KEY&quot;)</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a><span class="st">-    deployment_name = &#39;&lt;your_deployment_name&gt;&#39;</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="st">-    api_version = &#39;2023-12-01-preview&#39; # this might change in the future</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a><span class="st">-    client = AzureOpenAI(</span></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a><span class="st">-        api_key=api_key,  </span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="st">-        api_version=api_version,</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a><span class="st">-        base_url=f&quot;{api_base}/openai/deployments/{deployment_name}/extensions&quot;,</span></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="st">-    )</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a><span class="st">-    response = client.chat.completions.create(</span></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a><span class="st">-        model=deployment_name,</span></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a><span class="st">-        messages=[</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a><span class="st">-            { &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot; },</span></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a><span class="st">-            { &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [  </span></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="st">-                { </span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;type&quot;: &quot;text&quot;, </span></span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;text&quot;: &quot;Describe this picture:&quot; </span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a><span class="st">-                },</span></span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a><span class="st">-                { </span></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;type&quot;: &quot;image_url&quot;,</span></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;image_url&quot;: {</span></span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a><span class="st">-                        &quot;url&quot;: &quot;&lt;image URL&gt;&quot;</span></span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a><span class="st">-                    }</span></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a><span class="st">-            ] } </span></span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a><span class="st">-        ],</span></span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a><span class="st">-        extra_body={</span></span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;dataSources&quot;: [</span></span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a><span class="st">-                {</span></span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;type&quot;: &quot;AzureComputerVision&quot;,</span></span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;parameters&quot;: {</span></span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a><span class="st">-                        &quot;endpoint&quot;: &quot;&lt;your_computer_vision_endpoint&gt;&quot;,</span></span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a><span class="st">-                        &quot;key&quot;: &quot;&lt;your_computer_vision_key&gt;&quot;</span></span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a><span class="st">-                    }</span></span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a><span class="st">-                }],</span></span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;enhancements&quot;: {</span></span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;ocr&quot;: {</span></span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;enabled&quot;: True</span></span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a><span class="st">-                },</span></span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;grounding&quot;: {</span></span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;enabled&quot;: True</span></span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a><span class="st">-        },</span></span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a><span class="st">-        max_tokens=2000</span></span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a><span class="st">-    )</span></span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a><span class="st">-    print(response)</span></span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```</span></span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Make the following changes:</span></span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a><span class="st">-    1. Enter your GPT-4 Turbo with Vision deployment name in the appropriate field. </span></span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a><span class="st">-    1. Enter your Computer Vision endpoint URL and key in the appropriate fields.</span></span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a><span class="st">-    1. Change the value of the `&quot;url&quot;` field to the URL of your image.</span></span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a><span class="st">-        &gt; [!TIP]</span></span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a><span class="st">-        &gt; You can also use a base 64 encoded image data instead of a URL. For more information, see the [GPT-4 Turbo with Vision how-to guide](../how-to/gpt-with-vision.md#use-a-local-image).</span></span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Run the application with the `python` command:</span></span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```console</span></span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a><span class="st">-    python quickstart.py</span></span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```</span></span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Video prompt enhancements](#tab/video)</span></span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-107"><a href="#cb17-107" aria-hidden="true" tabindex="-1"></a><span class="st">-Video prompt integration is outside the scope of this quickstart. See the [GPT-4 Turbo with Vision how-to guide](../how-to/gpt-with-vision.md#use-vision-enhancement-with-video) for detailed instructions on setting up video prompts in chat completions programmatically.</span></span>
<span id="cb17-108"><a href="#cb17-108" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb17-109"><a href="#cb17-109" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb17-110"><a href="#cb17-110" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb17-111"><a href="#cb17-111" aria-hidden="true" tabindex="-1"></a> ## Clean up resources</span>
<span id="cb17-112"><a href="#cb17-112" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-8">Summary</h3>
<div class="sourceCode" id="cb18"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;breaking change&quot;</span><span class="fu">,</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;GPT-4 Turbo with Visionに関する内容の削除&quot;</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-8">Explanation</h3>
<p>この変更では、<code>gpt-v-python.md</code>
ドキュメントから、多くの内容が削除されました。特に、GPT-4 Turbo with
Vision
に関連する機能やライブラリ、サンプルコードが大幅に削除されています。主な更新ポイントは以下の通りです。</p>
<ol class="incremental" type="1">
<li><p><strong>関連情報の削除</strong>: Python
3.8や必要なライブラリ、Azure OpenAI
Serviceリソースに関する説明の一部が削除され、ユーザーに対しての初期設定に必要な情報が大幅に削減されました。</p></li>
<li><p><strong>画像プロンプトとその強化機能の説明の削除</strong>: GPT-4
Turbo with
Visionに関する特徴、例えば、光学文字認識（OCR）やオブジェクトグラウンディングに関する情報が削除され、これに伴い関連する注意事項や重要なメモも削除されています。</p></li>
<li><p><strong>サンプルコードの削除</strong>: ユーザーがGPT-4 Turbo with
Visionを活用するための具体的なサンプルコードが完全に削除され、これによりこの機能の利用方法を直接示唆した部分がなくなりました。</p></li>
</ol>
<p>この結果、ユーザーはGPT-4 Turbo with
Visionの利用方法に関する具体的な情報や、直接的なコードサンプルを参照することができなくなり、プロジェクトの実装に影響を及ぼす可能性があります。この変更は、特定の機能を使用するためのガイダンスを提供する上で、大きな制約となります。</p>
<h2
id="item-65c91c">articles/ai-services/openai/includes/gpt-v-rest.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb19"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -18,7 +18,6 @@ Use this article to get started using the Azure OpenAI REST APIs to deploy and u</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a> - &lt;a href=&quot;https://www.python.org/&quot; target=&quot;_blank&quot;&gt;Python 3.8 or later version&lt;/a&gt;.</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a> - The following Python libraries: `requests`, `json`.</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a> - An Azure OpenAI Service resource with a GPT-4 Turbo with Vision model deployed. See [GPT-4 and GPT-4 Turbo Preview model availability](../concepts/models.md#gpt-4-and-gpt-4-turbo-model-availability) for available regions. For more information about resource creation, see the [resource deployment guide](/azure/ai-services/openai/how-to/create-resource).</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="st">-- For Vision enhancement (optional): An Azure Computer Vision resource in the same region as your Azure OpenAI resource, in the paid (S1) tier.</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a> &gt; [!NOTE]</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a> &gt; It is currently not supported to turn off content filtering for the GPT-4 Turbo with Vision model.</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -40,7 +39,6 @@ Go to your resource in the Azure portal. On the navigation pane, select **Keys a</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a> Create a new Python file named _quickstart.py_. Open the new file in your preferred editor or IDE.</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Image prompts](#tab/image)</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a> 1. Replace the contents of _quickstart.py_ with the following code. </span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -99,101 +97,6 @@ Create a new Python file named _quickstart.py_. Open the new file in your prefer</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>     python quickstart.py</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>     ```</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Image prompt enhancements](#tab/enhanced)</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="st">-GPT-4 Turbo with Vision provides exclusive access to Azure AI Services tailored enhancements. When combined with Azure AI Vision, it enhances your chat experience by providing the chat model with more detailed information about visible text in the image and the locations of objects.</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="st">-The **Optical Character Recognition (OCR)** integration allows the model to produce higher quality responses for dense text, transformed images, and number-heavy financial documents. It also covers a wider range of languages.</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a><span class="st">-The **object grounding** integration brings a new layer to data analysis and user interaction, as the feature can visually distinguish and highlight important elements in the images it processes.</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!CAUTION]</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Azure AI enhancements for GPT-4 Turbo with Vision will be billed separately from the core functionalities. Each specific Azure AI enhancement for GPT-4 Turbo with Vision has its own distinct charges. For details, see the [special pricing information](../concepts/gpt-with-vision.md#special-pricing-information).</span></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Vision enhancements are not supported by the GPT-4 Turbo GA model. They are only available with the preview models.</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Replace the contents of _quickstart.py_ with the following code. </span></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```python</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a><span class="st">-    # Packages required:</span></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a><span class="st">-    import requests </span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a><span class="st">-    import json </span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a><span class="st">-    api_base = &#39;&lt;your_azure_openai_endpoint&gt;&#39; </span></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a><span class="st">-    deployment_name = &#39;&lt;your_deployment_name&gt;&#39;</span></span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a><span class="st">-    API_KEY = &#39;&lt;your_azure_openai_key&gt;&#39;</span></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a><span class="st">-    base_url = f&quot;{api_base}openai/deployments/{deployment_name}&quot; </span></span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a><span class="st">-    headers = {   </span></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;Content-Type&quot;: &quot;application/json&quot;,   </span></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;api-key&quot;: API_KEY </span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a><span class="st">-    } </span></span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a><span class="st">-    # Prepare endpoint, headers, and request body </span></span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a><span class="st">-    endpoint = f&quot;{base_url}/extensions/chat/completions?api-version=2023-12-01-preview&quot; </span></span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a><span class="st">-    data = {</span></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;model&quot;: &quot;gpt-4-vision-preview&quot;,</span></span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;enhancements&quot;: {</span></span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;ocr&quot;: {</span></span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a><span class="st">-              &quot;enabled&quot;: True</span></span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a><span class="st">-            },</span></span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;grounding&quot;: {</span></span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a><span class="st">-              &quot;enabled&quot;: True</span></span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a><span class="st">-        },</span></span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;dataSources&quot;: [</span></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a><span class="st">-        {</span></span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;type&quot;: &quot;AzureComputerVision&quot;,</span></span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;parameters&quot;: {</span></span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;endpoint&quot;: &quot;&lt;your_computer_vision_endpoint&gt;&quot;,</span></span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a><span class="st">-                &quot;key&quot;: &quot;&lt;your_computer_vision_key&gt;&quot;</span></span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a><span class="st">-            }</span></span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a><span class="st">-        }],</span></span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;messages&quot;: [ </span></span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a><span class="st">-            { &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot; }, </span></span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a><span class="st">-            { &quot;role&quot;: &quot;user&quot;, </span></span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a><span class="st">-            &quot;content&quot;: [  </span></span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a><span class="st">-                { </span></span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;type&quot;: &quot;text&quot;, </span></span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;text&quot;: &quot;Describe this picture:&quot; </span></span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a><span class="st">-                },</span></span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a><span class="st">-                { </span></span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;type&quot;: &quot;image_url&quot;, </span></span>
<span id="cb19-83"><a href="#cb19-83" aria-hidden="true" tabindex="-1"></a><span class="st">-                    &quot;image_url&quot;: {</span></span>
<span id="cb19-84"><a href="#cb19-84" aria-hidden="true" tabindex="-1"></a><span class="st">-                        &quot;url&quot; : &quot;&lt;image URL&gt;&quot;</span></span>
<span id="cb19-85"><a href="#cb19-85" aria-hidden="true" tabindex="-1"></a><span class="st">-                    }</span></span>
<span id="cb19-86"><a href="#cb19-86" aria-hidden="true" tabindex="-1"></a><span class="st">-                }</span></span>
<span id="cb19-87"><a href="#cb19-87" aria-hidden="true" tabindex="-1"></a><span class="st">-            ]} </span></span>
<span id="cb19-88"><a href="#cb19-88" aria-hidden="true" tabindex="-1"></a><span class="st">-        ], </span></span>
<span id="cb19-89"><a href="#cb19-89" aria-hidden="true" tabindex="-1"></a><span class="st">-        &quot;max_tokens&quot;: 2000 </span></span>
<span id="cb19-90"><a href="#cb19-90" aria-hidden="true" tabindex="-1"></a><span class="st">-    }   </span></span>
<span id="cb19-91"><a href="#cb19-91" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb19-92"><a href="#cb19-92" aria-hidden="true" tabindex="-1"></a><span class="st">-    # Make the API call   </span></span>
<span id="cb19-93"><a href="#cb19-93" aria-hidden="true" tabindex="-1"></a><span class="st">-    response = requests.post(endpoint, headers=headers, data=json.dumps(data))   </span></span>
<span id="cb19-94"><a href="#cb19-94" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-95"><a href="#cb19-95" aria-hidden="true" tabindex="-1"></a><span class="st">-    print(f&quot;Status Code: {response.status_code}&quot;)   </span></span>
<span id="cb19-96"><a href="#cb19-96" aria-hidden="true" tabindex="-1"></a><span class="st">-    print(response.text)</span></span>
<span id="cb19-97"><a href="#cb19-97" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```</span></span>
<span id="cb19-98"><a href="#cb19-98" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-99"><a href="#cb19-99" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Make the following changes:</span></span>
<span id="cb19-100"><a href="#cb19-100" aria-hidden="true" tabindex="-1"></a><span class="st">-    1. Enter your GPT-4 Turbo with Vision deployment name in the appropriate field. </span></span>
<span id="cb19-101"><a href="#cb19-101" aria-hidden="true" tabindex="-1"></a><span class="st">-    1. Enter your Computer Vision endpoint URL and key in the appropriate fields.</span></span>
<span id="cb19-102"><a href="#cb19-102" aria-hidden="true" tabindex="-1"></a><span class="st">-    1. Change the value of the `&quot;image&quot;` field to the URL of your image.</span></span>
<span id="cb19-103"><a href="#cb19-103" aria-hidden="true" tabindex="-1"></a><span class="st">-        &gt; [!TIP]</span></span>
<span id="cb19-104"><a href="#cb19-104" aria-hidden="true" tabindex="-1"></a><span class="st">-        &gt; You can also use a base 64 encoded image data instead of a URL. For more information, see the [GPT-4 Turbo with Vision how-to guide](../how-to/gpt-with-vision.md#use-a-local-image).</span></span>
<span id="cb19-105"><a href="#cb19-105" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Run the application with the `python` command:</span></span>
<span id="cb19-106"><a href="#cb19-106" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-107"><a href="#cb19-107" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```console</span></span>
<span id="cb19-108"><a href="#cb19-108" aria-hidden="true" tabindex="-1"></a><span class="st">-    python quickstart.py</span></span>
<span id="cb19-109"><a href="#cb19-109" aria-hidden="true" tabindex="-1"></a><span class="st">-    ```</span></span>
<span id="cb19-110"><a href="#cb19-110" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-111"><a href="#cb19-111" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Video prompt enhancements](#tab/video)</span></span>
<span id="cb19-112"><a href="#cb19-112" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-113"><a href="#cb19-113" aria-hidden="true" tabindex="-1"></a><span class="st">-Video prompt integration is outside the scope of this quickstart. See the [GPT-4 Turbo with Vision how-to guide](../how-to/gpt-with-vision.md#use-vision-enhancement-with-video) for detailed instructions on setting up video prompts in chat completions programmatically.</span></span>
<span id="cb19-114"><a href="#cb19-114" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb19-115"><a href="#cb19-115" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb19-116"><a href="#cb19-116" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb19-117"><a href="#cb19-117" aria-hidden="true" tabindex="-1"></a> ## Clean up resources</span>
<span id="cb19-118"><a href="#cb19-118" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-9">Summary</h3>
<div class="sourceCode" id="cb20"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;breaking change&quot;</span><span class="fu">,</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;GPT-4 Turbo with Visionに関するコンテンツの削除&quot;</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-9">Explanation</h3>
<p>この変更では、<code>gpt-v-rest.md</code>
ドキュメントから97行が削除され、GPT-4 Turbo with
Visionに関連する多くの情報が削除されました。主なポイントは以下の通りです。</p>
<ol class="incremental" type="1">
<li><p><strong>設定情報の削除</strong>:
ドキュメントの冒頭で必要とされていたリソース、ライブラリ、および設定手順が大幅に短縮され、ユーザーが初めに知っておくべき重要な情報が多く削除されました。</p></li>
<li><p><strong>画像プロンプトに関する詳細の削除</strong>: GPT-4 Turbo
with
Visionの利用に関する説明が削られ、特に画像に関連するプロンプト機能や、それに関連する強化機能（OCR、オブジェクトグラウンディング）についての詳しい情報が削除されました。これにより、ユーザーはこれらの機能の実装方法や使用方法についての具体的な情報を失ってしまいました。</p></li>
<li><p><strong>サンプルコードの完全な削除</strong>: REST
APIを利用してGPT-4 Turbo with
Visionを操作するための具体的なサンプルコードが完全に削除され、これによりユーザーがどのようにAPIを呼び出すべきかが全く示されなくなりました。</p></li>
<li><p><strong>ビデオプロンプトに関する情報の削除</strong>:
ビデオプロンプトに関する注記も削除され、関連する指示を提供する情報源が失われました。</p></li>
</ol>
<p>この変更により、ユーザーはGPT-4 Turbo with
Visionの機能を利用する際に必要な情報を得られず、実装やトラブルシューティングの段階で困難を感じる可能性が高まります。特に、機能が削除されたことによって、サービスの利用に対する理解が著しく制限されました。</p>
<h2
id="item-dcd50e">articles/ai-services/openai/includes/gpt-v-studio.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb21"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -16,7 +16,6 @@ Start exploring GPT-4 Turbo with Vision capabilities with a no-code approach thr</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a> - An Azure subscription. &lt;a href=&quot;https://azure.microsoft.com/free/ai-services&quot; target=&quot;_blank&quot;&gt;Create one for free&lt;/a&gt;.</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a> - An Azure OpenAI Service resource with a GPT-4 Turbo with Vision model deployed. See [GPT-4 and GPT-4 Turbo Preview model availability](../concepts/models.md#gpt-4-and-gpt-4-turbo-model-availability) for available regions. For more information about resource creation, see the [resource deployment guide](/azure/ai-services/openai/how-to/create-resource).</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="st">-- For Vision enhancement (optional): An Azure Computer Vision resource in the same region as your Azure OpenAI resource, in the paid (S1) tier.</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a> &gt; [!NOTE]</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a> &gt; It is currently not supported to turn off content filtering for the GPT-4 Turbo with Vision model.</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -53,66 +52,6 @@ In this chat session, you&#39;re instructing the assistant to aid in understanding i</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a> :::image type=&quot;content&quot; source=&quot;../media/quickstarts/studio-vision.png&quot; lightbox=&quot;../media/quickstarts/studio-vision.png&quot; alt-text=&quot;Screenshot of OpenAI studio chat playground.&quot;:::</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Image prompt enhancements](#tab/enhanced)</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="st">-GPT-4 Turbo with Vision provides exclusive access to Azure AI Services tailored enhancements. When combined with Azure AI Vision, it enhances your chat experience by providing the chat model with more detailed information about visible text in the image and the locations of objects.</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="st">-The **Optical Character Recognition (OCR)** integration allows the model to produce higher quality responses for dense text, transformed images, and number-heavy financial documents. It also covers a wider range of languages.</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="st">-The **object grounding** integration brings a new layer to data analysis and user interaction, as the feature can visually distinguish and highlight important elements in the images it processes.</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!CAUTION]</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Azure AI enhancements for GPT-4 Turbo with Vision will be billed separately from the core functionalities. Each specific Azure AI enhancement for GPT-4 Turbo with Vision has its own distinct charges. For details, see the [special pricing information](../concepts/gpt-with-vision.md#special-pricing-information).</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Vision enhancements are not supported by the GPT-4 Turbo GA model. They are only available with the preview models.</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="st">-In this chat session, you try out the capabilities of the enhanced Vision model.</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a><span class="st">-1. To start, select your GPT-4 Turbo with Vision deployment from the dropdown.</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="st">-1. In the **Configuration** tab on the right side of the chat experience, turn on the option for **Vision** under the **Enhancements** section.</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="st">-1. You&#39;re required to select a Computer Vision resource to try the enhanced Vision API. Select your resource, and **Save**. </span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="st">-1. In the **Assistant setup** pane, provide a System Message to guide the assistant. The default System Message is: &quot;You are an AI assistant that helps people find information.&quot; You can tailor the System Message to the image or scenario that you&#39;re uploading.  </span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a><span class="st">-    &gt; [!NOTE]</span></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a><span class="st">-    &gt; It is recommended to update the System Message to be specific to the task in order to avoid unhelpful responses from the model.</span></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Save your changes, and when prompted to confirm updating the system message, select **Continue**.</span></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a><span class="st">-1. In the **Chat session** pane, enter a text prompt like &quot;Describe this image,&quot; and upload an image with the attachment button. You can use a different text prompt for your use case. Then select **Send**.  </span></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a><span class="st">-1. You should receive a response with more detailed information about visible text in the image and the locations of objects. Consider asking follow-up questions related to the analysis of your image to learn more.</span></span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a><span class="st">-:::image type=&quot;content&quot; source=&quot;../media/quickstarts/studio-vision-enhanced.png&quot; lightbox=&quot;../media/quickstarts/studio-vision-enhanced.png&quot; alt-text=&quot;Screenshot of OpenAI studio chat playground with Enhancements turned on and the Computer Vision resource selection box.&quot;:::</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a><span class="st">-#### [Video prompt enhancements](#tab/video)</span></span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a><span class="st">-GPT-4 Turbo with Vision provides exclusive access to Azure AI Services tailored enhancements. The **video prompt** integration uses Azure AI Vision video retrieval to sample a set of frames from a video and create a transcript of the speech in the video. It enables the AI model to give summaries and answers about video content.</span></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!CAUTION]</span></span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Azure AI enhancements for GPT-4 Turbo with Vision will be billed separately from the core functionalities. Each specific Azure AI enhancement for GPT-4 Turbo with Vision has its own distinct charges. For details, see the [special pricing information](../concepts/gpt-with-vision.md#special-pricing-information).</span></span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Vision enhancements are not supported by the GPT-4 Turbo GA model. They are only available with the preview models.</span></span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a><span class="st">-1. To start, select your GPT-4 Turbo with Vision deployment from the dropdown.</span></span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a><span class="st">-1. In the **Configuration** tab on the right side of the chat experience, turn on the option for **Vision** under the **Enhancements** section.</span></span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a><span class="st">-1. You&#39;re required to select a Computer Vision resource to try the enhanced Vision API. Select your resource, and **Save**. </span></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a><span class="st">-1. In the **Assistant setup** pane, provide a System Message to guide the assistant. The default System Message is: &quot;You are an AI assistant that helps people find information.&quot; You can tailor the System Message to the video or scenario that you&#39;re uploading.  </span></span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a><span class="st">-    &gt; [!NOTE]</span></span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a><span class="st">-    &gt; It is recommended to update the System Message to be specific to the task in order to avoid unhelpful responses from the model.</span></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a><span class="st">-    </span></span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Save your changes, and when prompted to confirm updating the system message, select **Continue**.</span></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a><span class="st">-1. In the chat session pane, enter a question about the video like: &quot;Describe this video in detail. Focus on brands, technology and people.&quot; You can use a different text prompt for your use case. Upload a video using the attachment button and then select **Send**. </span></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a><span class="st">-    &gt; [!NOTE]</span></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a><span class="st">-    &gt; Currently the chat playground only supports videos that are less than 3 minutes long.</span></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a><span class="st">-1. You should receive a response describing the video. Consider asking follow-up questions related to the analysis of your video to learn more.</span></span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a><span class="st">-:::image type=&quot;content&quot; source=&quot;../media/quickstarts/studio-vision-enhanced-video.png&quot; alt-text=&quot;Screenshot of OpenAI studio chat playground with Enhancements turned on and the Computer Vision resource selection box. Video-specific text prompt.&quot; lightbox=&quot;../media/quickstarts/studio-vision-enhanced-video.png&quot;:::</span></span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a> ## Clean up resources</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-10">Summary</h3>
<div class="sourceCode" id="cb22"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;breaking change&quot;</span><span class="fu">,</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;GPT-4 Turbo with Visionに関する詳細の削除&quot;</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-10">Explanation</h3>
<p>このコードの変更では、<code>gpt-v-studio.md</code>
ドキュメントから61行が削除され、特にGPT-4 Turbo with
Visionの機能に関連する詳細が削除されました。主要なポイントは以下の通りです。</p>
<ol class="incremental" type="1">
<li><p><strong>設定要件の削除</strong>: GPT-4 Turbo with
Visionを使用するために必要なリソースの情報が削除され、ユーザーが必要とする環境設定に関する情報が欠けることになりました。</p></li>
<li><p><strong>画像プロンプトとその強化機能の削除</strong>:
画像プロンプトに関する説明や、Optical Character
Recognition（OCR）やオブジェクトグラウンディングなどの強化機能に関する重要な情報が削除されました。このことは、ユーザーがどのようにこれらの機能を活用できるかを理解する上での障害となります。</p></li>
<li><p><strong>具体的な手順の削除</strong>:
チャットセッション内での操作手順、特にシステムメッセージの設定や詳細なプロンプトの入力手順が削除され、ユーザーが機能を試すための具体的なガイドラインが失われました。</p></li>
<li><p><strong>ビデオプロンプトに関する情報の削除</strong>:
ビデオプロンプトの統合に関する情報とその利用方法が削除されたため、同様の機能についての理解が制限されました。</p></li>
</ol>
<p>この変更により、GPT-4 Turbo with
Visionの利用に関する具体的なガイダンスが大幅に減少し、ユーザーがこれらの機能を利用する際の知識と手順が不足する可能性があります。この結果、ユーザーの体験や実装の際の苦労が増加することが予想されます。</p>
<h2
id="item-e9b653">articles/ai-services/openai/includes/text-to-speech-javascript.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb23"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -0,0 +1,247 @@</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: include</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="va">+manager: nitinme</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.service: azure-ai-openai</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: include</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/12/2024</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.reviewer: v-baolianzou</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.author: eur</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="va">+author: eric-urban</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="va">+recommendations: false</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="va">+[Source code](https://github.com/openai/openai-node) | [Package (npm)](https://www.npmjs.com/package/openai) | [Samples](https://github.com/Azure/azure-sdk-for-js/tree/main/sdk/openai/openai/samples)</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="va">+## Prerequisites</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="va">+#### [JavaScript](#tab/javascript)</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true)</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="va">+- [LTS versions of Node.js](https://github.com/nodejs/release#release-schedule)</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI resource created in a supported region (see [Region availability](/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability)). For more information, see [Create a resource and deploy a model with Azure OpenAI](../how-to/create-resource.md).</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="va">+#### [TypeScript](#tab/typescript)</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true)</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="va">+- [LTS versions of Node.js](https://github.com/nodejs/release#release-schedule)</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="va">+- [TypeScript](https://www.typescriptlang.org/download/)</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI resource created in a supported region (see [Region availability](/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability)). For more information, see [Create a resource and deploy a model with Azure OpenAI](../how-to/create-resource.md).</span></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a><span class="va">+## Set up</span></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a><span class="va">+### Retrieve key and endpoint</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a><span class="va">+To successfully make a call against Azure OpenAI, you need an **endpoint** and a **key**.</span></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a><span class="va">+|Variable name | Value |</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="va">+|--------------------------|-------------|</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_ENDPOINT`               | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in the **Azure OpenAI Studio** &gt; **Playground** &gt; **Code View**. An example endpoint is: `https://aoai-docs.openai.azure.com/`.|</span></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_API_KEY` | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|</span></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a><span class="va">+Go to your resource in the Azure portal. The **Endpoint and Keys** can be found in the **Resource Management** section. Copy your endpoint and access key as you need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a><span class="va">+:::image type=&quot;content&quot; source=&quot;../media/quickstarts/endpoint.png&quot; alt-text=&quot;Screenshot of the overview UI for an Azure OpenAI resource in the Azure portal with the endpoint &amp; access keys location highlighted.&quot; lightbox=&quot;../media/quickstarts/endpoint.png&quot;:::</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a><span class="va">+### Environment variables</span></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a><span class="va">+Create and assign persistent environment variables for your key and endpoint.</span></span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Azure key vault](~/reusable-content/ce-skilling/azure/includes/ai-services/security/azure-key-vault.md)]</span></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Command Line](#tab/command-line)</span></span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_API_KEY &quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; </span></span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_ENDPOINT &quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; </span></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a><span class="va">+# [PowerShell](#tab/powershell)</span></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_API_KEY&#39;, &#39;REPLACE_WITH_YOUR_KEY_VALUE_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_ENDPOINT&#39;, &#39;REPLACE_WITH_YOUR_ENDPOINT_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Bash](#tab/bash)</span></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_API_KEY=&quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a Node application</span></span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a><span class="va">+In a console window (such as cmd, PowerShell, or Bash), create a new directory for your app, and navigate to it. Then run the `npm init` command to create a node application with a _package.json_ file.</span></span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a><span class="va">+```console</span></span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a><span class="va">+npm init</span></span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a><span class="va">+## Install the client library</span></span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a><span class="va">+Install the client libraries with:</span></span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a><span class="va">+```console</span></span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a><span class="va">+npm install openai @azure/identity</span></span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a><span class="va">+Your app&#39;s _package.json_ file will be updated with the dependencies.</span></span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a speech file</span></span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a><span class="va">+#### [JavaScript](#tab/javascript)</span></span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Create a new file named _Text-to-speech.js_ and open it in your preferred code editor. Copy the following code into the _Text-to-speech.js_ file:</span></span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```javascript</span></span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a><span class="va">+    require(&quot;dotenv/config&quot;);</span></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a><span class="va">+    const { writeFile } = require(&quot;fs/promises&quot;);</span></span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a><span class="va">+    const { AzureOpenAI } = require(&quot;openai&quot;);</span></span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a><span class="va">+    require(&quot;openai/shims/node&quot;);</span></span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a><span class="va">+    // You will need to set these environment variables or edit the following values</span></span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a><span class="va">+    const endpoint = process.env[&quot;AZURE_OPENAI_ENDPOINT&quot;] || &quot;&lt;endpoint&gt;&quot;;</span></span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a><span class="va">+    const apiKey = process.env[&quot;AZURE_OPENAI_API_KEY&quot;] || &quot;&lt;api key&gt;&quot;;</span></span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a><span class="va">+    const speechFilePath =</span></span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a><span class="va">+      process.env[&quot;SPEECH_FILE_PATH&quot;] || &quot;&lt;path to save the speech file&gt;&quot;;</span></span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a><span class="va">+    // Required Azure OpenAI deployment name and API version</span></span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a><span class="va">+    const deploymentName = &quot;tts&quot;;</span></span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a><span class="va">+    const apiVersion = &quot;2024-08-01-preview&quot;;</span></span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a><span class="va">+    function getClient() {</span></span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a><span class="va">+      return new AzureOpenAI({</span></span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a><span class="va">+        endpoint,</span></span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a><span class="va">+        apiKey,</span></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a><span class="va">+        apiVersion,</span></span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a><span class="va">+        deployment: deploymentName,</span></span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a><span class="va">+      });</span></span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a><span class="va">+    async function generateAudioStream(</span></span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a><span class="va">+      client,</span></span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a><span class="va">+      params</span></span>
<span id="cb23-142"><a href="#cb23-142" aria-hidden="true" tabindex="-1"></a><span class="va">+    ) {</span></span>
<span id="cb23-143"><a href="#cb23-143" aria-hidden="true" tabindex="-1"></a><span class="va">+      const response = await client.audio.speech.create(params);</span></span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a><span class="va">+      if (response.ok) return response.body;</span></span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a><span class="va">+      throw new Error(`Failed to generate audio stream: ${response.statusText}`);</span></span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a><span class="va">+    export async function main() {</span></span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(&quot;== Text to Speech Sample ==&quot;);</span></span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a><span class="va">+      const client = getClient();</span></span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a><span class="va">+      const streamToRead = await generateAudioStream(client, {</span></span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a><span class="va">+        model: deploymentName,</span></span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a><span class="va">+        voice: &quot;alloy&quot;,</span></span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a><span class="va">+        input: &quot;the quick brown chicken jumped over the lazy dogs&quot;,</span></span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a><span class="va">+      });</span></span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(`Streaming response to ${speechFilePath}`);</span></span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a><span class="va">+      await writeFile(speechFilePath, streamToRead);</span></span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(&quot;Finished streaming&quot;);</span></span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a><span class="va">+    main().catch((err) =&gt; {</span></span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.error(&quot;The sample encountered an error:&quot;, err);</span></span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a><span class="va">+    });</span></span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Run the script with the following command:</span></span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```console</span></span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a><span class="va">+    node Text-to-speech.js</span></span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb23-173"><a href="#cb23-173" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-174"><a href="#cb23-174" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a><span class="va">+#### [TypeScript](#tab/typescript)</span></span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Create a new file named _Text-to-speech.ts_ and open it in your preferred code editor. Copy the following code into the _Text-to-speech.ts_ file:</span></span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```typescript</span></span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a><span class="va">+    import &quot;dotenv/config&quot;;</span></span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a><span class="va">+    import { writeFile } from &quot;fs/promises&quot;;</span></span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a><span class="va">+    import { AzureOpenAI } from &quot;openai&quot;;</span></span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a><span class="va">+    import type { SpeechCreateParams } from &quot;openai/resources/audio/speech&quot;;</span></span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a><span class="va">+    import &quot;openai/shims/node&quot;;</span></span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a><span class="va">+    // You will need to set these environment variables or edit the following values</span></span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a><span class="va">+    const endpoint = process.env[&quot;AZURE_OPENAI_ENDPOINT&quot;] || &quot;&lt;endpoint&gt;&quot;;</span></span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a><span class="va">+    const apiKey = process.env[&quot;AZURE_OPENAI_API_KEY&quot;] || &quot;&lt;api key&gt;&quot;;</span></span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a><span class="va">+    const speechFilePath =</span></span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a><span class="va">+      process.env[&quot;SPEECH_FILE_PATH&quot;] || &quot;&lt;path to save the speech file&gt;&quot;;</span></span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a><span class="va">+    // Required Azure OpenAI deployment name and API version</span></span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a><span class="va">+    const deploymentName = &quot;tts&quot;;</span></span>
<span id="cb23-194"><a href="#cb23-194" aria-hidden="true" tabindex="-1"></a><span class="va">+    const apiVersion = &quot;2024-08-01-preview&quot;;</span></span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a><span class="va">+    function getClient(): AzureOpenAI {</span></span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a><span class="va">+      return new AzureOpenAI({</span></span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a><span class="va">+        endpoint,</span></span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a><span class="va">+        apiKey,</span></span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a><span class="va">+        apiVersion,</span></span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a><span class="va">+        deployment: deploymentName,</span></span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a><span class="va">+      });</span></span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a><span class="va">+    async function generateAudioStream(</span></span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a><span class="va">+      client: AzureOpenAI,</span></span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a><span class="va">+      params: SpeechCreateParams</span></span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a><span class="va">+    ): Promise&lt;NodeJS.ReadableStream&gt; {</span></span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a><span class="va">+      const response = await client.audio.speech.create(params);</span></span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a><span class="va">+      if (response.ok) return response.body;</span></span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a><span class="va">+      throw new Error(`Failed to generate audio stream: ${response.statusText}`);</span></span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a><span class="va">+    export async function main() {</span></span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(&quot;== Text to Speech Sample ==&quot;);</span></span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a><span class="va">+      const client = getClient();</span></span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a><span class="va">+      const streamToRead = await generateAudioStream(client, {</span></span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a><span class="va">+        model: deploymentName,</span></span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a><span class="va">+        voice: &quot;alloy&quot;,</span></span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a><span class="va">+        input: &quot;the quick brown chicken jumped over the lazy dogs&quot;,</span></span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a><span class="va">+      });</span></span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(`Streaming response to ${speechFilePath}`);</span></span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a><span class="va">+      await writeFile(speechFilePath, streamToRead);</span></span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(&quot;Finished streaming&quot;);</span></span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a><span class="va">+    main().catch((err) =&gt; {</span></span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.error(&quot;The sample encountered an error:&quot;, err);</span></span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a><span class="va">+    });</span></span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-232"><a href="#cb23-232" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb23-233"><a href="#cb23-233" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a><span class="va">+   The import of `&quot;openai/shims/node&quot;` is necessary when running the code in a Node.js environment. It ensures that the output type of the `client.audio.speech.create` method is correctly set to `NodeJS.ReadableStream`.</span></span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Build the application with the following command:</span></span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-238"><a href="#cb23-238" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```console</span></span>
<span id="cb23-239"><a href="#cb23-239" aria-hidden="true" tabindex="-1"></a><span class="va">+    tsc</span></span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Run the application with the following command:</span></span>
<span id="cb23-243"><a href="#cb23-243" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-244"><a href="#cb23-244" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```console</span></span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a><span class="va">+    node Text-to-speech.js</span></span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb23-247"><a href="#cb23-247" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb23-248"><a href="#cb23-248" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb23-249"><a href="#cb23-249" aria-hidden="true" tabindex="-1"></a>\ No newline at end of file</span></code></pre></div>
</details>
<h3 id="summary-11">Summary</h3>
<div class="sourceCode" id="cb24"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;JavaScript用のテキストから音声への変換ガイドの追加&quot;</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-11">Explanation</h3>
<p>このコードの変更では、<code>text-to-speech-javascript.md</code>
ファイルが新たに追加され、247行の内容が含まれています。このドキュメントは、JavaScriptおよびTypeScript環境でのAzure
OpenAIのテキストから音声への変換機能の利用方法について詳しく説明しています。</p>
<ol class="incremental" type="1">
<li><p><strong>前提条件の明示</strong>:
Azureのサブスクリプション、Node.jsのLTS版、そしてAzure
OpenAIリソースの設定に関する情報が含まれています。これにより、ユーザーは必要な設定を事前に行うことができます。</p></li>
<li><p><strong>キーおよびエンドポイントの取得</strong>: Azure
OpenAIを呼び出すために必要なエンドポイントとキーの取得方法が説明されており、具体的な値をどのように見つけるかを示しています。</p></li>
<li><p><strong>環境変数の設定</strong>:
キーとエンドポイントを環境変数として設定する手順が説明され、これにより安全に情報を管理できます。</p></li>
<li><p><strong>Node.jsアプリケーションの作成</strong>:
新しいNodeアプリケーションを作成する手順が説明されています。<code>npm init</code>を使用してプロジェクトを初期化し、必要なパッケージをインストールする方法が示されています。</p></li>
<li><p><strong>音声ファイルの生成</strong>:
JavaScriptおよびTypeScriptのサンプルコードが提供されており、具体的なコードを用いてテキストから音声への変換を実行する方法が詳述されています。この部分は、ユーザーが具体的な実装を行いやすくするための重要な要素です。</p></li>
<li><p><strong>エラー処理</strong>:
サンプルコードではエラー処理の部分も含まれ、実行時に発生する可能性のあるエラーにどのように対処するかが述べられています。</p></li>
</ol>
<p>この新しいドキュメントにより、JavaScriptやTypeScriptを使用する開発者がAzure
OpenAIを用いて音声機能を実装するための具体的なステップとリソースが提供され、開発プロセスが大幅に簡素化されます。</p>
<h2
id="item-d067a1">articles/ai-services/openai/includes/text-to-speech-rest.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb25"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -10,7 +10,65 @@ author: eric-urban</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a> recommendations: false</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="st">-## REST API</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="va">+## Prerequisites</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true).</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI resource created in the North Central US or Sweden Central regions with the `tts-1` or `tts-1-hd` model deployed. For more information, see [Create a resource and deploy a model with Azure OpenAI](../how-to/create-resource.md).</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="va">+## Set up</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="va">+### Retrieve key and endpoint</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="va">+To successfully make a call against Azure OpenAI, you need an **endpoint** and a **key**.</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="va">+|Variable name | Value |</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="va">+|--------------------------|-------------|</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_ENDPOINT`               | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in the **Azure OpenAI Studio** &gt; **Playground** &gt; **Code View**. An example endpoint is: `https://aoai-docs.openai.azure.com/`.|</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_API_KEY` | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="va">+Go to your resource in the Azure portal. The **Endpoint and Keys** can be found in the **Resource Management** section. Copy your endpoint and access key as you need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a><span class="va">+:::image type=&quot;content&quot; source=&quot;../media/quickstarts/endpoint.png&quot; alt-text=&quot;Screenshot of the overview UI for an Azure OpenAI resource in the Azure portal with the endpoint &amp; access keys location highlighted.&quot; lightbox=&quot;../media/quickstarts/endpoint.png&quot;:::</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a><span class="va">+### Environment variables</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a><span class="va">+Create and assign persistent environment variables for your key and endpoint.</span></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Azure key vault](~/reusable-content/ce-skilling/azure/includes/ai-services/security/azure-key-vault.md)]</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Command Line](#tab/command-line)</span></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_API_KEY &quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; </span></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_ENDPOINT &quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; </span></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a><span class="va">+# [PowerShell](#tab/powershell)</span></span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_API_KEY&#39;, &#39;REPLACE_WITH_YOUR_KEY_VALUE_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_ENDPOINT&#39;, &#39;REPLACE_WITH_YOUR_ENDPOINT_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Bash](#tab/bash)</span></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_API_KEY=&quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a REST request and response</span></span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a> In a bash shell, run the following command. You need to replace `YourDeploymentName` with the deployment name you chose when you deployed the text to speech model. The deployment name isn&#39;t necessarily the same as the model name. Entering the model name results in an error unless you chose a deployment name that is identical to the underlying model name.</span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-12">Summary</h3>
<div class="sourceCode" id="cb26"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;REST APIの事前条件とセットアップ手順の拡充&quot;</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-12">Explanation</h3>
<p>このコードの変更では、<code>text-to-speech-rest.md</code>
ファイルに対して59行が追加され、1行が削除されています。この変更は、REST
APIの使用に関する事前条件とセットアップ手順の詳細を明記しています。</p>
<ol class="incremental" type="1">
<li><p><strong>事前条件の追加</strong>:
ユーザーが音声合成機能を利用するための条件として、Azureのサブスクリプションと特定の地域にデプロイされたAzure
OpenAIリソースの作成を明示しています。</p></li>
<li><p><strong>キーおよびエンドポイントの取得手順</strong>: Azure
OpenAIを呼び出すために必要なエンドポイントとAPIキーの取得方法についての詳細が追加されています。これには、Azureポータルでの利用方法や、エンドポイントとキーがどこに表示されるかについての具体的な説明が含まれています。</p></li>
<li><p><strong>環境変数の設定手順</strong>:
環境変数を設定するためのコマンドライン、PowerShell、Bashにおける具体的なコマンドが追加されており、ユーザーが自身の環境で設定を行う際の手助けとなる内容が充実しています。</p></li>
<li><p><strong>RESTリクエストとレスポンスの作成</strong>:
音声合成モデルのデプロイ名に関する注意事項が記載され、モデル名とデプロイ名の違いについての理解を促進しています。</p></li>
</ol>
<p>これにより、ユーザーはAzure
OpenAIのテキストから音声への変換機能を使用するために必要な準備作業をより明確に理解できるようになります。この変更は、技術ドキュメントの使いやすさと有用性を向上させることを目的としています。</p>
<h2
id="item-3ee990">articles/ai-services/openai/includes/whisper-javascript.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb27"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -0,0 +1,235 @@</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: include</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="va">+manager: nitinme</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.service: azure-ai-openai</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: include</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 9/12/2024</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.reviewer: v-baolianzou</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.author: eur</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="va">+author: eric-urban</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="va">+[Source code](https://github.com/openai/openai-node) | [Package (npm)](https://www.npmjs.com/package/openai) | [Samples](https://github.com/Azure/azure-sdk-for-js/tree/main/sdk/openai/openai/samples)</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="va">+## Prerequisites</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="va">+#### [JavaScript](#tab/javascript)</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true)</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="va">+- [LTS versions of Node.js](https://github.com/nodejs/release#release-schedule)</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI resource created in a supported region (see [Region availability](/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability)). For more information, see [Create a resource and deploy a model with Azure OpenAI](../how-to/create-resource.md).</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="va">+#### [TypeScript](#tab/typescript)</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true)</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="va">+- [LTS versions of Node.js](https://github.com/nodejs/release#release-schedule)</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span class="va">+- [TypeScript](https://www.typescriptlang.org/download/)</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI resource created in a supported region (see [Region availability](/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability)). For more information, see [Create a resource and deploy a model with Azure OpenAI](../how-to/create-resource.md).</span></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a><span class="va">+## Set up</span></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a><span class="va">+### Retrieve key and endpoint</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a><span class="va">+To successfully make a call against Azure OpenAI, you need an *endpoint* and a *key*.</span></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a><span class="va">+|Variable name | Value |</span></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a><span class="va">+|--------------------------|-------------|</span></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_ENDPOINT`               | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in the **Azure OpenAI Studio** &gt; **Playground** &gt; **Code View**. An example endpoint is: `https://aoai-docs.openai.azure.com/`.|</span></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_API_KEY` | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|</span></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a><span class="va">+Go to your resource in the Azure portal. The **Endpoint and Keys** can be found in the **Resource Management** section. Copy your endpoint and access key as you&#39;ll need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.</span></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a><span class="va">+:::image type=&quot;content&quot; source=&quot;../media/quickstarts/endpoint.png&quot; alt-text=&quot;Screenshot of the overview UI for an Azure OpenAI resource in the Azure portal with the endpoint &amp; access keys location circled in red.&quot; lightbox=&quot;../media/quickstarts/endpoint.png&quot;:::</span></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a><span class="va">+### Environment variables</span></span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a><span class="va">+Create and assign persistent environment variables for your key and endpoint.</span></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Azure key vault](~/reusable-content/ce-skilling/azure/includes/ai-services/security/azure-key-vault.md)]</span></span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Command Line](#tab/command-line)</span></span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_API_KEY &quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; </span></span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_ENDPOINT &quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; </span></span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a><span class="va">+# [PowerShell](#tab/powershell)</span></span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_API_KEY&#39;, &#39;REPLACE_WITH_YOUR_KEY_VALUE_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_ENDPOINT&#39;, &#39;REPLACE_WITH_YOUR_ENDPOINT_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Bash](#tab/bash)</span></span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_API_KEY=&quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb27-81"><a href="#cb27-81" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb27-82"><a href="#cb27-82" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-83"><a href="#cb27-83" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb27-84"><a href="#cb27-84" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb27-85"><a href="#cb27-85" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb27-86"><a href="#cb27-86" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb27-87"><a href="#cb27-87" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-88"><a href="#cb27-88" aria-hidden="true" tabindex="-1"></a><span class="va">+## Passwordless authentication is recommended</span></span>
<span id="cb27-89"><a href="#cb27-89" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-90"><a href="#cb27-90" aria-hidden="true" tabindex="-1"></a><span class="va">+For passwordless authentication, you need to </span></span>
<span id="cb27-91"><a href="#cb27-91" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-92"><a href="#cb27-92" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Use the `@azure/identity` package.</span></span>
<span id="cb27-93"><a href="#cb27-93" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Assign the `Cognitive Services User` role to your user account. This can be done in the Azure portal under **Access control (IAM)** &gt; **Add role assignment**.</span></span>
<span id="cb27-94"><a href="#cb27-94" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Sign in with the Azure CLI such as `az login`.</span></span>
<span id="cb27-95"><a href="#cb27-95" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-96"><a href="#cb27-96" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a Node application</span></span>
<span id="cb27-97"><a href="#cb27-97" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-98"><a href="#cb27-98" aria-hidden="true" tabindex="-1"></a><span class="va">+In a console window (such as cmd, PowerShell, or Bash), create a new directory for your app, and navigate to it. Then run the `npm init` command to create a node application with a _package.json_ file.</span></span>
<span id="cb27-99"><a href="#cb27-99" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-100"><a href="#cb27-100" aria-hidden="true" tabindex="-1"></a><span class="va">+```console</span></span>
<span id="cb27-101"><a href="#cb27-101" aria-hidden="true" tabindex="-1"></a><span class="va">+npm init</span></span>
<span id="cb27-102"><a href="#cb27-102" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb27-103"><a href="#cb27-103" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-104"><a href="#cb27-104" aria-hidden="true" tabindex="-1"></a><span class="va">+## Install the client library</span></span>
<span id="cb27-105"><a href="#cb27-105" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-106"><a href="#cb27-106" aria-hidden="true" tabindex="-1"></a><span class="va">+Install the client libraries with:</span></span>
<span id="cb27-107"><a href="#cb27-107" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-108"><a href="#cb27-108" aria-hidden="true" tabindex="-1"></a><span class="va">+```console</span></span>
<span id="cb27-109"><a href="#cb27-109" aria-hidden="true" tabindex="-1"></a><span class="va">+npm install openai @azure/identity</span></span>
<span id="cb27-110"><a href="#cb27-110" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb27-111"><a href="#cb27-111" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-112"><a href="#cb27-112" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb27-113"><a href="#cb27-113" aria-hidden="true" tabindex="-1"></a><span class="va">+Your app&#39;s _package.json_ file will be updated with the dependencies.</span></span>
<span id="cb27-114"><a href="#cb27-114" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-115"><a href="#cb27-115" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a sample application</span></span>
<span id="cb27-116"><a href="#cb27-116" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-117"><a href="#cb27-117" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-118"><a href="#cb27-118" aria-hidden="true" tabindex="-1"></a><span class="va">+#### [JavaScript](#tab/javascript)</span></span>
<span id="cb27-119"><a href="#cb27-119" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-120"><a href="#cb27-120" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Create a new file named _Whisper.js_ and open it in your preferred code editor. Copy the following code into the _Whisper.js_ file:</span></span>
<span id="cb27-121"><a href="#cb27-121" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-122"><a href="#cb27-122" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```javascript</span></span>
<span id="cb27-123"><a href="#cb27-123" aria-hidden="true" tabindex="-1"></a><span class="va">+    require(&quot;dotenv/config&quot;);</span></span>
<span id="cb27-124"><a href="#cb27-124" aria-hidden="true" tabindex="-1"></a><span class="va">+    const { createReadStream } = require(&quot;fs&quot;);</span></span>
<span id="cb27-125"><a href="#cb27-125" aria-hidden="true" tabindex="-1"></a><span class="va">+    const { AzureOpenAI } = require(&quot;openai&quot;);</span></span>
<span id="cb27-126"><a href="#cb27-126" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-127"><a href="#cb27-127" aria-hidden="true" tabindex="-1"></a><span class="va">+    // You will need to set these environment variables or edit the following values</span></span>
<span id="cb27-128"><a href="#cb27-128" aria-hidden="true" tabindex="-1"></a><span class="va">+    const audioFilePath = process.env[&quot;AUDIO_FILE_PATH&quot;] || &quot;&lt;audio file path&gt;&quot;;</span></span>
<span id="cb27-129"><a href="#cb27-129" aria-hidden="true" tabindex="-1"></a><span class="va">+    const endpoint = process.env[&quot;AZURE_OPENAI_ENDPOINT&quot;] || &quot;&lt;endpoint&gt;&quot;;</span></span>
<span id="cb27-130"><a href="#cb27-130" aria-hidden="true" tabindex="-1"></a><span class="va">+    const apiKey = process.env[&quot;AZURE_OPENAI_API_KEY&quot;] || &quot;&lt;api key&gt;&quot;;</span></span>
<span id="cb27-131"><a href="#cb27-131" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-132"><a href="#cb27-132" aria-hidden="true" tabindex="-1"></a><span class="va">+    // Required Azure OpenAI deployment name and API version</span></span>
<span id="cb27-133"><a href="#cb27-133" aria-hidden="true" tabindex="-1"></a><span class="va">+    const apiVersion = &quot;2024-08-01-preview&quot;;</span></span>
<span id="cb27-134"><a href="#cb27-134" aria-hidden="true" tabindex="-1"></a><span class="va">+    const deploymentName = &quot;whisper&quot;;</span></span>
<span id="cb27-135"><a href="#cb27-135" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-136"><a href="#cb27-136" aria-hidden="true" tabindex="-1"></a><span class="va">+    function getClient() {</span></span>
<span id="cb27-137"><a href="#cb27-137" aria-hidden="true" tabindex="-1"></a><span class="va">+      return new AzureOpenAI({</span></span>
<span id="cb27-138"><a href="#cb27-138" aria-hidden="true" tabindex="-1"></a><span class="va">+        endpoint,</span></span>
<span id="cb27-139"><a href="#cb27-139" aria-hidden="true" tabindex="-1"></a><span class="va">+        apiKey,</span></span>
<span id="cb27-140"><a href="#cb27-140" aria-hidden="true" tabindex="-1"></a><span class="va">+        apiVersion,</span></span>
<span id="cb27-141"><a href="#cb27-141" aria-hidden="true" tabindex="-1"></a><span class="va">+        deployment: deploymentName,</span></span>
<span id="cb27-142"><a href="#cb27-142" aria-hidden="true" tabindex="-1"></a><span class="va">+      });</span></span>
<span id="cb27-143"><a href="#cb27-143" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb27-144"><a href="#cb27-144" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-145"><a href="#cb27-145" aria-hidden="true" tabindex="-1"></a><span class="va">+    export async function main() {</span></span>
<span id="cb27-146"><a href="#cb27-146" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(&quot;== Transcribe Audio Sample ==&quot;);</span></span>
<span id="cb27-147"><a href="#cb27-147" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-148"><a href="#cb27-148" aria-hidden="true" tabindex="-1"></a><span class="va">+      const client = getClient();</span></span>
<span id="cb27-149"><a href="#cb27-149" aria-hidden="true" tabindex="-1"></a><span class="va">+      const result = await client.audio.transcriptions.create({</span></span>
<span id="cb27-150"><a href="#cb27-150" aria-hidden="true" tabindex="-1"></a><span class="va">+        model: &quot;&quot;,</span></span>
<span id="cb27-151"><a href="#cb27-151" aria-hidden="true" tabindex="-1"></a><span class="va">+        file: createReadStream(audioFilePath),</span></span>
<span id="cb27-152"><a href="#cb27-152" aria-hidden="true" tabindex="-1"></a><span class="va">+      });</span></span>
<span id="cb27-153"><a href="#cb27-153" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-154"><a href="#cb27-154" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(`Transcription: ${result.text}`);</span></span>
<span id="cb27-155"><a href="#cb27-155" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb27-156"><a href="#cb27-156" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-157"><a href="#cb27-157" aria-hidden="true" tabindex="-1"></a><span class="va">+    main().catch((err) =&gt; {</span></span>
<span id="cb27-158"><a href="#cb27-158" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.error(&quot;The sample encountered an error:&quot;, err);</span></span>
<span id="cb27-159"><a href="#cb27-159" aria-hidden="true" tabindex="-1"></a><span class="va">+    });</span></span>
<span id="cb27-160"><a href="#cb27-160" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb27-161"><a href="#cb27-161" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-162"><a href="#cb27-162" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Run the script with the following command:</span></span>
<span id="cb27-163"><a href="#cb27-163" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-164"><a href="#cb27-164" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```console</span></span>
<span id="cb27-165"><a href="#cb27-165" aria-hidden="true" tabindex="-1"></a><span class="va">+    node Whisper.js</span></span>
<span id="cb27-166"><a href="#cb27-166" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb27-167"><a href="#cb27-167" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-168"><a href="#cb27-168" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-169"><a href="#cb27-169" aria-hidden="true" tabindex="-1"></a><span class="va">+#### [TypeScript](#tab/typescript)</span></span>
<span id="cb27-170"><a href="#cb27-170" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-171"><a href="#cb27-171" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Create a new file named _Whisper.js_ and open it in your preferred code editor. Copy the following code into the _Whisper.js_ file:</span></span>
<span id="cb27-172"><a href="#cb27-172" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-173"><a href="#cb27-173" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```typescript</span></span>
<span id="cb27-174"><a href="#cb27-174" aria-hidden="true" tabindex="-1"></a><span class="va">+    import &quot;dotenv/config&quot;;</span></span>
<span id="cb27-175"><a href="#cb27-175" aria-hidden="true" tabindex="-1"></a><span class="va">+    import { createReadStream } from &quot;fs&quot;;</span></span>
<span id="cb27-176"><a href="#cb27-176" aria-hidden="true" tabindex="-1"></a><span class="va">+    import { AzureOpenAI } from &quot;openai&quot;;</span></span>
<span id="cb27-177"><a href="#cb27-177" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-178"><a href="#cb27-178" aria-hidden="true" tabindex="-1"></a><span class="va">+    // You will need to set these environment variables or edit the following values</span></span>
<span id="cb27-179"><a href="#cb27-179" aria-hidden="true" tabindex="-1"></a><span class="va">+    const audioFilePath = process.env[&quot;AUDIO_FILE_PATH&quot;] || &quot;&lt;audio file path&gt;&quot;;</span></span>
<span id="cb27-180"><a href="#cb27-180" aria-hidden="true" tabindex="-1"></a><span class="va">+    const endpoint = process.env[&quot;AZURE_OPENAI_ENDPOINT&quot;] || &quot;&lt;endpoint&gt;&quot;;</span></span>
<span id="cb27-181"><a href="#cb27-181" aria-hidden="true" tabindex="-1"></a><span class="va">+    const apiKey = process.env[&quot;AZURE_OPENAI_API_KEY&quot;] || &quot;&lt;api key&gt;&quot;;</span></span>
<span id="cb27-182"><a href="#cb27-182" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-183"><a href="#cb27-183" aria-hidden="true" tabindex="-1"></a><span class="va">+    // Required Azure OpenAI deployment name and API version</span></span>
<span id="cb27-184"><a href="#cb27-184" aria-hidden="true" tabindex="-1"></a><span class="va">+    const apiVersion = &quot;2024-08-01-preview&quot;;</span></span>
<span id="cb27-185"><a href="#cb27-185" aria-hidden="true" tabindex="-1"></a><span class="va">+    const deploymentName = &quot;whisper&quot;;</span></span>
<span id="cb27-186"><a href="#cb27-186" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-187"><a href="#cb27-187" aria-hidden="true" tabindex="-1"></a><span class="va">+    function getClient(): AzureOpenAI {</span></span>
<span id="cb27-188"><a href="#cb27-188" aria-hidden="true" tabindex="-1"></a><span class="va">+      return new AzureOpenAI({</span></span>
<span id="cb27-189"><a href="#cb27-189" aria-hidden="true" tabindex="-1"></a><span class="va">+        endpoint,</span></span>
<span id="cb27-190"><a href="#cb27-190" aria-hidden="true" tabindex="-1"></a><span class="va">+        apiKey,</span></span>
<span id="cb27-191"><a href="#cb27-191" aria-hidden="true" tabindex="-1"></a><span class="va">+        apiVersion,</span></span>
<span id="cb27-192"><a href="#cb27-192" aria-hidden="true" tabindex="-1"></a><span class="va">+        deployment: deploymentName,</span></span>
<span id="cb27-193"><a href="#cb27-193" aria-hidden="true" tabindex="-1"></a><span class="va">+      });</span></span>
<span id="cb27-194"><a href="#cb27-194" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb27-195"><a href="#cb27-195" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-196"><a href="#cb27-196" aria-hidden="true" tabindex="-1"></a><span class="va">+    export async function main() {</span></span>
<span id="cb27-197"><a href="#cb27-197" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(&quot;== Transcribe Audio Sample ==&quot;);</span></span>
<span id="cb27-198"><a href="#cb27-198" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-199"><a href="#cb27-199" aria-hidden="true" tabindex="-1"></a><span class="va">+      const client = getClient();</span></span>
<span id="cb27-200"><a href="#cb27-200" aria-hidden="true" tabindex="-1"></a><span class="va">+      const result = await client.audio.transcriptions.create({</span></span>
<span id="cb27-201"><a href="#cb27-201" aria-hidden="true" tabindex="-1"></a><span class="va">+        model: &quot;&quot;,</span></span>
<span id="cb27-202"><a href="#cb27-202" aria-hidden="true" tabindex="-1"></a><span class="va">+        file: createReadStream(audioFilePath),</span></span>
<span id="cb27-203"><a href="#cb27-203" aria-hidden="true" tabindex="-1"></a><span class="va">+      });</span></span>
<span id="cb27-204"><a href="#cb27-204" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-205"><a href="#cb27-205" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.log(`Transcription: ${result.text}`);</span></span>
<span id="cb27-206"><a href="#cb27-206" aria-hidden="true" tabindex="-1"></a><span class="va">+    }</span></span>
<span id="cb27-207"><a href="#cb27-207" aria-hidden="true" tabindex="-1"></a><span class="va">+    </span></span>
<span id="cb27-208"><a href="#cb27-208" aria-hidden="true" tabindex="-1"></a><span class="va">+    main().catch((err) =&gt; {</span></span>
<span id="cb27-209"><a href="#cb27-209" aria-hidden="true" tabindex="-1"></a><span class="va">+      console.error(&quot;The sample encountered an error:&quot;, err);</span></span>
<span id="cb27-210"><a href="#cb27-210" aria-hidden="true" tabindex="-1"></a><span class="va">+    });</span></span>
<span id="cb27-211"><a href="#cb27-211" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb27-212"><a href="#cb27-212" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-213"><a href="#cb27-213" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Build the application with the following command:</span></span>
<span id="cb27-214"><a href="#cb27-214" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-215"><a href="#cb27-215" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```console</span></span>
<span id="cb27-216"><a href="#cb27-216" aria-hidden="true" tabindex="-1"></a><span class="va">+    tsc</span></span>
<span id="cb27-217"><a href="#cb27-217" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb27-218"><a href="#cb27-218" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-219"><a href="#cb27-219" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Run the application with the following command:</span></span>
<span id="cb27-220"><a href="#cb27-220" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-221"><a href="#cb27-221" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```console</span></span>
<span id="cb27-222"><a href="#cb27-222" aria-hidden="true" tabindex="-1"></a><span class="va">+    node Whisper.js</span></span>
<span id="cb27-223"><a href="#cb27-223" aria-hidden="true" tabindex="-1"></a><span class="va">+    ```</span></span>
<span id="cb27-224"><a href="#cb27-224" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-225"><a href="#cb27-225" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb27-226"><a href="#cb27-226" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-227"><a href="#cb27-227" aria-hidden="true" tabindex="-1"></a><span class="va">+You can get sample audio files, such as *wikipediaOcelot.wav*, from the [Azure AI Speech SDK repository at GitHub](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/sampledata/audiofiles).</span></span>
<span id="cb27-228"><a href="#cb27-228" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-229"><a href="#cb27-229" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!IMPORTANT]</span></span>
<span id="cb27-230"><a href="#cb27-230" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; For production, store and access your credentials using a secure method, such as [Azure Key Vault](/azure/key-vault/general/overview). For more information about credential security, see [Azure AI services security](../../security-features.md).</span></span>
<span id="cb27-231"><a href="#cb27-231" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-232"><a href="#cb27-232" aria-hidden="true" tabindex="-1"></a><span class="va">+## Output</span></span>
<span id="cb27-233"><a href="#cb27-233" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb27-234"><a href="#cb27-234" aria-hidden="true" tabindex="-1"></a><span class="va">+```json</span></span>
<span id="cb27-235"><a href="#cb27-235" aria-hidden="true" tabindex="-1"></a><span class="va">+{&quot;text&quot;:&quot;The ocelot, Lepardus paradalis, is a small wild cat native to the southwestern United States, Mexico, and Central and South America. This medium-sized cat is characterized by solid black spots and streaks on its coat, round ears, and white neck and undersides. It weighs between 8 and 15.5 kilograms, 18 and 34 pounds, and reaches 40 to 50 centimeters 16 to 20 inches at the shoulders. It was first described by Carl Linnaeus in 1758. Two subspecies are recognized, L. p. paradalis and L. p. mitis. Typically active during twilight and at night, the ocelot tends to be solitary and territorial. It is efficient at climbing, leaping, and swimming. It preys on small terrestrial mammals such as armadillo, opossum, and lagomorphs.&quot;}</span></span>
<span id="cb27-236"><a href="#cb27-236" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span></code></pre></div>
</details>
<h3 id="summary-13">Summary</h3>
<div class="sourceCode" id="cb28"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Whisperを用いた音声の文字起こしに関するドキュメントの追加&quot;</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-13">Explanation</h3>
<p>このコードの変更では、<code>whisper-javascript.md</code>
ファイルが新たに追加され、235行のコンテンツが含まれています。このドキュメントは、JavaScriptおよびTypeScript環境におけるWhisper
APIを使用した音声の文字起こしについて説明しています。</p>
<ol class="incremental" type="1">
<li><p><strong>前提条件の明示</strong>:
音声の文字起こし機能を利用するために必要なAzureのサブスクリプション、LTSバージョンのNode.js、及びAzure
OpenAIリソースの作成に関する情報が記載されています。</p></li>
<li><p><strong>キーとエンドポイントの取得手順</strong>: Azure
OpenAIを利用するために必要なエンドポイントとAPIキーを取得する手順が、Azureポータル内での手順に基づいて説明されています。この部分は、ユーザーがスムーズにAPIを利用開始できるようにするための重要な要素です。</p></li>
<li><p><strong>環境変数の設定手順</strong>:
ユーザーが開発環境で使用するための環境変数の設定手順が明確に示されています。これには、コマンドライン、PowerShell、Bashでの具体的なコマンドが掲示されています。</p></li>
<li><p><strong>パスワードレス認証の推奨</strong>:
パスワードなしでの認証方法が説明され、<code>@azure/identity</code>パッケージを使用した方法が推奨されています。この手法により、より安全なアクセスが実現できます。</p></li>
<li><p><strong>Nodeアプリケーションの作成</strong>:
新しいNodeアプリケーションを作成する手順が詳しく説明されており、依存関係を管理するための<code>npm init</code>および<code>npm install</code>コマンドが示されています。</p></li>
<li><p><strong>サンプルアプリケーションの作成</strong>:
翻訳機能を用いたサンプルコードが提供され、具体的にどのように音声ファイルからテキストを抽出するか、またその際のエラー処理についても触れられています。JavaScriptとTypeScriptの両方のサンプルが示されているため、開発者は自身の必要に応じて選択できます。</p></li>
<li><p><strong>セキュリティの注意</strong>:
プロダクション環境での安全な認証情報の取扱についての注意喚起が行われ、Azure
Key Vaultの利用が推奨されています。</p></li>
</ol>
<p>この新しいドキュメントにより、開発者はWhisper
APIを効果的に利用できる方法を理解し、音声データの処理プロセスを簡素化することが可能になります。これにより、音声からテキストへの変換の実装が容易になり、ユーザーに対する利便性が向上します。</p>
<h2
id="item-7db269">articles/ai-services/openai/includes/whisper-powershell.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb29"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -9,7 +9,67 @@ ms.author: eur</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a> author: eric-urban</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="st">-## PowerShell</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="va">+## Prerequisites</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true)</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="va">+- &lt;a href=&quot;https://aka.ms/installpowershell&quot; target=&quot;_blank&quot;&gt;You can use either the latest version, PowerShell 7, or Windows PowerShell 5.1.&lt;/a&gt;</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI Service resource with a model deployed. For more information about model deployment, see the [resource deployment guide](../how-to/create-resource.md).</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI Service resource with either the `gpt-35-turbo` or the `gpt-4` models deployed. For more information about model deployment, see the [resource deployment guide](../how-to/create-resource.md).</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="va">+## Set up</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="va">+### Retrieve key and endpoint</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="va">+To successfully make a call against Azure OpenAI, you need an *endpoint* and a *key*.</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="va">+|Variable name | Value |</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="va">+|--------------------------|-------------|</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_ENDPOINT`               | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in the **Azure OpenAI Studio** &gt; **Playground** &gt; **Code View**. An example endpoint is: `https://aoai-docs.openai.azure.com/`.|</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_API_KEY` | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|</span></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="va">+Go to your resource in the Azure portal. The **Endpoint and Keys** can be found in the **Resource Management** section. Copy your endpoint and access key as you&#39;ll need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a><span class="va">+:::image type=&quot;content&quot; source=&quot;../media/quickstarts/endpoint.png&quot; alt-text=&quot;Screenshot of the overview UI for an Azure OpenAI resource in the Azure portal with the endpoint &amp; access keys location circled in red.&quot; lightbox=&quot;../media/quickstarts/endpoint.png&quot;:::</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="va">+### Environment variables</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a><span class="va">+Create and assign persistent environment variables for your key and endpoint.</span></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Azure key vault](~/reusable-content/ce-skilling/azure/includes/ai-services/security/azure-key-vault.md)]</span></span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Command Line](#tab/command-line)</span></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_API_KEY &quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; </span></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_ENDPOINT &quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; </span></span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a><span class="va">+# [PowerShell](#tab/powershell)</span></span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_API_KEY&#39;, &#39;REPLACE_WITH_YOUR_KEY_VALUE_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_ENDPOINT&#39;, &#39;REPLACE_WITH_YOUR_ENDPOINT_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Bash](#tab/bash)</span></span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_API_KEY=&quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a PowerShell app</span></span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a> Run the following command. You need to replace `YourDeploymentName` with the deployment name you chose when you deployed the Whisper model. The deployment name isn&#39;t necessarily the same as the model name. Entering the model name results in an error unless you chose a deployment name that is identical to the underlying model name.</span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-14">Summary</h3>
<div class="sourceCode" id="cb30"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Whisper用のPowerShellによる音声処理に関するドキュメントの更新&quot;</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-14">Explanation</h3>
<p>このコードの変更では、<code>whisper-powershell.md</code>
ファイルが更新され、61行が追加され、1行が削除されています。この変更は、Whisperモデルを用いたPowerShellでの音声処理に関する事前条件や設定手順が新たに追加され、内容が充実しています。</p>
<ol class="incremental" type="1">
<li><p><strong>事前条件の明示</strong>: ユーザーがWhisper
APIを利用するための条件として、Azureサブスクリプション、PowerShellのバージョン、Azure
OpenAI
Serviceリソースの作成が追加されています。具体的には、<code>gpt-35-turbo</code>または<code>gpt-4</code>モデルがデプロイされたリソースが必要です。</p></li>
<li><p><strong>キーとエンドポイントの取得手順</strong>: Azure
OpenAIを呼び出す際に必要なエンドポイントとAPIキーの取得方法が強調されています。この情報には、Azureポータルでの具体的な参照先が含まれており、ユーザーがスムーズに設定を行えるよう配慮されています。</p></li>
<li><p><strong>環境変数の設定手順</strong>:
PowerShellを含む複数の環境での環境変数の設定方法が示されており、ユーザーがAPIを利用開始するための準備が整うようにしています。</p></li>
<li><p><strong>PowerShellアプリケーションの作成</strong>:
Whisperモデルのデプロイ名を用いたPowerShellアプリケーションを作成する手順が記述されており、具体的なコマンドを示すことで実装の手助けをしています。</p></li>
</ol>
<p>これにより、ユーザーはWhisperモデルを用いた音声処理をPowerShellで簡単に実行できるようになり、必要な準備や手順を理解しやすくなります。このドキュメントの更新は、開発者がAzure
OpenAIの機能を効果的に活用できるように設計されています。</p>
<h2
id="item-e61179">articles/ai-services/openai/includes/whisper-python.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb31"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -7,14 +7,75 @@ ms.topic: include</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a> ms.date: 3/19/2024</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="st">-## Python</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="st">-### Prerequisites</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="va">+## Prerequisites</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure subscription. You can [create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true).</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI resource with a Whisper model deployed in a [supported region](../concepts/models.md#whisper-models). For more information, see [Create a resource and deploy a model with Azure OpenAI](../how-to/create-resource.md).</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a> - [Python 3.8 or later](https://www.python.org)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a> - The following Python library: os</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="st">-### Set up</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="va">+## Set up</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="va">+### Retrieve key and endpoint</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="va">+To successfully make a call against Azure OpenAI, you need an *endpoint* and a *key*.</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="va">+|Variable name | Value |</span></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="va">+|--------------------------|-------------|</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_ENDPOINT`               | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in the **Azure OpenAI Studio** &gt; **Playground** &gt; **Code View**. An example endpoint is: `https://aoai-docs.openai.azure.com/`.|</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_API_KEY` | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a><span class="va">+Go to your resource in the Azure portal. The **Endpoint and Keys** can be found in the **Resource Management** section. Copy your endpoint and access key as you&#39;ll need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.</span></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="va">+:::image type=&quot;content&quot; source=&quot;../media/quickstarts/endpoint.png&quot; alt-text=&quot;Screenshot of the overview UI for an Azure OpenAI resource in the Azure portal with the endpoint &amp; access keys location circled in red.&quot; lightbox=&quot;../media/quickstarts/endpoint.png&quot;:::</span></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a><span class="va">+### Environment variables</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a><span class="va">+Create and assign persistent environment variables for your key and endpoint.</span></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Azure key vault](~/reusable-content/ce-skilling/azure/includes/ai-services/security/azure-key-vault.md)]</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Command Line](#tab/command-line)</span></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_API_KEY &quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; </span></span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_ENDPOINT &quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; </span></span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a><span class="va">+# [PowerShell](#tab/powershell)</span></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_API_KEY&#39;, &#39;REPLACE_WITH_YOUR_KEY_VALUE_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_ENDPOINT&#39;, &#39;REPLACE_WITH_YOUR_ENDPOINT_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Bash](#tab/bash)</span></span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_API_KEY=&quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a><span class="va">+## Passwordless authentication is recommended</span></span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a><span class="va">+For passwordless authentication, you need to </span></span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Use the `@azure/identity` package.</span></span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Assign the `Cognitive Services User` role to your user account. This can be done in the Azure portal under **Access control (IAM)** &gt; **Add role assignment**.</span></span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Sign in with the Azure CLI such as `az login`.</span></span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a Python environment</span></span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a> Install the OpenAI Python client library with:</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -34,6 +95,8 @@ pip install openai==0.28.1</span></span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create the Python app</span></span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a> 1. Create a new Python file called *quickstart.py*. Then open it up in your preferred editor or IDE.</span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a> 1. Replace the contents of *quickstart.py* with the following code. Modify the code to add your deployment name:</span></code></pre></div>
</details>
<h3 id="summary-15">Summary</h3>
<div class="sourceCode" id="cb32"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Whisper用のPythonに関するドキュメントの更新&quot;</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-15">Explanation</h3>
<p>このコードの変更では、<code>whisper-python.md</code>
ファイルが更新され、67行が追加され、4行が削除されています。この改訂は、Whisperモデルを使用する際のPython環境に関する事前条件や設定手順を詳しく説明しています。</p>
<ol class="incremental" type="1">
<li><p><strong>事前条件の更新</strong>:
Azureサブスクリプションの作成方法、WhisperモデルがデプロイされたAzure
OpenAIリソースが必要であることが明示されています。また、Python
3.8以上と必要なライブラリに関する情報も含まれています。</p></li>
<li><p><strong>設定手順の詳細追加</strong>: Azure
OpenAIに対して呼び出しを行うためには、エンドポイントとAPIキーが必要であることが強調されています。その取得手順も具体的に示されており、Azureポータル内でのアクセス方法が説明されています。</p></li>
<li><p><strong>環境変数の設定</strong>:
Python環境でのAPIキーとエンドポイントの永続的な環境変数の設定手順が具体的なコマンドとともに示されています。これにより、ユーザーが自分の環境での設定を簡単に行うことができます。</p></li>
<li><p><strong>パスワードなしの認証の推奨</strong>:
より安全な認証方法として、<code>@azure/identity</code>パッケージを使用することが推奨されています。この手法により、安全にAzureサービスにアクセスすることが可能です。</p></li>
<li><p><strong>Python環境の作成</strong>: OpenAI
Pythonクライアントライブラリのインストール方法や、実際に使用するPythonファイルの作成方法が具体的に指示されています。また、サンプルコードと一緒にデプロイ名を変更する必要があることが明記されています。</p></li>
</ol>
<p>この更新により、開発者はWhisperモデルを使用するためのPython環境を整えやすくなり、利用の際に必要な手順がより明確に理解できるようになります。全体として、Azure
OpenAIを効果的に活用するためのガイドラインが強化されています。</p>
<h2
id="item-639ccb">articles/ai-services/openai/includes/whisper-rest.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb33"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -9,7 +9,69 @@ ms.author: eur</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a> author: eric-urban</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="st">-## REST API</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="va">+## Prerequisites</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure subscription - &lt;a href=&quot;https://azure.microsoft.com/free/cognitive-services&quot; target=&quot;_blank&quot;&gt;Create one for free&lt;/a&gt;.</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI resource deployed in a [supported region and with a supported model](../concepts/use-your-data.md#regional-availability-and-model-support).</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="va">+- Be sure that you are assigned at least the [Cognitive Services Contributor](../how-to/role-based-access-control.md#cognitive-services-contributor) role for the Azure OpenAI resource.</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="va">+- Download the example data from [GitHub](https://github.com/Azure-Samples/cognitive-services-sample-data-files/blob/master/openai/contoso_benefits_document_example.pdf) if you don&#39;t have your own data.</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="va">+## Set up</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="va">+### Retrieve key and endpoint</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="va">+To successfully make a call against Azure OpenAI, you need an *endpoint* and a *key*.</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a><span class="va">+|Variable name | Value |</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a><span class="va">+|--------------------------|-------------|</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_ENDPOINT`               | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in the **Azure OpenAI Studio** &gt; **Playground** &gt; **Code View**. An example endpoint is: `https://aoai-docs.openai.azure.com/`.|</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a><span class="va">+| `AZURE_OPENAI_API_KEY` | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|</span></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a><span class="va">+Go to your resource in the Azure portal. The **Endpoint and Keys** can be found in the **Resource Management** section. Copy your endpoint and access key as you&#39;ll need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a><span class="va">+:::image type=&quot;content&quot; source=&quot;../media/quickstarts/endpoint.png&quot; alt-text=&quot;Screenshot of the overview UI for an Azure OpenAI resource in the Azure portal with the endpoint &amp; access keys location circled in red.&quot; lightbox=&quot;../media/quickstarts/endpoint.png&quot;:::</span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a><span class="va">+### Environment variables</span></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a><span class="va">+Create and assign persistent environment variables for your key and endpoint.</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Azure key vault](~/reusable-content/ce-skilling/azure/includes/ai-services/security/azure-key-vault.md)]</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Command Line](#tab/command-line)</span></span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_API_KEY &quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; </span></span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a><span class="va">+```CMD</span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a><span class="va">+setx AZURE_OPENAI_ENDPOINT &quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; </span></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a><span class="va">+# [PowerShell](#tab/powershell)</span></span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_API_KEY&#39;, &#39;REPLACE_WITH_YOUR_KEY_VALUE_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell</span></span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a><span class="va">+[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_ENDPOINT&#39;, &#39;REPLACE_WITH_YOUR_ENDPOINT_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Bash](#tab/bash)</span></span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_API_KEY=&quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a><span class="va">+```Bash</span></span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a><span class="va">+echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a REST API request and response</span></span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a> In a bash shell, run the following command. You need to replace `YourDeploymentName` with the deployment name you chose when you deployed the Whisper model. The deployment name isn&#39;t necessarily the same as the model name. Entering the model name results in an error unless you chose a deployment name that is identical to the underlying model name.</span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-16">Summary</h3>
<div class="sourceCode" id="cb34"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Whisper用のREST APIに関するドキュメントの更新&quot;</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-16">Explanation</h3>
<p>このコードの変更では、<code>whisper-rest.md</code>
ファイルが更新され、63行が追加され、1行が削除されています。この改訂は、Whisperモデルを使用する際のREST
API利用に必要な事前条件や設定手順をより詳しく説明しています。</p>
<ol class="incremental" type="1">
<li><p><strong>事前条件の明示</strong>:
Azureのサブスクリプションを持ち、WhisperモデルがデプロイされたAzure
OpenAIリソースが必要であることが明示されています。また、“Cognitive
Services
Contributor”の役割が必要なことも記載されています。これにより、リソースに対して適切なアクセス権を持つことが強調されています。</p></li>
<li><p><strong>設定手順の追加</strong>: Azure
OpenAIに対してAPIを呼び出すためにはエンドポイントとAPIキーが必要であることが強調され、これらの具体的な取得方法やAzureポータル内での位置が明記されています。</p></li>
<li><p><strong>環境変数の設定手順</strong>:
ユーザーが自身の環境でAPIキーとエンドポイントを持続的に使用できるように、環境変数の設定手順が詳細に説明されています。具体的なコマンドの形式も示されており、実施が容易になっています。</p></li>
<li><p><strong>REST APIリクエストの作成</strong>:
ユーザーはBashシェルでのAPIリクエストの方法が示されており、デプロイ名を適切に指定する方法も明記されています。これにより、誤ったモデル名を指定した場合のエラーを避けるためのガイダンスが提供されています。</p></li>
</ol>
<p>この更新は、開発者がWhisperモデルをREST
APIを介して効果的に使用できるように設計されており、必要な手順や設定がより分かりやすくなっています。全体として、ユーザーがAzure
OpenAIの機能を最大限に活用するためのサポートが強化されています。</p>
<h2 id="item-0adb87">articles/ai-services/openai/index.yml</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb35"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,17 +1,17 @@</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a> ### YamlMime:Landing</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a> title: Azure OpenAI Service documentation # &lt; 60 chars</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="st">-summary: Azure OpenAI Service provides access to OpenAI&#39;s models including the GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, DALLE-3 and Embeddings model series with the security and enterprise capabilities of Azure. </span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="va">+summary: Azure OpenAI Service provides access to OpenAI&#39;s models including the GPT-4o, GPT-4o mini, GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, DALLE-3 and Embeddings model series with the security and enterprise capabilities of Azure. </span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a> metadata:</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>   title: Azure OpenAI Service documentation - Quickstarts, Tutorials, API Reference - Azure AI services | Microsoft Docs</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="st">-  description: Learn how to use Azure OpenAI&#39;s powerful models including the GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, DALL-E 3 and Embeddings model series</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="va">+  description: Learn how to use Azure OpenAI&#39;s powerful models including the GPT-4o, GPT-4o mini, GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, DALL-E 3 and Embeddings model series</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>   ms.service: azure-ai-openai</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>   ms.custom:</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>   ms.topic: landing-page</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>   author: mrbullwinkle</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>   ms.author: mbullwin</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="st">-  ms.date: 08/31/2024</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="va">+  ms.date: 09/18/2024</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a> # linkListType: architecture | concept | deploy | download | get-started | how-to-guide | learn | overview | quickstart | reference | tutorial | video | whats-new</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a> # Limits: https://review.learn.microsoft.com/help/contribute/contribute-how-to-write-landing-page?branch=main#limits</span></code></pre></div>
</details>
<h3 id="summary-17">Summary</h3>
<div class="sourceCode" id="cb36"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Azure OpenAI Serviceのドキュメントの更新&quot;</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-17">Explanation</h3>
<p>このコードの変更では、<code>index.yml</code>
ファイルが更新され、3行が追加され、3行が削除されています。この改訂は、Azure
OpenAI
Serviceのドキュメントに関するメタデータの内容を更新しています。</p>
<ol class="incremental" type="1">
<li><p><strong>サマリーの修正</strong>:
サマリー文中に記載されているモデル名が更新され、“GPT-4”が”GPT-4o”および”GPT-4o
mini”に変更されています。これにより、このサービスで利用可能な特定のモデルが正確に反映されています。</p></li>
<li><p><strong>説明の更新</strong>:
説明文でも同様に、「GPT-4」が「GPT-4o」と「GPT-4o
mini」に修正されており、新しいモデル名が追加されています。この変更により、正確な情報が利用者に提供されるようになっています。</p></li>
<li><p><strong>日付の変更</strong>: <code>ms.date</code> の値が
“08/31/2024” から “09/18/2024”
に更新されています。これは、最新のリリースや変更が行われる予定の日付を示しており、文書のタイムスタンプを最新のものに保つことが意図されています。</p></li>
</ol>
<p>この起伏は、Azure OpenAI
Serviceに関する情報を最新かつ正確に保つために重要であり、ユーザーがサービスの利用に際して最も正しい情報を得られるようにすることに繋がります。全体として、更新の内容は、サービスの利用者にとって重要な情報の透明性を向上させるものです。</p>
<h2 id="item-97d507">articles/ai-services/openai/overview.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb37"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -14,7 +14,7 @@ recommendations: false</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a> # What is Azure OpenAI Service?</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="st">-Azure OpenAI Service provides REST API access to OpenAI&#39;s powerful language models including GPT-4o, GPT-4 Turbo with Vision, GPT-4, GPT-3.5-Turbo, and Embeddings model series. These models can be easily adapted to your specific task including but not limited to content generation, summarization, image understanding, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="va">+Azure OpenAI Service provides REST API access to OpenAI&#39;s powerful language models including GPT-4o, GPT-4o mini, GPT-4 Turbo with Vision, GPT-4, GPT-3.5-Turbo, and Embeddings model series. These models can be easily adapted to your specific task including but not limited to content generation, summarization, image understanding, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a> ### Features overview</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-18">Summary</h3>
<div class="sourceCode" id="cb38"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Azure OpenAI Serviceの概要の更新&quot;</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-18">Explanation</h3>
<p>このコードの変更では、<code>overview.md</code>
ファイルが更新され、1行が追加され、1行が削除されています。この修正は、Azure
OpenAI
Serviceに関する概要説明を最新の情報に基づいて修正することを目的としています。</p>
<ol class="incremental" type="1">
<li><p><strong>モデル名の追加</strong>: Azure OpenAI
Serviceの説明部分において、モデルリストに「GPT-4o
mini」が追加され、他のモデルと共に記載されています。これにより、利用可能なモデルの選択肢が明確になり、ユーザーがサービスの機能を理解しやすくなっています。</p></li>
<li><p><strong>内容の整合性</strong>:
修正された行に関連する情報は全体的には整合性を保ちながら、編集が施されています。この内容は、ユーザーにAzure
OpenAI
Serviceの機能を正確に伝えることを目的としており、特に新しいモデルの追加は重要な情報となります。</p></li>
</ol>
<p>この変更は、ユーザーがAzure OpenAI
Serviceを利用する際に、最新かつ正確な情報を得られるようにするためのもので、特にモデルの情報が重要な要素であるため、変更が行われたことは大きな意義を持っています。全体として、サービスの説明はより包括的かつ利用者にとって有益なものとなっています。</p>
<h2 id="item-7d1656">articles/ai-services/openai/quickstart.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb39"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,7 +1,7 @@</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="st">-title: &#39;Quickstart - Deploy a model and generate text using Azure OpenAI Service&#39;</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="va">+title: &#39;Quickstart - Deploy a model and generate text using the legacy completions API&#39;</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure OpenAI</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="st">-description: Walkthrough on how to get started with Azure OpenAI and make your first completions call.</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="va">+description: Walkthrough on how to get started with Azure OpenAI and make your first legacy completions API call.</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a> #services: cognitive-services</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -14,7 +14,7 @@ zone_pivot_groups: openai-quickstart-new</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a> recommendations: false</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="st">-# Quickstart: Get started generating text using Azure OpenAI Service</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="va">+# Quickstart: Get started generating text using the legacy completions API</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a> Use this article to get started making your first calls to Azure OpenAI.</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-19">Summary</h3>
<div class="sourceCode" id="cb40"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Azure OpenAI Serviceのクイックスタートガイドの更新&quot;</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-19">Explanation</h3>
<p>このコードの変更では、<code>quickstart.md</code>
ファイルが更新され、3行が追加され、3行が削除されています。この変更は、Azure
OpenAI
Serviceに関連するクイックスタートガイドのタイトルと説明に焦点を当てています。</p>
<ol class="incremental" type="1">
<li><p><strong>タイトルの修正</strong>: タイトルが「Quickstart - Deploy
a model and generate text using Azure OpenAI Service」から「Quickstart -
Deploy a model and generate text using the legacy completions
API」に変更されました。これにより、特に使用するAPIの種類が明確になり、新旧のAPIに対する認識が助けられます。</p></li>
<li><p><strong>説明の変更</strong>: 説明文も同様に更新され、「Azure
OpenAI Service」に関する最初のコールを行うための手順として「legacy
completions
API」が挿入されました。この変更は、ユーザーが古いAPIを使用して初めてのコールを行う方法に特化した情報を提供することを意図しています。</p></li>
<li><p><strong>セクションタイトルの調整</strong>:
セクションのタイトルも変更され、内容の一貫性を保つために新たに「legacy
completions
API」という言葉が用いられています。これにより、文書全体が最新の機能および環境に合致した内容に整えられています。</p></li>
</ol>
<p>この変更は、Azure OpenAI
Serviceの利用者が特定のAPIバージョンに基づいた正確な情報を得られるようにすることを目的としています。全体として、クイックスタート記事は、ユーザーがスムーズにサービスを開始できるよう支援する情報が提供されています。</p>
<h2
id="item-c344ad">articles/ai-services/openai/text-to-speech-quickstart.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb41"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -5,11 +5,12 @@ description: Use the Azure OpenAI Service for text to speech with OpenAI voices.</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a> ms.topic: quickstart</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 2/1/2024</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 9/12/2024</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a> ms.reviewer: v-baolianzou</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a> ms.author: eur</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a> author: eric-urban</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a> recommendations: false</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="va">+zone_pivot_groups: programming-languages-rest-js</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a> # Quickstart: Text to speech with the Azure OpenAI Service</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -18,64 +19,18 @@ In this quickstart, you use the Azure OpenAI Service for text to speech with Ope</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a> The available voices are: `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. For more information, see [Azure OpenAI Service reference documentation for text to speech](./reference.md#text-to-speech).</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="st">-## Prerequisites</span></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="st">-- An Azure subscription - [Create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true).</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a><span class="st">-- An Azure OpenAI resource created in the North Central US or Sweden Central regions with the `tts-1` or `tts-1-hd` model deployed. For more information, see [Create a resource and deploy a model with Azure OpenAI](how-to/create-resource.md).</span></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone pivot=&quot;rest-api&quot;</span></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a><span class="st">-## Set up</span></span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a><span class="st">-### Retrieve key and endpoint</span></span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a><span class="st">-To successfully make a call against Azure OpenAI, you need an **endpoint** and a **key**.</span></span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a><span class="st">-|Variable name | Value |</span></span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a><span class="st">-|--------------------------|-------------|</span></span>
<span id="cb41-33"><a href="#cb41-33" aria-hidden="true" tabindex="-1"></a><span class="st">-| `AZURE_OPENAI_ENDPOINT`               | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in the **Azure OpenAI Studio** &gt; **Playground** &gt; **Code View**. An example endpoint is: `https://aoai-docs.openai.azure.com/`.|</span></span>
<span id="cb41-34"><a href="#cb41-34" aria-hidden="true" tabindex="-1"></a><span class="st">-| `AZURE_OPENAI_API_KEY` | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|</span></span>
<span id="cb41-35"><a href="#cb41-35" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-36"><a href="#cb41-36" aria-hidden="true" tabindex="-1"></a><span class="st">-Go to your resource in the Azure portal. The **Endpoint and Keys** can be found in the **Resource Management** section. Copy your endpoint and access key as you need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.</span></span>
<span id="cb41-37"><a href="#cb41-37" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-38"><a href="#cb41-38" aria-hidden="true" tabindex="-1"></a><span class="st">-:::image type=&quot;content&quot; source=&quot;media/quickstarts/endpoint.png&quot; alt-text=&quot;Screenshot of the overview UI for an Azure OpenAI resource in the Azure portal with the endpoint &amp; access keys location highlighted.&quot; lightbox=&quot;media/quickstarts/endpoint.png&quot;:::</span></span>
<span id="cb41-39"><a href="#cb41-39" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-40"><a href="#cb41-40" aria-hidden="true" tabindex="-1"></a><span class="st">-### Environment variables</span></span>
<span id="cb41-41"><a href="#cb41-41" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-42"><a href="#cb41-42" aria-hidden="true" tabindex="-1"></a><span class="st">-Create and assign persistent environment variables for your key and endpoint.</span></span>
<span id="cb41-43"><a href="#cb41-43" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-44"><a href="#cb41-44" aria-hidden="true" tabindex="-1"></a><span class="st">-[!INCLUDE [Azure key vault](~/reusable-content/ce-skilling/azure/includes/ai-services/security/azure-key-vault.md)]</span></span>
<span id="cb41-45"><a href="#cb41-45" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-46"><a href="#cb41-46" aria-hidden="true" tabindex="-1"></a><span class="st">-# [Command Line](#tab/command-line)</span></span>
<span id="cb41-47"><a href="#cb41-47" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-48"><a href="#cb41-48" aria-hidden="true" tabindex="-1"></a><span class="st">-```CMD</span></span>
<span id="cb41-49"><a href="#cb41-49" aria-hidden="true" tabindex="-1"></a><span class="st">-setx AZURE_OPENAI_API_KEY &quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; </span></span>
<span id="cb41-50"><a href="#cb41-50" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb41-51"><a href="#cb41-51" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-52"><a href="#cb41-52" aria-hidden="true" tabindex="-1"></a><span class="st">-```CMD</span></span>
<span id="cb41-53"><a href="#cb41-53" aria-hidden="true" tabindex="-1"></a><span class="st">-setx AZURE_OPENAI_ENDPOINT &quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; </span></span>
<span id="cb41-54"><a href="#cb41-54" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb41-55"><a href="#cb41-55" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-56"><a href="#cb41-56" aria-hidden="true" tabindex="-1"></a><span class="st">-# [PowerShell](#tab/powershell)</span></span>
<span id="cb41-57"><a href="#cb41-57" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-58"><a href="#cb41-58" aria-hidden="true" tabindex="-1"></a><span class="st">-```powershell</span></span>
<span id="cb41-59"><a href="#cb41-59" aria-hidden="true" tabindex="-1"></a><span class="st">-[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_API_KEY&#39;, &#39;REPLACE_WITH_YOUR_KEY_VALUE_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb41-60"><a href="#cb41-60" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb41-61"><a href="#cb41-61" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb41-62"><a href="#cb41-62" aria-hidden="true" tabindex="-1"></a><span class="st">-```powershell</span></span>
<span id="cb41-63"><a href="#cb41-63" aria-hidden="true" tabindex="-1"></a><span class="st">-[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_ENDPOINT&#39;, &#39;REPLACE_WITH_YOUR_ENDPOINT_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb41-64"><a href="#cb41-64" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb41-65"><a href="#cb41-65" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [REST API quickstart](includes/text-to-speech-rest.md)]</span></span>
<span id="cb41-66"><a href="#cb41-66" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-67"><a href="#cb41-67" aria-hidden="true" tabindex="-1"></a><span class="st">-# [Bash](#tab/bash)</span></span>
<span id="cb41-68"><a href="#cb41-68" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone-end</span></span>
<span id="cb41-69"><a href="#cb41-69" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-70"><a href="#cb41-70" aria-hidden="true" tabindex="-1"></a><span class="st">-```Bash</span></span>
<span id="cb41-71"><a href="#cb41-71" aria-hidden="true" tabindex="-1"></a><span class="st">-echo export AZURE_OPENAI_API_KEY=&quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb41-72"><a href="#cb41-72" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb41-73"><a href="#cb41-73" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone pivot=&quot;programming-language-javascript&quot;</span></span>
<span id="cb41-74"><a href="#cb41-74" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-75"><a href="#cb41-75" aria-hidden="true" tabindex="-1"></a><span class="st">-```Bash</span></span>
<span id="cb41-76"><a href="#cb41-76" aria-hidden="true" tabindex="-1"></a><span class="st">-echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb41-77"><a href="#cb41-77" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb41-78"><a href="#cb41-78" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb41-79"><a href="#cb41-79" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [JavaScript quickstart](includes/text-to-speech-javascript.md)]</span></span>
<span id="cb41-80"><a href="#cb41-80" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-81"><a href="#cb41-81" aria-hidden="true" tabindex="-1"></a><span class="st">-[!INCLUDE [REST API quickstart](includes/text-to-speech-rest.md)]</span></span>
<span id="cb41-82"><a href="#cb41-82" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone-end</span></span>
<span id="cb41-83"><a href="#cb41-83" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb41-84"><a href="#cb41-84" aria-hidden="true" tabindex="-1"></a> ## Clean up resources</span>
<span id="cb41-85"><a href="#cb41-85" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-20">Summary</h3>
<div class="sourceCode" id="cb42"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Azure OpenAI Serviceのテキスト音声合成クイックスタートの更新&quot;</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-20">Explanation</h3>
<p>このコードの変更では、<code>text-to-speech-quickstart.md</code>
ファイルが大幅に修正され、主に内容の整理と新しいセクションの追加が行われました。具体的には、以下の点が変更されています。</p>
<ol class="incremental" type="1">
<li><p><strong>日付の更新</strong>:
ドキュメントの日付が「2/1/2024」から「9/12/2024」に変更され、最新の情報として更新されています。</p></li>
<li><p><strong>新しいセクションの追加</strong>: 新しいゾーンピボット
<code>programming-languages-rest-js</code>
が追加され、特定のプログラミング言語に関連する内容を示しています。</p></li>
<li><p><strong>大幅なコンテンツの削除と整理</strong>:
全体的に53行の削除が行われ、特に設定手順や環境変数に関するセクションが省略されています。その代わりに、他のリファレンスドキュメントへのインクルード
(<code>[!INCLUDE]</code>)
が追加され、具体的な設定手順を外部リンクとして提供する形に変更されています。</p></li>
<li><p><strong>音声のリストの簡略化</strong>:
音声のリストは簡潔に説明され、利用可能な声の情報が重要ポイントとして強調されています。</p></li>
<li><p><strong>リソースのクリーンアップセクション</strong>:
最後にはリソースをクリーンアップするためのセクションが新たに追加され、利用者が実行後にリソースを整理する手順が記載されています。</p></li>
</ol>
<p>この変更は、ドキュメントの構造をより明確にし、ユーザーが求める情報を迅速に見つけられるようにすることを目的としています。また、クイックスタートガイドがより使いやすく、最新の情報に基づいていることを示しています。全体として、情報の詰め込みすぎを避け、ユーザーが必要な手順にアクセスしやすくなっています。</p>
<h2 id="item-c945af">articles/ai-services/openai/toc.yml</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb43"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -29,8 +29,6 @@ items:</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>   items:</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>     - name: Assistants (preview)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>       href: assistants-quickstart.md</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="st">-    - name: Completions</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="st">-      href: quickstart.md</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>     - name: Chat</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>       href: chatgpt-quickstart.md  </span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>       displayName: ChatGPT, chatgpt</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -44,6 +42,8 @@ items:</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>       href: whisper-quickstart.md</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>     - name: Text to speech (preview)</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>       href: text-to-speech-quickstart.md</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="va">+    - name: Completions (legacy)</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="va">+      href: quickstart.md</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a> - name: Concepts</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>   items:</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>     - name: Assistants</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -118,7 +118,7 @@ items:</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>       href: ./how-to/dall-e.md</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>     - name: Function calling</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>       href: ./how-to/function-calling.md</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a><span class="st">-    - name: Completions</span></span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a><span class="va">+    - name: Completions (legacy)</span></span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>       href: ./how-to/completions.md</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>     - name: JSON mode</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>       href: ./how-to/json-mode.md</span></code></pre></div>
</details>
<h3 id="summary-21">Summary</h3>
<div class="sourceCode" id="cb44"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;OpenAIサービスの目次の更新&quot;</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-21">Explanation</h3>
<p>このコードの変更は、<code>toc.yml</code>
ファイルに対するもので、いくつかの小変更が加えられました。具体的な変更内容は以下の通りです。</p>
<ol class="incremental" type="1">
<li><p><strong>コンテンツの整理</strong>:
一部の項目の名前が「Completions」から「Completions
(legacy)」に変更され、このセクションが古いAPIに関連していることを明確にしています。この変更は、ユーザーが古い機能と新しい機能を区別しやすくすることを目的としています。</p></li>
<li><p><strong>新しい項目の追加</strong>: メニューに「Completions
(legacy)」という新しい項目が追加され、クイックスタートガイドへのリンクが設けられています。これにより、利用者は古いAPIの使用方法にアクセスしやすくなっています。</p></li>
<li><p><strong>不必要な重複の削除</strong>:
「Completions」の項目が以前の位置から削除され、ファイル全体の構造が簡潔になっています。これにより情報が整理され、メニューが見やすくなりました。</p></li>
<li><p><strong>整合性の確保</strong>:
他の部分でも同様に「Completions」が「Completions
(legacy)」として統一され、目次全体の整合性が向上しています。</p></li>
</ol>
<p>この更新は、OpenAIサービスに関するドキュメントのナビゲーションの質を改善し、ユーザーが必要な情報を迅速に見つけられることを目的としています。また、新旧の機能の違いを明確にすることで、利用者が適切なリソースを選択しやすくなっています。全体として、目次はより整理され、理解しやすくなりました。</p>
<h2 id="item-53303b">articles/ai-services/openai/whats-new.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb45"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -20,6 +20,16 @@ This article provides a summary of the latest releases and major documentation u</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a> ## September 2024</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="va">+### GPT-4o 2024-08-06 provisioned deployments</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="va">+GPT-4o 2024-08-06 is now available for provisioned deployments in East US, East US 2, North Central US, and Sweden Central. It is also available for global provisioned deployments.</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="va">+For the latest information on model availability, see the [models page](/azure/ai-services/openai/concepts/models#provisioned-deployment-model-availability).</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="va">+### NEW Global provisioned deployment type</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="va">+Global deployments are available in the same Azure OpenAI resources as non-global deployment types but allow you to leverage Azure&#39;s global infrastructure to dynamically route traffic to the data center with best availability for each request. Global provisioned deployments provide reserved model processing capacity for high and predictable throughput using Azure global infrastructure. Global provisioned deployments are supported on `gpt-4o-2024-08-06` and `gpt-4o-mini-2024-07-18` models.</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="va">+For more information, see the [deployment types guide](https://aka.ms/aoai/docs/deployment-types).</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a> ### NEW o1-preview and o1-mini models available for limited access</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a> The Azure OpenAI `o1-preview` and `o1-mini` models are specifically designed to tackle reasoning and problem-solving tasks with increased focus and capability. These models spend more time processing and understanding the user&#39;s request, making them exceptionally strong in areas like science, coding, and math compared to previous iterations.</span></code></pre></div>
</details>
<h3 id="summary-22">Summary</h3>
<div class="sourceCode" id="cb46"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;What&#39;s New in OpenAIサービスの更新&quot;</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-22">Explanation</h3>
<p>このコードの変更は、<code>whats-new.md</code>
ファイルに対するもので、新たに10行が追加され、OpenAIサービスの最新のリリース情報が更新されました。具体的な変更内容は以下の通りです。</p>
<ol class="incremental" type="1">
<li><p><strong>モデルの新情報追加</strong>:
2024年8月6日に展開された新しいGPT-4oモデルについての情報が追加されました。このモデルは、米国東部（East
US）、米国東部2（East US 2）、北中部（North Central
US）、スウェーデン中部（Sweden
Central）でのプロビジョニング展開に対応しており、グローバルに利用可能です。</p></li>
<li><p><strong>グローバルプロビジョニング展開の新たな説明</strong>:
新しいグローバルプロビジョニング展開のタイプが紹介され、Azureのグローバルインフラストラクチャを利用してトラフィックを最適なデータセンターに動的にルーティングする方法が説明されています。この展開タイプは、高いスループットを持つ処理能力を提供します。</p></li>
<li><p><strong>新モデルの限定アクセス情報</strong>:
<code>o1-preview</code>と<code>o1-mini</code>モデルについての情報が追加されています。これらのモデルは、理由付けや問題解決タスクに特化しており、以前のバージョンに比べてユーザーのリクエストをより深く理解する能力が向上しています。</p></li>
<li><p><strong>リソースへのリンクの追加</strong>:
モデルの可用性や展開タイプに関する詳細情報へのリンクが追加されており、ユーザーが必要な情報に容易にアクセスできるようになっています。</p></li>
</ol>
<p>この更新により、OpenAIサービスの最新の機能とモデルが紹介され、利用者は新しい技術を活用しやすくなっています。情報が整理され、最新のリリースについての理解が深まる内容となっています。</p>
<h2
id="item-4cae3d">articles/ai-services/openai/whisper-quickstart.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb47"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -11,7 +11,7 @@ ms.reviewer: v-baolianzou</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a> ms.author: eur</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a> author: eric-urban</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a> recommendations: false</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="st">-zone_pivot_groups: openai-whisper</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="va">+zone_pivot_groups: programming-languages-rest-ps-py-js</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a> # Quickstart: Speech to text with the Azure OpenAI Whisper model</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -23,67 +23,21 @@ The file size limit for the Whisper model is 25 MB. If you need to transcribe a</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a> &gt; [!NOTE]</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a> &gt; The OpenAI Whisper model is currently in Limited Access Public Preview.</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a><span class="st">-## Prerequisites</span></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a><span class="st">-- An Azure subscription. You can [create one for free](https://azure.microsoft.com/free/cognitive-services?azure-portal=true).</span></span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a><span class="st">-- An Azure OpenAI resource with a Whisper model deployed in a [supported region](./concepts/models.md#whisper-models). For more information, see [Create a resource and deploy a model with Azure OpenAI](how-to/create-resource.md).</span></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a><span class="st">-## Set up</span></span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a><span class="st">-### Retrieve key and endpoint</span></span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a><span class="st">-To successfully make a call against Azure OpenAI, you need an *endpoint* and a *key*.</span></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a><span class="st">-|Variable name | Value |</span></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a><span class="st">-|--------------------------|-------------|</span></span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a><span class="st">-| `AZURE_OPENAI_ENDPOINT`               | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in the **Azure OpenAI Studio** &gt; **Playground** &gt; **Code View**. An example endpoint is: `https://aoai-docs.openai.azure.com/`.|</span></span>
<span id="cb47-28"><a href="#cb47-28" aria-hidden="true" tabindex="-1"></a><span class="st">-| `AZURE_OPENAI_API_KEY` | This value can be found in the **Keys &amp; Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|</span></span>
<span id="cb47-29"><a href="#cb47-29" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-30"><a href="#cb47-30" aria-hidden="true" tabindex="-1"></a><span class="st">-Go to your resource in the Azure portal. The **Endpoint and Keys** can be found in the **Resource Management** section. Copy your endpoint and access key as you&#39;ll need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.</span></span>
<span id="cb47-31"><a href="#cb47-31" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-32"><a href="#cb47-32" aria-hidden="true" tabindex="-1"></a><span class="st">-:::image type=&quot;content&quot; source=&quot;media/quickstarts/endpoint.png&quot; alt-text=&quot;Screenshot of the overview UI for an Azure OpenAI resource in the Azure portal with the endpoint &amp; access keys location circled in red.&quot; lightbox=&quot;media/quickstarts/endpoint.png&quot;:::</span></span>
<span id="cb47-33"><a href="#cb47-33" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-34"><a href="#cb47-34" aria-hidden="true" tabindex="-1"></a><span class="st">-### Environment variables</span></span>
<span id="cb47-35"><a href="#cb47-35" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-36"><a href="#cb47-36" aria-hidden="true" tabindex="-1"></a><span class="st">-Create and assign persistent environment variables for your key and endpoint.</span></span>
<span id="cb47-37"><a href="#cb47-37" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-38"><a href="#cb47-38" aria-hidden="true" tabindex="-1"></a><span class="st">-[!INCLUDE [Azure key vault](~/reusable-content/ce-skilling/azure/includes/ai-services/security/azure-key-vault.md)]</span></span>
<span id="cb47-39"><a href="#cb47-39" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-40"><a href="#cb47-40" aria-hidden="true" tabindex="-1"></a><span class="st">-# [Command Line](#tab/command-line)</span></span>
<span id="cb47-41"><a href="#cb47-41" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-42"><a href="#cb47-42" aria-hidden="true" tabindex="-1"></a><span class="st">-```CMD</span></span>
<span id="cb47-43"><a href="#cb47-43" aria-hidden="true" tabindex="-1"></a><span class="st">-setx AZURE_OPENAI_API_KEY &quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; </span></span>
<span id="cb47-44"><a href="#cb47-44" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb47-45"><a href="#cb47-45" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-46"><a href="#cb47-46" aria-hidden="true" tabindex="-1"></a><span class="st">-```CMD</span></span>
<span id="cb47-47"><a href="#cb47-47" aria-hidden="true" tabindex="-1"></a><span class="st">-setx AZURE_OPENAI_ENDPOINT &quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; </span></span>
<span id="cb47-48"><a href="#cb47-48" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb47-49"><a href="#cb47-49" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-50"><a href="#cb47-50" aria-hidden="true" tabindex="-1"></a><span class="st">-# [PowerShell](#tab/powershell)</span></span>
<span id="cb47-51"><a href="#cb47-51" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-52"><a href="#cb47-52" aria-hidden="true" tabindex="-1"></a><span class="st">-```powershell</span></span>
<span id="cb47-53"><a href="#cb47-53" aria-hidden="true" tabindex="-1"></a><span class="st">-[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_API_KEY&#39;, &#39;REPLACE_WITH_YOUR_KEY_VALUE_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb47-54"><a href="#cb47-54" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb47-55"><a href="#cb47-55" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone pivot=&quot;rest-api&quot;</span></span>
<span id="cb47-56"><a href="#cb47-56" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-57"><a href="#cb47-57" aria-hidden="true" tabindex="-1"></a><span class="st">-```powershell</span></span>
<span id="cb47-58"><a href="#cb47-58" aria-hidden="true" tabindex="-1"></a><span class="st">-[System.Environment]::SetEnvironmentVariable(&#39;AZURE_OPENAI_ENDPOINT&#39;, &#39;REPLACE_WITH_YOUR_ENDPOINT_HERE&#39;, &#39;User&#39;)</span></span>
<span id="cb47-59"><a href="#cb47-59" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb47-60"><a href="#cb47-60" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [REST API quickstart](includes/whisper-rest.md)]</span></span>
<span id="cb47-61"><a href="#cb47-61" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-62"><a href="#cb47-62" aria-hidden="true" tabindex="-1"></a><span class="st">-# [Bash](#tab/bash)</span></span>
<span id="cb47-63"><a href="#cb47-63" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone-end</span></span>
<span id="cb47-64"><a href="#cb47-64" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-65"><a href="#cb47-65" aria-hidden="true" tabindex="-1"></a><span class="st">-```Bash</span></span>
<span id="cb47-66"><a href="#cb47-66" aria-hidden="true" tabindex="-1"></a><span class="st">-echo export AZURE_OPENAI_API_KEY=&quot;REPLACE_WITH_YOUR_KEY_VALUE_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb47-67"><a href="#cb47-67" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb47-68"><a href="#cb47-68" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone pivot=&quot;programming-language-python&quot;</span></span>
<span id="cb47-69"><a href="#cb47-69" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-70"><a href="#cb47-70" aria-hidden="true" tabindex="-1"></a><span class="st">-```Bash</span></span>
<span id="cb47-71"><a href="#cb47-71" aria-hidden="true" tabindex="-1"></a><span class="st">-echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/environment &amp;&amp; source /etc/environment</span></span>
<span id="cb47-72"><a href="#cb47-72" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb47-73"><a href="#cb47-73" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb47-74"><a href="#cb47-74" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Python SDK quickstart](includes/whisper-python.md)]</span></span>
<span id="cb47-75"><a href="#cb47-75" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-76"><a href="#cb47-76" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone-end</span></span>
<span id="cb47-77"><a href="#cb47-77" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-78"><a href="#cb47-78" aria-hidden="true" tabindex="-1"></a><span class="st">-::: zone pivot=&quot;rest-api&quot;</span></span>
<span id="cb47-79"><a href="#cb47-79" aria-hidden="true" tabindex="-1"></a><span class="va">+::: zone pivot=&quot;programming-language-javascript&quot;</span></span>
<span id="cb47-80"><a href="#cb47-80" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-81"><a href="#cb47-81" aria-hidden="true" tabindex="-1"></a><span class="st">-[!INCLUDE [REST API quickstart](includes/whisper-rest.md)]</span></span>
<span id="cb47-82"><a href="#cb47-82" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [JavaScript quickstart](includes/whisper-javascript.md)]</span></span>
<span id="cb47-83"><a href="#cb47-83" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-84"><a href="#cb47-84" aria-hidden="true" tabindex="-1"></a> ::: zone-end</span>
<span id="cb47-85"><a href="#cb47-85" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-86"><a href="#cb47-86" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -93,12 +47,6 @@ echo export AZURE_OPENAI_ENDPOINT=&quot;REPLACE_WITH_YOUR_ENDPOINT_HERE&quot; &gt;&gt; /etc/envi</span></span>
<span id="cb47-87"><a href="#cb47-87" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-88"><a href="#cb47-88" aria-hidden="true" tabindex="-1"></a> ::: zone-end</span>
<span id="cb47-89"><a href="#cb47-89" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-90"><a href="#cb47-90" aria-hidden="true" tabindex="-1"></a><span class="st">-::: zone pivot=&quot;programming-language-python&quot;</span></span>
<span id="cb47-91"><a href="#cb47-91" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-92"><a href="#cb47-92" aria-hidden="true" tabindex="-1"></a><span class="st">-[!INCLUDE [Python quickstart](includes/whisper-python.md)]</span></span>
<span id="cb47-93"><a href="#cb47-93" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-94"><a href="#cb47-94" aria-hidden="true" tabindex="-1"></a><span class="st">-::: zone-end</span></span>
<span id="cb47-95"><a href="#cb47-95" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb47-96"><a href="#cb47-96" aria-hidden="true" tabindex="-1"></a> ## Clean up resources</span>
<span id="cb47-97"><a href="#cb47-97" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb47-98"><a href="#cb47-98" aria-hidden="true" tabindex="-1"></a> If you want to clean up and remove an Azure OpenAI resource, you can delete the resource. Before deleting the resource, you must first delete any deployed models.</span></code></pre></div>
</details>
<h3 id="summary-23">Summary</h3>
<div class="sourceCode" id="cb48"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;breaking change&quot;</span><span class="fu">,</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Whisperモデルのクイックスタートガイドの大幅な改訂&quot;</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-23">Explanation</h3>
<p>このコードの変更は、<code>whisper-quickstart.md</code>
ファイルに対するもので、大幅な改訂が行われました。主な変更点は以下の通りです。</p>
<ol class="incremental" type="1">
<li><p><strong>内容の整理と簡素化</strong>:
以前のバージョンでは多くの詳細が含まれていた「Prerequisites」セクションや環境変数の設定手順が削除されました。これにより、クイックスタートガイドがよりシンプルかつ直感的になり、必要な情報へのアクセスが容易になっています。</p></li>
<li><p><strong>新しいゾーンピボットの導入</strong>:
新しいゾーンピボットが追加され、プログラミング言語のセクションが効果的に管理されています。これにより、ユーザーが利用したい具体的なプログラミング言語に基づいて、迅速に情報を取得できるようになっています。</p></li>
<li><p><strong>REST APIと他のプログラミング言語の比較</strong>:
クイックスタートガイド内で、REST
APIのクイックスタートとJavaScriptやPythonのクイックスタートが明確に区別され、言語ごとの選択肢がダイナミックに表示されています。</p></li>
<li><p><strong>不要な部分の削除</strong>:
認証に必要な情報やAPIキーの取得方法など、重複した情報が削除され、全体的なファイルサイズが減少し、より効率的になっています。</p></li>
</ol>
<p>この改訂により、Whisperモデルのクイックスタートが簡潔に整理され、特にプログラミング言語に応じた指示が明確化されたことで、開発者にとってより使いやすいリソースが提供されています。しかし、情報の一部が削除されたため、ユーザーは新しい構成に適応する必要があります。全体として、ガイドは使用手順が直感的に理解できるようになっていますが、詳細な情報が必要な場合は他のリソースを参照する必要があります。</p>
</body>
</html>
