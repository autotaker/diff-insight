<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="dcterms.date" content="2024-09-10" />
  <title>Diff Insight Report</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Diff Insight Report</h1>
<p class="date">2024-09-10</p>
</header>
<p><a
href="https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:3501c57...MicrosoftDocs:67d9a22"
target="_blank">View Diff on GitHub</a></p>
<p><format><br />
# ハイライト<br />
このコード差分は、Azure OpenAI、およびAzure Machine
Learning関連のドキュメントのバージョン更新、新機能追加、および修正を対象としています。以下の新機能および重要な変更点があります。</p>
<h2 id="新機能">新機能</h2>
<ul class="incremental">
<li><code>articles/ai-studio/includes/install-cli.md</code>：Azure
CLIのインストール手順の追加</li>
<li><code>articles/ai-studio/includes/install-promptflow.md</code>：Prompt
Flow SDKのインストール手順の追加</li>
<li><code>articles/ai-studio/includes/install-python.md</code>：Python環境の設定手順の追加</li>
<li><code>articles/ai-studio/tutorials/copilot-sdk-create-resources.md</code>：カスタムチャットアプリ構築のためのリソース作成ガイドの追加</li>
<li>汎用コンテナレジストリへの接続方法を示す画像の追加(<code>media</code>フォルダ内のいくつかの画像)</li>
</ul>
<h2 id="破壊的変更">破壊的変更</h2>
<p>特に破壊的な変更はありませんが、いくつかの重要な更新が含まれています。</p>
<h2 id="その他の更新">その他の更新</h2>
<ul class="incremental">
<li>日付や名称の更新</li>
<li>Azure OpenAIおよびMachine
Learning関連の複数のファイルの内容の整理と更新</li>
<li>チュートリアルファイルのリネームおよび構成の見直し</li>
<li>関連リンクとドキュメントの整理</li>
</ul>
<h1 id="インサイト">インサイト</h1>
<p>このコード差分は、複数のAzure OpenAIおよびAzure Machine
Learning関連のドキュメントに対する詳細な更新を反映しています。</p>
<p>特に、APIバージョンや新機能の追加に関する詳細な情報が提供されており、ユーザーが最新の技術を適切に利用できるようにサポートしています。例えば、Azure
OpenAIのドキュメントでは構造化出力のサポートや大容量ファイルのアップロードAPIなどの新機能が追加されています。一方、Azure
Machine
Learningのドキュメントでは、汎用コンテナレジストリの接続方法やPython環境の設定手順が新たに追加され、ユーザーが各種リソースやツールを効率的に利用できるように構築されています。</p>
<p>また、リネームされたチュートリアルやリンクされた他の共通ドキュメントも、ユーザーエクスペリエンスを向上させ、一貫性のある情報提供を可能にしています。例えば、Azure
AI StudioにおけるAzure
CLIやPython環境の設定に関する手順の簡素化は、ドキュメントの保守性を高め、ユーザーが必要な情報を迅速に探しやすくするための戦略的な変更です。</p>
<p>これらの更新は、ユーザーがAzure OpenAIおよびAzure Machine
Learningの最新機能を最大限に活用できるよう、技術ドキュメントの信頼性と有用性を強化するために慎重に行われています。<br />
</format></p>
<h1 id="summary-table">Summary Table</h1>
<table style="width:100%;">
<colgroup>
<col style="width: 23%" />
<col style="width: 11%" />
<col style="width: 25%" />
<col style="width: 15%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
</colgroup>
<thead>
<tr>
<th>Filename</th>
<th>Type</th>
<th>Title</th>
<th>Status</th>
<th>A</th>
<th>D</th>
<th>M</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#item-1cad50">api-version-deprecation.md</a></td>
<td>minor update</td>
<td>APIバージョンの更新と変更の追加</td>
<td>modified</td>
<td>13</td>
<td>2</td>
<td>15</td>
</tr>
<tr>
<td><a href="#item-db2c37">models.md</a></td>
<td>minor update</td>
<td>モデル情報の更新と地域の追加</td>
<td>modified</td>
<td>5</td>
<td>3</td>
<td>8</td>
</tr>
<tr>
<td><a href="#item-a25fa2">api-surface.md</a></td>
<td>minor update</td>
<td>APIサーフェスのバージョン更新</td>
<td>modified</td>
<td>4</td>
<td>4</td>
<td>8</td>
</tr>
<tr>
<td><a href="#item-24bf0f">latest-inference-preview.md</a></td>
<td>minor update</td>
<td>最新推論プレビューAPIドキュメントの更新</td>
<td>modified</td>
<td>636</td>
<td>495</td>
<td>1131</td>
</tr>
<tr>
<td><a href="#item-389aa1">quota.md</a></td>
<td>minor update</td>
<td>クォータ情報の更新</td>
<td>modified</td>
<td>4</td>
<td>3</td>
<td>7</td>
</tr>
<tr>
<td><a href="#item-e197a2">reference-preview.md</a></td>
<td>minor update</td>
<td>最新プレビューAPIリリースの更新</td>
<td>modified</td>
<td>2</td>
<td>2</td>
<td>4</td>
</tr>
<tr>
<td><a href="#item-7b1183">reference.md</a></td>
<td>minor update</td>
<td>ドキュメントの日付更新</td>
<td>modified</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td><a href="#item-8f87b5">fine-tune.md</a></td>
<td>minor update</td>
<td>ファインチューニングチュートリアルの更新</td>
<td>modified</td>
<td>43</td>
<td>41</td>
<td>84</td>
</tr>
<tr>
<td><a href="#item-868060">install-cli.md</a></td>
<td>new feature</td>
<td>Azure CLIのインストール手順追加</td>
<td>added</td>
<td>41</td>
<td>0</td>
<td>41</td>
</tr>
<tr>
<td><a href="#item-40e054">install-promptflow.md</a></td>
<td>new feature</td>
<td>Prompt Flow SDKのインストール手順追加</td>
<td>added</td>
<td>24</td>
<td>0</td>
<td>24</td>
</tr>
<tr>
<td><a href="#item-f5f09e">install-python.md</a></td>
<td>new feature</td>
<td>Python環境の設定手順追加</td>
<td>added</td>
<td>49</td>
<td>0</td>
<td>49</td>
</tr>
<tr>
<td><a href="#item-8a5082">get-started-code.md</a></td>
<td>minor update</td>
<td>Azure CLIおよびPython環境設定の指示を統合</td>
<td>modified</td>
<td>3</td>
<td>78</td>
<td>81</td>
</tr>
<tr>
<td><a href="#item-2745cd">toc.yml</a></td>
<td>minor update</td>
<td>チャットアプリに関する手順の名称変更とリンク追加</td>
<td>modified</td>
<td>7</td>
<td>4</td>
<td>11</td>
</tr>
<tr>
<td><a href="#item-b77dba">copilot-sdk-build-rag.md</a></td>
<td>minor update</td>
<td>チュートリアル内容のリネームと構造のアップデート</td>
<td>modified</td>
<td>87</td>
<td>162</td>
<td>249</td>
</tr>
<tr>
<td><a href="#item-552960">copilot-sdk-create-resources.md</a></td>
<td>new feature</td>
<td>カスタムチャットアプリ構築のためのリソース作成ガイド</td>
<td>added</td>
<td>153</td>
<td>0</td>
<td>153</td>
</tr>
<tr>
<td><a href="#item-96e7b3">copilot-sdk-evaluate-deploy.md</a></td>
<td>minor update</td>
<td>チャットアプリの評価とデプロイに関するガイドの更新</td>
<td>modified</td>
<td>32</td>
<td>33</td>
<td>65</td>
</tr>
<tr>
<td><a href="#item-9b3912">concept-soft-delete.md</a></td>
<td>minor update</td>
<td>ワークスペースのソフト削除に関するガイドの更新</td>
<td>modified</td>
<td>38</td>
<td>37</td>
<td>75</td>
</tr>
<tr>
<td><a href="#item-edd02a">how-to-auto-train-forecast.md</a></td>
<td>minor update</td>
<td>時系列予測のためのAutoML設定に関するガイドの更新</td>
<td>modified</td>
<td>174</td>
<td>157</td>
<td>331</td>
</tr>
<tr>
<td><a href="#item-5aa1c8">how-to-connection.md</a></td>
<td>new feature</td>
<td>汎用コンテナレジストリへの接続設定の追加</td>
<td>modified</td>
<td>120</td>
<td>0</td>
<td>120</td>
</tr>
<tr>
<td><a href="#item-2fb579">how-to-deploy-models-jamba.md</a></td>
<td>minor update</td>
<td>AI21のJambaファミリーモデルのデプロイに関するガイドの更新</td>
<td>modified</td>
<td>38</td>
<td>27</td>
<td>65</td>
</tr>
<tr>
<td><a
href="#item-4de1d8">how-to-prepare-datasets-for-automl-images.md</a></td>
<td>minor update</td>
<td>自動機械学習のための画像データセット準備に関するガイドの更新</td>
<td>modified</td>
<td>44</td>
<td>43</td>
<td>87</td>
</tr>
<tr>
<td><a href="#item-d072d3">how-to-connect-add-connection.png</a></td>
<td>new feature</td>
<td>接続の追加方法を示す画像の追加</td>
<td>added</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><a
href="#item-29d619">how-to-connect-generic-container-registry.png</a></td>
<td>new feature</td>
<td>汎用コンテナレジストリへの接続方法を示す画像の追加</td>
<td>added</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><a href="#item-7aa2af">how-to-manage-connections-create.png</a></td>
<td>new feature</td>
<td>接続管理の作成方法を示す画像の追加</td>
<td>added</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><a href="#item-e1c1a2">samples-notebooks.md</a></td>
<td>minor update</td>
<td>サンプルノートブック記事の更新</td>
<td>modified</td>
<td>16</td>
<td>16</td>
<td>32</td>
</tr>
<tr>
<td><a href="#item-cbc1da">toc.yml</a></td>
<td>minor update</td>
<td>トピックの名称更新</td>
<td>modified</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td><a
href="#item-990f5d">how-to-deploy-azure-kubernetes-service.md</a></td>
<td>minor update</td>
<td>Azure Kubernetes Service への ML
モデルのデプロイに関するドキュメントの更新</td>
<td>modified</td>
<td>8</td>
<td>7</td>
<td>15</td>
</tr>
<tr>
<td><a href="#item-f4b00a">how-to-select-algorithms.md</a></td>
<td>minor update</td>
<td>アルゴリズム選択に関する表の編集</td>
<td>modified</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
</tbody>
</table>
<h1 id="modified-contents">Modified Contents</h1>
<h2
id="item-1cad50">articles/ai-services/openai/api-version-deprecation.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb1"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -23,8 +23,8 @@ This article is to help you understand the support lifecycle for the Azure OpenA</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a> Azure OpenAI API latest release:</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="st">-- Inference: [2024-07-01-preview](https://github.com/Azure/azure-rest-api-specs/blob/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/preview/2024-07-01-preview/inference.json)</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="st">-- Authoring: [2024-07-01-preview](https://github.com/Azure/azure-rest-api-specs/blob/main/specification/cognitiveservices/data-plane/AzureOpenAI/authoring/preview/2024-07-01-preview/azureopenai.json)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="va">+- Inference: [2024-08-01-preview](https://github.com/Azure/azure-rest-api-specs/blob/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/preview/2024-08-01-preview/inference.json)</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="va">+- Authoring: [2024-08-01-preview](https://github.com/Azure/azure-rest-api-specs/blob/main/specification/cognitiveservices/data-plane/AzureOpenAI/authoring/preview/2024-08-01-preview/azureopenai.json)</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a> This version contains support for the latest Azure OpenAI features including:</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -38,6 +38,17 @@ This version contains support for the latest Azure OpenAI features including:</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a> - [Function calling](./how-to/function-calling.md)  [**Added in 2023-07-01-preview**]</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a> - [Retrieval augmented generation with your data feature](./use-your-data-quickstart.md).  [**Added in 2023-06-01-preview**]</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="va">+## Changes between 2024-07-01-preview and 2024-08-01-preview API specification</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="va">+- [Structured outputs support](./how-to/structured-outputs.md).</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="va">+- Large file upload API added.</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="va">+- On your data changes:</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="va">+    * [Mongo DB integration](./reference-preview.md#example-7).</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="va">+    * `role_information` parameter removed.</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="va">+    *  [`rerank_score`](https://github.com/Azure/azure-rest-api-specs/blob/2b700e5e84d4a95880d373e6a4bce5d16882e4b5/specification/cognitiveservices/data-plane/AzureOpenAI/inference/preview/2024-08-01-preview/inference.json#L5532) added to citation object.</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="va">+    * AML datasource removed.</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="va">+    * AI Search vectorization integration improvements.</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a> ## Changes between 2024-5-01-preview and 2024-07-01-preview API specification</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a> - [Batch API support added](./how-to/batch.md)</span></code></pre></div>
</details>
<h3 id="summary">Summary</h3>
<div class="sourceCode" id="cb2"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-services/openai/api-version-deprecation.md&quot;</span><span class="fu">,</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;APIバージョンの更新と変更の追加&quot;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation">Explanation</h3>
<p>この変更は、Azure OpenAI
APIのドキュメントにおけるバージョンアップデートに関するものであり、2024年7月1日のプレビューから2024年8月1日のプレビューにかけての主な変更点を記載しています。具体的には、推論と著作の最新リリース日が2024年7月1日から2024年8月1日へと変更され、いくつかの新機能と削除されたパラメータについての詳細が追加されています。</p>
<p>変更された内容には、構造化出力のサポートや大容量ファイルのアップロードAPIの追加、MongoDB統合に関する変更が含まれています。また、<code>role_information</code>パラメータが削除され、引用オブジェクトに<code>rerank_score</code>が追加されるなど、API仕様に関する重要なアップデートが反映されています。これにより、ユーザーは新しい機能を適切に利用できるようになります。</p>
<h2 id="item-db2c37">articles/ai-services/openai/concepts/models.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb3"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -4,7 +4,7 @@ titleSuffix: Azure OpenAI</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a> description: Learn about the different model capabilities that are available with Azure OpenAI.</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a> ms.topic: conceptual</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 08/28/2024</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a> ms.custom: references_regions, build-2023, build-2023-dataai, refefences_regions</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a> author: mrbullwinkle #ChrisHMSFT</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -198,7 +198,8 @@ For more information on Provisioned deployments, see our [Provisioned guidance](</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a> - koreacentral      </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a> - northcentralus    </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a> - norwayeast        </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="st">-- polandcentral     </span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="va">+- polandcentral</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="va">+- spaincentral     </span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a> - southafricanorth  </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a> - southcentralus    </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a> - southindia        </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -214,6 +215,7 @@ For more information on Provisioned deployments, see our [Provisioned guidance](</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a> **Supported regions:**</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a> - eastus</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="va">+- swedencentral</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a> ### Global batch model availability</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -313,7 +315,7 @@ These models can only be used with Embedding API requests.</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a> | `gpt-35-turbo` (0125)  | East US2 &lt;br&gt; North Central US &lt;br&gt; Sweden Central &lt;br&gt; Switzerland West | 16,385 | Sep 2021 |</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a> | `gpt-4` (0613) &lt;sup&gt;**1**&lt;/sup&gt; | North Central US &lt;br&gt; Sweden Central | 8192 | Sep 2021 |</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a> | `gpt-4o-mini` &lt;sup&gt;**1**&lt;/sup&gt; (2024-07-18) | North Central US &lt;br&gt; Sweden Central | Input: 128,000 &lt;br&gt; Output: 16,384  &lt;br&gt; Training example context length: 64,536 | Oct 2023 |</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="st">-| `gpt-4o` &lt;sup&gt;**1**&lt;/sup&gt; (2024-08-06) | North Central US &lt;br&gt; Sweden Central | Input: 128,000 &lt;br&gt; Output: 16,384  &lt;br&gt; Training example context length: 64,536 | Oct 2023 | </span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="va">+| `gpt-4o` &lt;sup&gt;**1**&lt;/sup&gt; (2024-08-06) | East US2 &lt;br&gt; North Central US &lt;br&gt; Sweden Central | Input: 128,000 &lt;br&gt; Output: 16,384  &lt;br&gt; Training example context length: 64,536 | Oct 2023 | </span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a> **&lt;sup&gt;1&lt;/sup&gt;** GPT-4, GPT-4o, and GPT-4o mini fine-tuning is currently in public preview. See our [GPT-4, GPT-4o,  &amp; GPT-4o mini fine-tuning safety evaluation guidance](/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython-new&amp;pivots=programming-language-python#safety-evaluation-gpt-4-fine-tuning---public-preview) for more information.</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-1">Summary</h3>
<div class="sourceCode" id="cb4"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-services/openai/concepts/models.md&quot;</span><span class="fu">,</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;モデル情報の更新と地域の追加&quot;</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-1">Explanation</h3>
<p>この変更は、Azure
OpenAIのモデルに関するドキュメントに対して行われたもので、情報の更新が含まれています。具体的には、ドキュメントの日付が2024年8月28日から2024年9月9日に変更され、サポートされる地域リストに「スウェーデン中部」が追加されたことが記されています。</p>
<p>さらに、いくつかのモデルの利用可能地域が修正され、「gpt-4o」の利用地域が「北中部US」および「スウェーデン中部」から「東US2」「北中部US」「スウェーデン中部」に拡大されています。このような更新により、ユーザーは最新のモデル能力とその利用可能地域に関する正確な情報を得ることができます。</p>
<h2
id="item-a25fa2">articles/ai-services/openai/includes/api-surface.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb5"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -5,7 +5,7 @@ description: Information on the division of control plane and data plane API sur</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a> ms.topic: include</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 08/14/2024</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -21,9 +21,9 @@ Each API surface/specification encapsulates a different set of Azure OpenAI capa</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a> | API | Latest preview release | Latest GA release | Specifications | Description |</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a> |:---|:----|:----|:----|:---|</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Control plane** | `2024-04-01-preview` | [`2023-05-01`](/rest/api/aiservices/accountmanagement/deployments/create-or-update?view=rest-aiservices-accountmanagement-2023-05-01&amp;tabs=HTTP&amp;preserve-view=true) | [Spec files](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/resource-manager/Microsoft.CognitiveServices) | Azure OpenAI shares a common control plane with all other Azure AI Services. The control plane API is used for things like [creating Azure OpenAI resources](/rest/api/aiservices/accountmanagement/accounts/create?view=rest-aiservices-accountmanagement-2023-05-01&amp;tabs=HTTP&amp;preserve-view=true), [model deployment](/rest/api/aiservices/accountmanagement/deployments/create-or-update?view=rest-aiservices-accountmanagement-2023-05-01&amp;tabs=HTTP&amp;preserve-view=true), and other higher level resource management tasks. The control plane also governs what is possible to do with capabilities like Azure Resource Manager, Bicep, Terraform, and Azure CLI.|</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Data plane - authoring** | [`2024-07-01-preview`](/rest/api/azureopenai/operation-groups?view=rest-azureopenai-2024-07-01-preview&amp;preserve-view=true) | [`2024-06-01`](/rest/api/azureopenai/operation-groups?view=rest-azureopenai-2024-06-01&amp;preserve-view=true) | [Spec files](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/authoring) | The data plane authoring API controls [fine-tuning](/rest/api/azureopenai/fine-tuning?view=rest-azureopenai-2024-07-01-preview&amp;preserve-view=true), [file-upload](/rest/api/azureopenai/files/upload?view=rest-azureopenai-2024-07-01-preview&amp;tabs=HTTP&amp;preserve-view=true), [ingestion jobs](/rest/api/azureopenai/ingestion-jobs/create?view=rest-azureopenai-2024-07-01-preview&amp;tabs=HTTP&amp;preserve-view=true), [batch](/rest/api/azureopenai/batch?view=rest-azureopenai-2024-07-01-preview&amp;tabs=HTTP&amp;preserve-view=true) and certain [model level queries](/rest/api/azureopenai/models/get?view=rest-azureopenai-2024-07-01-preview&amp;tabs=HTTP&amp;preserve-view=true)</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="st">-| **Data plane - inference** | [`2024-07-01-preview`](/azure/ai-services/openai/reference-preview#data-plane-inference) | [`2024-06-01`](/azure/ai-services/openai/reference#data-plane-inference) | [Spec files](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference) | The data plane inference API provides the inference capabilities/endpoints for features like completions, chat completions, embeddings, speech/whisper, on your data, Dall-e, assistants, etc. |</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Control plane** | [`2024-06-01-preview`](/rest/api/aiservices/accountmanagement/operation-groups?view=rest-aiservices-accountmanagement-2024-06-01-preview&amp;preserve-view=true) | [`2023-05-01`](/rest/api/aiservices/accountmanagement/deployments/create-or-update?view=rest-aiservices-accountmanagement-2023-05-01&amp;tabs=HTTP&amp;preserve-view=true) | [Spec files](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/resource-manager/Microsoft.CognitiveServices) | Azure OpenAI shares a common control plane with all other Azure AI Services. The control plane API is used for things like [creating Azure OpenAI resources](/rest/api/aiservices/accountmanagement/accounts/create?view=rest-aiservices-accountmanagement-2023-05-01&amp;tabs=HTTP&amp;preserve-view=true), [model deployment](/rest/api/aiservices/accountmanagement/deployments/create-or-update?view=rest-aiservices-accountmanagement-2023-05-01&amp;tabs=HTTP&amp;preserve-view=true), and other higher level resource management tasks. The control plane also governs what is possible to do with capabilities like Azure Resource Manager, Bicep, Terraform, and Azure CLI.|</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Data plane - authoring** | `2024-08-01-preview` | [`2024-06-01`](/rest/api/azureopenai/operation-groups?view=rest-azureopenai-2024-06-01&amp;preserve-view=true) | [Spec files](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/authoring) | The data plane authoring API controls [fine-tuning](/rest/api/azureopenai/fine-tuning?view=rest-azureopenai-2024-08-01-preview&amp;preserve-view=true), [file-upload](/rest/api/azureopenai/files/upload?view=rest-azureopenai-2024-08-01-preview&amp;tabs=HTTP&amp;preserve-view=true), [ingestion jobs](/rest/api/azureopenai/ingestion-jobs/create?view=rest-azureopenai-2024-08-01-preview&amp;tabs=HTTP&amp;preserve-view=true), [batch](/rest/api/azureopenai/batch?view=rest-azureopenai-2024-08-01-preview&amp;tabs=HTTP&amp;preserve-view=true) and certain [model level queries](/rest/api/azureopenai/models/get?view=rest-azureopenai-2024-08-01-preview&amp;tabs=HTTP&amp;preserve-view=true)</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="va">+| **Data plane - inference** | [`2024-08-01-preview`](/azure/ai-services/openai/reference-preview#data-plane-inference) | [`2024-06-01`](/azure/ai-services/openai/reference#data-plane-inference) | [Spec files](https://github.com/Azure/azure-rest-api-specs/tree/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference) | The data plane inference API provides the inference capabilities/endpoints for features like completions, chat completions, embeddings, speech/whisper, on your data, Dall-e, assistants, etc. |</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a> ## Authentication</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-2">Summary</h3>
<div class="sourceCode" id="cb6"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-services/openai/includes/api-surface.md&quot;</span><span class="fu">,</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;APIサーフェスのバージョン更新&quot;</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-2">Explanation</h3>
<p>この変更は、Azure
OpenAIのAPIサーフェスに関するドキュメントの更新であり、各APIの最新のプレビューリリースとGAリリースの日付が変更されています。具体的には、制御プレーンの最新プレビューリリースが「2024-04-01」から「2024-06-01」に、データプレーンの著作機能に関する最新プレビューリリースが「2024-07-01」から「2024-08-01」に更新されています。</p>
<p>これにより、ユーザーは最新のAPIリリース情報を得ることができ、それぞれのAPIが提供する機能やリソース管理タスクに対する理解を深めることができます。また、ドキュメントの日付も2024年8月14日から2024年9月9日に変更されているため、最新の状態が反映されています。このような変更は、開発者が新しい機能へのアクセス方法を把握し、適切に利用できるようサポートします。</p>
<h2
id="item-24bf0f">articles/ai-services/openai/includes/api-versions/latest-inference-preview.md</h2>
<h3 id="summary-3">Summary</h3>
<div class="sourceCode" id="cb7"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-services/openai/includes/api-versions/latest-inference-preview.md&quot;</span><span class="fu">,</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;最新推論プレビューAPIドキュメントの更新&quot;</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-3">Explanation</h3>
<p>この変更は、Azure
OpenAIの最新推論プレビューAPIに関するドキュメントの大幅な更新を示しています。追加された行が636行、削除された行が495行、全体的に1131行の変更がなされました。これにより、APIが提供する最新の推論機能やそれに関連する使用方法が詳述され、より包括的な情報が提供されています。</p>
<p>更新内容には、新しい推論アルゴリズムやAPIの改善点、使用例、エラーハンドリングやパフォーマンスに関する詳細などが含まれている可能性があります。このようなアップデートは、開発者が最新のAPI仕様を理解し、実装するのに役立ちます。また、ドキュメント全体の内容が整備され、最新の技術やトレンドに合わせた情報が提供されることで、ユーザーがより円滑にAzure
OpenAIの機能を活用できるようになります。</p>
<h2
id="item-389aa1">articles/ai-services/openai/includes/model-matrix/quota.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb8"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -5,7 +5,7 @@ description: Azure OpenAI model quota</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a> ms.topic: include</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 08/29/2024</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -15,7 +15,7 @@ ms.date: 08/29/2024</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a> | brazilsouth        | -       | -           | -             | -               | -        | -             | -              | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | -                        | -                        | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a> | canadaeast         | 40 K    | 80 K        | 80 K          | -               | -        | -             | 300 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | 350 K                    | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a> | eastus             | -       | -           | 80 K          | -               | 1 M      | 2 M           | 240 K          | 240 K                   | 30 M                      | 50 M                           | 2 M                            | 5 B                     | 5 B                          | 150 M                  | 300 M                        | 10 B                          | 240 K                    | 350 K                    | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="st">-| eastus2            | -       | -           | 80 K          | -               | 1 M      | -             | 300 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | 350 K                    | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | 250 K                     | 250 K                          | 250 K                          |</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="va">+| eastus2            | -       | -           | 80 K          | -               | 1 M      | -             | 300 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | 350 K                    | 350 K                    | 100 K               | -                        | -                  | -             | -                        | -             | -                        | 250 K                     | 250 K                          | 250 K                          |</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a> | francecentral      | 20 K    | 60 K        | 80 K          | -               | -        | -             | 240 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 240 K                    | -                        | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a> | germanywestcentral | -       | -           | -             | -               | -        | -             | -              | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | -                        | -                        | -                        | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a> | japaneast          | -       | -           | -             | 30 K            | -        | -             | 300 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | -                        | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -26,10 +26,11 @@ ms.date: 08/29/2024</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a> | southafricanorth   | -       | -           | -             | -               | -        | -             | -              | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | -                        | -                        | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a> | southcentralus     | -       | -           | 80 K          | -               | 1 M      | -             | 240 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 240 K                    | -                        | -                        | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a> | southindia         | -       | -           | 150 K         | -               | -        | -             | 300 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | -                        | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="va">+| spaincentral       | -       | -           | -             | -               | -        | -             | -              | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | -                        | -                        | -                        | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a> | swedencentral      | 40 K    | 80 K        | 150 K         | 30 K            | 1 M      | 2 M           | 300 K          | 240 K                   | 30 M                      | 50 M                           | 2 M                            | 5 B                     | 5 B                          | 150 M                  | 300 M                        | 10 B                          | 350 K                    | -                        | 350 K                    | 100 K               | 100 K                    | 100 K              | 240 K         | 250 K                    | 240 K         | 250 K                    | 250 K                     | 250 K                          | 250 K                          |</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a> | switzerlandnorth   | 40 K    | 80 K        | -             | 30 K            | -        | -             | 300 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | -                        | -                        | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a> | switzerlandwest    | -       | -           | -             | -               | -        | -             | -              | -                       | -                         | -                              | -                              | -                       | -                            | -                      | -                            | -                             | -                        | -                        | -                        | -                   | -                        | -                  | -             | 250 K                    | -             | 250 K                    | 250 K                     | 250 K                          | 250 K                          |</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a> | uksouth            | -       | -           | 80 K          | -               | -        | -             | 240 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | -                        | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a> | westeurope         | -       | -           | -             | -               | -        | -             | 240 K          | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 240 K                    | -                        | -                        | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a> | westus             | -       | -           | 80 K          | 30 K            | 1 M      | -             | 300 K          | -                       | 30 M                      | -                              | 2 M                            | 5 B                     | 5 B                          | 150 M                  | 300 M                        | 10 B                          | 350 K                    | -                        | -                        | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="st">-| westus3            | -       | -           | 80 K          | -               | 1 M      | -             | -              | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | -                        | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>\ No newline at end of file</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="va">+| westus3            | -       | -           | 80 K          | -               | 1 M      | -             | -              | -                       | 30 M                      | -                              | 2 M                            | -                       | -                            | -                      | -                            | -                             | 350 K                    | -                        | 350 K                    | -                   | -                        | -                  | -             | -                        | -             | -                        | -                         | -                              | -                              |</span></span></code></pre></div>
</details>
<h3 id="summary-4">Summary</h3>
<div class="sourceCode" id="cb9"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-services/openai/includes/model-matrix/quota.md&quot;</span><span class="fu">,</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;クォータ情報の更新&quot;</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-4">Explanation</h3>
<p>この変更は、Azure
OpenAIのクォータに関するドキュメントの更新を示しています。4行の新しい情報が追加され、3行の情報が削除され、合計で7行の変更がありました。この更新は、さまざまなリージョンにおけるAPI利用の制限に関する正確な情報を提供することを目的としています。</p>
<p>特に、新たに追加された情報には、特定のリージョンにおける新しいクォータ制限や、以前のクォータの修正が含まれている可能性があります。これにより、開発者は各リージョンにおけるAPI利用可能性を正確に把握し、アプリケーションの設計やデプロイメントに役立てることができます。また、特定のクォータに合わせた最適化を行うことで、リソースの管理を向上させることが期待されます。全体として、この更新はAzure
OpenAIの利用経験を向上させるための重要なステップです。</p>
<h2
id="item-e197a2">articles/ai-services/openai/reference-preview.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb10"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -5,7 +5,7 @@ description: Learn how to use Azure OpenAI&#39;s latest preview REST API. In this ar</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a> ms.topic: conceptual</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 07/09/2024</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a> author: mrbullwinkle</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a> ms.author: mbullwin</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a> recommendations: false</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -20,7 +20,7 @@ This article provides details on the inference REST API endpoints for Azure Open</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a> ## Data plane inference</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="st">-The rest of the article covers the latest preview release of the Azure OpenAI data plane inference specification, `2024-05-01-preview`. This article includes documentation for the latest preview capabilities like assistants, threads, and vector stores.</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="va">+The rest of the article covers the latest preview release of the Azure OpenAI data plane inference specification, `2024-08-01-preview`. This article includes documentation for the latest preview capabilities like assistants, threads, and vector stores.</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a> If you&#39;re looking for documentation on the latest GA API release, refer to the [latest GA data plane inference API](./reference.md)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-5">Summary</h3>
<div class="sourceCode" id="cb11"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-services/openai/reference-preview.md&quot;</span><span class="fu">,</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;最新プレビューAPIリリースの更新&quot;</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-5">Explanation</h3>
<p>この変更は、Azure OpenAIの最新プレビューREST
APIに関するドキュメントの更新を示しています。具体的には、2行が新しく追加され、2行が削除され、合計で4行の変更がありました。更新された日付は、2024年7月9日から2024年9月9日に変更されており、これによりリリース日が最新の情報に反映されています。</p>
<p>さらに、ドキュメントの内容も新しいプレビューリリースに合わせて更新されています。特に、データプレーン推論仕様に関連する最新のプレビューリリースである
<code>2024-05-01-preview</code> が <code>2024-08-01-preview</code>
に変更されており、これにより最新の機能や改善点にアクセスできるようになっています。この更新は、開発者が新しい機能を理解し、活用するのに役立つ重要な情報を提供することを目的としています。全体として、この変更はAzure
OpenAIのユーザーが最新の情報に基づいてAPIを利用できるようにするためのものです。</p>
<h2 id="item-7b1183">articles/ai-services/openai/reference.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb12"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -5,7 +5,7 @@ description: Learn how to use Azure OpenAI&#39;s REST API. In this article, you lear</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a> ms.topic: conceptual</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 07/09/2024</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a> author: mrbullwinkle </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a> ms.author: mbullwin</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a> recommendations: false</span></code></pre></div>
</details>
<h3 id="summary-6">Summary</h3>
<div class="sourceCode" id="cb13"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-services/openai/reference.md&quot;</span><span class="fu">,</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;ドキュメントの日付更新&quot;</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-6">Explanation</h3>
<p>この変更は、Azure OpenAIのREST
APIに関するリファレンスドキュメントの更新を示しています。具体的には、1行が追加され、1行が削除され、合計で2行の変更が行われています。この更新において、ドキュメントの日付が2024年7月9日から2024年9月9日に変更されました。</p>
<p>このような日付の更新は、ドキュメントが最新の状態であることを確認するために重要です。特に、ユーザーは常に新しい情報を把握する必要があり、最新の日付が付されたドキュメントは信頼性を高めます。全体として、この変更はAzure
OpenAIのユーザーが正確で最新の情報に基づいてAPIを利用できるようにするためのものです。</p>
<h2
id="item-8f87b5">articles/ai-services/openai/tutorials/fine-tune.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb14"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,21 +1,21 @@</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="st">-title: Azure OpenAI Service fine-tuning gpt-3.5-turbo</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="va">+title: Azure OpenAI Service fine-tuning gpt-4o-mini</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure OpenAI</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="st">-description: Learn how to use Azure OpenAI&#39;s latest fine-tuning capabilities with gpt-3.5-turbo.</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="va">+description: Learn how to use Azure OpenAI&#39;s latest fine-tuning capabilities with gpt-4o-mini-2024-07-18</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a> #services: cognitive-services</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a> manager: nitinme</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-openai</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a> ms.topic: tutorial</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 05/15/2024</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a> author: mrbullwinkle</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a> ms.author: mbullwin</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a> recommendations: false</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a> ms.custom: devx-track-python</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="st">-# Azure OpenAI GPT-3.5 Turbo fine-tuning tutorial</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="va">+# Azure OpenAI GPT-4o-mini fine-tuning tutorial</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="st">-This tutorial walks you through fine-tuning a `gpt-35-turbo-0613` model.</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="va">+This tutorial walks you through fine-tuning a `gpt-4o-mini-2024-07-18` model.</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a> In this tutorial you learn how to:</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -24,7 +24,7 @@ In this tutorial you learn how to:</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a> &gt; * Create environment variables for your resource endpoint and API key.</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a> &gt; * Prepare your sample training and validation datasets for fine-tuning.</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a> &gt; * Upload your training file and validation file for fine-tuning.</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; * Create a fine-tuning job for `gpt-35-turbo-0613`.</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; * Create a fine-tuning job for `gpt-4o-mini-2024-07-18`.</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a> &gt; * Deploy a custom fine-tuned model.</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a> ## Prerequisites</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -33,13 +33,12 @@ In this tutorial you learn how to:</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a> - Python 3.8 or later version</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a> - The following Python libraries: `json`, `requests`, `os`, `tiktoken`, `time`, `openai`, `numpy`.</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a> - [Jupyter Notebooks](https://jupyter.org/)</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a><span class="st">-- An Azure OpenAI resource in a [region where `gpt-35-turbo-0613` fine-tuning is available](../concepts/models.md). If you don&#39;t have a resource the process of creating one is documented in our resource [deployment guide](../how-to/create-resource.md).</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure OpenAI resource in a [region where `gpt-4o-mini-2024-07-18` fine-tuning is available](../concepts/models.md). If you don&#39;t have a resource the process of creating one is documented in our resource [deployment guide](../how-to/create-resource.md).</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a> - Fine-tuning access requires **Cognitive Services OpenAI Contributor**.</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a> - If you do not already have access to view quota, and deploy models in Azure OpenAI Studio you will require [additional permissions](../how-to/role-based-access-control.md).</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a> &gt; [!IMPORTANT]</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; We strongly recommend reviewing the [pricing information](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/#pricing) for fine-tuning prior to beginning this tutorial to make sure you are comfortable with the associated costs. In testing, this tutorial resulted in one training hour billed, in addition to the costs that are associated with fine-tuning inference, and the hourly hosting costs of having a fine-tuned model deployed. Once you have completed the tutorial, you should delete your fine-tuned model deployment otherwise you will continue to incur the hourly hosting cost.</span></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; We recommend reviewing the [pricing information](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/#pricing) for fine-tuning to familiarize yourself with the associated costs. In testing, this tutorial resulted in 48,000 tokens being billed (4,800 training tokens * 10 epochs of training). Training costs are in addition to the costs that are associated with fine-tuning inference, and the hourly hosting costs of having a fine-tuned model deployed. Once you have completed the tutorial, you should delete your fine-tuned model deployment otherwise you will continue to incur the hourly hosting cost.</span></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a> ## Set up</span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -106,7 +105,7 @@ source /etc/environment</span></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a> ### Create a sample dataset</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a><span class="st">-Fine-tuning `gpt-35-turbo-0613` requires a specially formatted JSONL training file. OpenAI provides the following example in their documentation:</span></span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a><span class="va">+Fine-tuning `gpt-4o-mini-2024-07-18` requires a specially formatted JSONL training file. OpenAI provides the following example in their documentation:</span></span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a> ```json</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a> {&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Marv is a factual chatbot that is also sarcastic.&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What&#39;s the capital of France?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Paris, as if everyone doesn&#39;t know that already.&quot;}]}</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -206,7 +205,10 @@ First example in validation set:</span></span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a> In this case we only have 10 training and 10 validation examples so while this will demonstrate the basic mechanics of fine-tuning a model this in unlikely to be a large enough number of examples to produce a consistently noticeable impact.</span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a><span class="st">-Now you can then run some additional code from OpenAI using the tiktoken library to validate the token counts. Individual examples need to remain under the `gpt-35-turbo-0613` model&#39;s input token limit of 4096 tokens.</span></span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a><span class="va">+Now you can then run some additional code from OpenAI using the tiktoken library to validate the token counts. Token counting using this method is not going to give you the exact token counts that will be used for fine-tuning, but should provide a good estimate.</span></span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!NOTE]</span></span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; Individual examples need to remain under the `gpt-4o-mini-2024-07-18` model&#39;s current training example context legnth of: 64,536 tokens. The model&#39;s input token limit remains 128,000 tokens.</span></span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a> ```python</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a> # Validate token counts</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -216,7 +218,7 @@ import tiktoken</span></span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a> import numpy as np</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a> from collections import defaultdict</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a><span class="st">-encoding = tiktoken.get_encoding(&quot;cl100k_base&quot;) # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models</span></span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a><span class="va">+encoding = tiktoken.get_encoding(&quot;o200k_base&quot;) # default encoding for gpt-4o models. This requires the latest version of tiktoken to be installed.</span></span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a> def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):</span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a>     num_tokens = 0</span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -268,27 +270,27 @@ for file in files:</span></span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a> Processing file: training_set.jsonl</span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a> #### Distribution of total tokens:</span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a><span class="st">-min / max: 47, 62</span></span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a><span class="st">-mean / median: 52.1, 50.5</span></span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a><span class="st">-p5 / p95: 47.9, 57.5</span></span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a><span class="va">+min / max: 46, 59</span></span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a><span class="va">+mean / median: 49.8, 48.5</span></span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a><span class="va">+p5 / p95: 46.0, 53.599999999999994</span></span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a> #### Distribution of assistant tokens:</span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a><span class="st">-min / max: 13, 30</span></span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a><span class="st">-mean / median: 17.6, 15.5</span></span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a><span class="st">-p5 / p95: 13.0, 21.9</span></span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a><span class="va">+min / max: 13, 28</span></span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a><span class="va">+mean / median: 16.5, 14.0</span></span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a><span class="va">+p5 / p95: 13.0, 19.9</span></span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a> **************************************************</span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a> Processing file: validation_set.jsonl</span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a> #### Distribution of total tokens:</span>
<span id="cb14-105"><a href="#cb14-105" aria-hidden="true" tabindex="-1"></a><span class="st">-min / max: 43, 65</span></span>
<span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a><span class="st">-mean / median: 51.4, 49.0</span></span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a><span class="st">-p5 / p95: 45.7, 56.9</span></span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a><span class="va">+min / max: 41, 64</span></span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a><span class="va">+mean / median: 48.9, 47.0</span></span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a><span class="va">+p5 / p95: 43.7, 54.099999999999994</span></span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a> #### Distribution of assistant tokens:</span>
<span id="cb14-113"><a href="#cb14-113" aria-hidden="true" tabindex="-1"></a> min / max: 8, 29</span>
<span id="cb14-114"><a href="#cb14-114" aria-hidden="true" tabindex="-1"></a><span class="st">-mean / median: 15.9, 13.5</span></span>
<span id="cb14-115"><a href="#cb14-115" aria-hidden="true" tabindex="-1"></a><span class="st">-p5 / p95: 11.6, 20.9</span></span>
<span id="cb14-116"><a href="#cb14-116" aria-hidden="true" tabindex="-1"></a><span class="st">-**************************************************</span></span>
<span id="cb14-117"><a href="#cb14-117" aria-hidden="true" tabindex="-1"></a><span class="va">+mean / median: 15.0, 12.5</span></span>
<span id="cb14-118"><a href="#cb14-118" aria-hidden="true" tabindex="-1"></a><span class="va">+p5 / p95: 10.7, 19.999999999999996</span></span>
<span id="cb14-119"><a href="#cb14-119" aria-hidden="true" tabindex="-1"></a><span class="va">+****************************</span></span></code></pre></div>
<p>## Upload fine-tuning files<br />
@@ -304,7 +306,7 @@ from openai import AzureOpenAI<br />
client = AzureOpenAI(<br />
azure_endpoint = os.getenv(“AZURE_OPENAI_ENDPOINT”),<br />
api_key = os.getenv(“AZURE_OPENAI_API_KEY”),<br />
- api_version = “2024-05-01-preview” # This API version or later is
required to access seed/events/checkpoint features<br />
+ api_version = “2024-08-01-preview” # This API version or later is
required to access seed/events/checkpoint features<br />
)</p>
<p>training_file_name = ‘training_set.jsonl’<br />
@@ -381,7 +383,7 @@ In this example we’re also passing the seed
parameter. The seed controls the rep<br />
response = client.fine_tuning.jobs.create(<br />
training_file = training_file_id,<br />
validation_file = validation_file_id,<br />
- model = “gpt-35-turbo-0613”, # Enter base model name. Note that in
Azure OpenAI the model name contains dashes and cannot contain
dot/period characters.<br />
+ model = “gpt-4o-mini-2024-07-18”, # Enter base model name. Note that
in Azure OpenAI the model name contains dashes and cannot contain
dot/period characters.<br />
seed = 105 # seed parameter controls reproducibility of the fine-tuning
job. If no seed is specified one will be generated automatically.<br />
)</p>
<p>@@ -404,7 +406,7 @@ print(response.model_dump_json(indent=2))<br />
response = openai.FineTuningJob.create(<br />
training_file = training_file_id,<br />
validation_file = validation_file_id,<br />
- model = “gpt-35-turbo-0613”,<br />
+ model = “gpt-4o-mini-2024-07-18”,<br />
)</p>
<p>job_id = response[“id”]<br />
@@ -435,7 +437,7 @@ Status: pending<br />
“batch_size”: -1,<br />
“learning_rate_multiplier”: 1<br />
},<br />
- “model”: “gpt-35-turbo-0613”,<br />
+ “model”: “gpt-4o-mini-2024-07-18”,<br />
“object”: “fine_tuning.job”,<br />
“organization_id”: null,<br />
“result_files”: null,<br />
@@ -540,7 +542,7 @@ Status: pending<br />
“batch_size”: -1,<br />
“learning_rate_multiplier”: 1<br />
},<br />
- “model”: “gpt-35-turbo-0613”,<br />
+ “model”: “gpt-4o-mini-2024-07-18”,<br />
“object”: “fine_tuning.job”,<br />
“organization_id”: null,<br />
“result_files”: null,<br />
@@ -564,7 +566,7 @@ Found 4 fine-tune jobs.</p>
<p>## List fine-tuning events</p>
<p>-API version: <code>2024-05-01-preview</code> or later is required
for this command.<br />
+API version: <code>2024-08-01-preview</code> or later is required for
this command.</p>
<p>While not necessary to complete fine-tuning it can be helpful to
examine the individual fine-tuning events that were generated during
training. The full training results can also be examined after training
is complete in the <a
href="../how-to/fine-tuning.md#analyze-your-customized-model">training
results file</a>.</p>
<p>@@ -728,7 +730,7 @@ This command isn’t available in the 0.28.1 OpenAI
Python library. Upgrade to the</p>
<p>## List checkpoints</p>
<p>-API version: <code>2024-05-01-preview</code> or later is required
for this command.<br />
+API version: <code>2024-08-01-preview</code> or later is required for
this command.</p>
<p>When each training epoch completes a checkpoint is generated. A
checkpoint is a fully functional version of a model which can both be
deployed and used as the target model for subsequent fine-tuning jobs.
Checkpoints can be particularly useful, as they can provide a snapshot
of your model prior to overfitting having occurred. When a fine-tuning
job completes you will have the three most recent versions of the model
available to deploy. The final epoch will be represented by your
fine-tuned model, the previous two epochs will be available as
checkpoints.</p>
<p>@@ -753,7 +755,7 @@ This command isn’t available in the 0.28.1 OpenAI
Python library. Upgrade to the<br />
{<br />
“id”: “ftchkpt-148ab69f0a404cf9ab55a73d51b152de”,<br />
“created_at”: 1715743077,<br />
- “fine_tuned_model_checkpoint”:
“gpt-35-turbo-0613.ft-372c72db22c34e6f9ccb62c26ee0fbd9”,<br />
+ “fine_tuned_model_checkpoint”:
“gpt-4o-mini-2024-07-18.ft-372c72db22c34e6f9ccb62c26ee0fbd9”,<br />
“fine_tuning_job_id”: “ftjob-372c72db22c34e6f9ccb62c26ee0fbd9”,<br />
“metrics”: {<br />
“full_valid_loss”: 1.8258173013035255,<br />
@@ -770,7 +772,7 @@ This command isn’t available in the 0.28.1 OpenAI
Python library. Upgrade to the<br />
{<br />
“id”: “ftchkpt-e559c011ecc04fc68eaa339d8227d02d”,<br />
“created_at”: 1715743013,<br />
- “fine_tuned_model_checkpoint”:
“gpt-35-turbo-0613.ft-372c72db22c34e6f9ccb62c26ee0fbd9:ckpt-step-90”,<br />
+ “fine_tuned_model_checkpoint”:
“gpt-4o-mini-2024-07-18.ft-372c72db22c34e6f9ccb62c26ee0fbd9:ckpt-step-90”,<br />
“fine_tuning_job_id”: “ftjob-372c72db22c34e6f9ccb62c26ee0fbd9”,<br />
“metrics”: {<br />
“full_valid_loss”: 1.7958603267428241,<br />
@@ -787,7 +789,7 @@ This command isn’t available in the 0.28.1 OpenAI
Python library. Upgrade to the<br />
{<br />
“id”: “ftchkpt-8ae8beef3dcd4dfbbe9212e79bb53265”,<br />
“created_at”: 1715742984,<br />
- “fine_tuned_model_checkpoint”:
“gpt-35-turbo-0613.ft-372c72db22c34e6f9ccb62c26ee0fbd9:ckpt-step-80”,<br />
+ “fine_tuned_model_checkpoint”:
“gpt-4o-mini-2024-07-18.ft-372c72db22c34e6f9ccb62c26ee0fbd9:ckpt-step-80”,<br />
“fine_tuning_job_id”: “ftjob-372c72db22c34e6f9ccb62c26ee0fbd9”,<br />
“metrics”: {<br />
“full_valid_loss”: 1.6909511662736725,<br />
@@ -848,7 +850,7 @@ Alternatively, you can deploy your fine-tuned model
using any of the other commo<br />
| resource_group | The resource group name for your Azure OpenAI
resource |<br />
| resource_name | The Azure OpenAI resource name |<br />
| model_deployment_name | The custom name for your new fine-tuned model
deployment. This is the name that will be referenced in your code when
making chat completion calls. |<br />
-| fine_tuned_model | Retrieve this value from your fine-tuning job
results in the previous step. It will look like
<code>gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83</code>.
You’ll need to add that value to the deploy_data json. |<br />
+| fine_tuned_model | Retrieve this value from your fine-tuning job
results in the previous step. It will look like
<code>gpt-4o-mini-2024-07-18.ft-b044a9d3cf9c4228b5d393567f693b83</code>.
You’ll need to add that value to the deploy_data json. |</p>
<p>[!INCLUDE <a href="../includes/fine-tune.md">Fine-tuning
deletion</a>]</p>
<p>@@ -862,7 +864,7 @@ token = os.getenv(“TEMP_AUTH_TOKEN”)<br />
subscription = “<YOUR_SUBSCRIPTION_ID>”<br />
resource_group = “<YOUR_RESOURCE_GROUP_NAME>”<br />
resource_name = “<YOUR_AZURE_OPENAI_RESOURCE_NAME>”<br />
-model_deployment_name = “YOUR_CUSTOM_MODEL_DEPLOYMENT_NAME”<br />
+model_deployment_name = “gpt-4o-mini-2024-07-18-ft” # Custom deployment
name you chose for your fine-tuning model</p>
<p>deploy_params = {‘api-version’: “2023-05-01”}<br />
deploy_headers = {‘Authorization’: ‘Bearer {}’.format(token),
‘Content-Type’: ‘application/json’}<br />
@@ -872,7 +874,7 @@ deploy_data = {<br />
“properties”: {<br />
“model”: {<br />
“format”: “OpenAI”,<br />
- “name”: “<YOUR_FINE_TUNED_MODEL>”, #retrieve this value from the
previous call, it will look like
gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83<br />
+ “name”: “<YOUR_FINE_TUNED_MODEL>”, #retrieve this value from the
previous call, it will look like
gpt-4o-mini-2024-07-18.ft-b044a9d3cf9c4228b5d393567f693b83<br />
“version”: “1”<br />
}<br />
}<br />
@@ -911,11 +913,11 @@ from openai import AzureOpenAI<br />
client = AzureOpenAI(<br />
azure_endpoint = os.getenv(“AZURE_OPENAI_ENDPOINT”),<br />
api_key = os.getenv(“AZURE_OPENAI_API_KEY”),<br />
- api_version = “2024-02-01”<br />
+ api_version = “2024-06-01”<br />
)</p>
<p>response = client.chat.completions.create(<br />
- model = “gpt-35-turbo-ft”, # model = “Custom deployment name you chose
for your fine-tuning model”<br />
+ model = “gpt-4o-mini-2024-07-18-ft”, # model = “Custom deployment name
you chose for your fine-tuning model”<br />
messages = [<br />
{“role”: “system”, “content”: “You are a helpful assistant.”},<br />
{“role”: “user”, “content”: “Does Azure OpenAI support customer managed
keys?”},<br />
@@ -937,11 +939,11 @@ import openai</p>
<p>openai.api_type = “azure”<br />
openai.api_base = os.getenv(“AZURE_OPENAI_ENDPOINT”)<br />
-openai.api_version = “2024-02-01”<br />
+openai.api_version = “2024-06-01”<br />
openai.api_key = os.getenv(“AZURE_OPENAI_API_KEY”)</p>
<p>response = openai.ChatCompletion.create(<br />
- engine = “gpt-35-turbo-ft”, # engine = “Custom deployment name you
chose for your fine-tuning model”<br />
+ engine = “gpt-4o-mini-2024-07-18-ft”, # engine = “Custom deployment
name you chose for your fine-tuning model”<br />
messages = [<br />
{“role”: “system”, “content”: “You are a helpful assistant.”},<br />
{“role”: “user”, “content”: “Does Azure OpenAI support customer managed
keys?”},</p>
<pre><code>&lt;/details&gt;

### Summary

```json
{
    &quot;filename&quot;: &quot;articles/ai-services/openai/tutorials/fine-tune.md&quot;,
    &quot;modification_type&quot;: &quot;minor update&quot;,
    &quot;modification_title&quot;: &quot;ファインチューニングチュートリアルの更新&quot;
}</code></pre>
<h3 id="explanation-7">Explanation</h3>
<p>この変更は、Azure
OpenAIサービスにおけるファインチューニングに関するチュートリアルドキュメントの重要な更新を適用しています。合計で43行の追加と41行の削除が行われ、84行が変更されています。変更の主な内容は、ファインチューニング対象のモデル名を
<code>gpt-3.5-turbo</code> から <code>gpt-4o-mini</code>
に変更し、それに伴う説明や処理手順を最新のものに更新しています。</p>
<p>具体的には、チュートリアル内では新しいモデルである
<code>gpt-4o-mini-2024-07-18</code>
に基づいたファインチューニング手順が紹介されています。この更新により、ユーザーは最新のAzure
OpenAIサービスによるモデルファインチューニングの新機能にアクセスし、より効果的に利用できるようになります。また、手順の中では利用するAPIバージョンが
<code>2024-08-01-preview</code>
に変更され、適切な使用方法や注意事項も記載されています。</p>
<p>全体として、この変更はユーザーが最新のモデルと機能を利用してファインチューニングを行うために必要な情報を提供し、技術ドキュメントの信頼性と有用性を向上させることを目的としています。</p>
<h2 id="item-868060">articles/ai-studio/includes/install-cli.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb16"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -0,0 +1,41 @@</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="va">+title: include file</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="va">+description: include file</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="va">+author: sdgilley</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.reviewer: sgilley</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.author: esgiley</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.service: azure-ai-studio</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: include</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 08/29/2024</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.custom: include</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="va">+You install the Azure CLI and sign in from your local development environment, so that you can use your user credentials to call the Azure OpenAI service.</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="va">+In most cases you can install the Azure CLI from your terminal using the following command: </span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Windows](#tab/windows)</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="va">+```powershell </span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="va">+winget install -e --id Microsoft.AzureCLI</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Linux](#tab/linux)</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="va">+```bash</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="va">+curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="va">+# [macOS](#tab/macos)</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="va">+```bash</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a><span class="va">+brew update &amp;&amp; brew install azure-cli</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="va">+You can follow instructions [How to install the Azure CLI](/cli/azure/install-azure-cli) if these commands don&#39;t work for your particular operating system or setup.</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="va">+After you install the Azure CLI, sign in using the ``az login`` command and sign-in using the browser:</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="va">+az login</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>\ No newline at end of file</span></code></pre></div>
</details>
<h3 id="summary-7">Summary</h3>
<div class="sourceCode" id="cb17"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-studio/includes/install-cli.md&quot;</span><span class="fu">,</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Azure CLIのインストール手順追加&quot;</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-8">Explanation</h3>
<p>この変更は、Azure AI Studioの使用に必要なAzure
CLIのインストール手順を記載した新しいファイル
<code>install-cli.md</code> を追加するものです。このファイルには、Azure
CLIをインストールし、Azure
OpenAIサービスを呼び出すためにローカル開発環境からサインインする方法が詳述されています。</p>
<p>具体的には、Windows、Linux、macOSの各プラットフォームにおけるAzure
CLIのインストール方法がそれぞれのコマンドとともに示されています。また、CLIのインストールに関する詳細な手順が記載されたリンクも提供されています。インストールが完了した後は、
<code>az login</code>
コマンドを使用してAzureにサインインするプロセスも記載されています。</p>
<p>この新しいファイルの追加により、Azure OpenAIサービスやAzure AI
Studioを利用するための準備がスムーズに行えるようになり、ユーザーにとって非常に有益な情報源が提供されることになります。全体として、ユーザーがAzure
CLIを簡単にインストールし、適切に利用できることを目的としています。</p>
<h2
id="item-40e054">articles/ai-studio/includes/install-promptflow.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb18"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -0,0 +1,24 @@</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="va">+title: include file</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="va">+description: include file</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="va">+author: sdgilley</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.reviewer: sgilley</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.author: sgilley</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.service: azure-ai-studio</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: include</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 08/29/2024</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.custom: include</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="va">+Use pip to install the prompt flow SDK into the virtual environment that you created.</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="va">+pip install promptflow</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="va">+pip install azure-identity</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="va">+The prompt flow SDK takes a dependency on multiple packages, that you can choose to separately install if you don&#39;t want all of them:</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="va">+ * ```promptflow-core```: contains the core prompt flow runtime used for executing LLM code</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="va">+ * ```promptflow-tracing```: lightweight library used for emitting OpenTelemetry traces in standards</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="va">+ * ```promptflow-devkit```: contains the prompt flow test bed and trace viewer tools for local development environments</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="va">+ * ```openai```: client libraries for using the Azure OpenAI service</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="va">+ * ```python-dotenv```: used to set environment variables by reading them from ```.env``` files</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>\ No newline at end of file</span></code></pre></div>
</details>
<h3 id="summary-8">Summary</h3>
<div class="sourceCode" id="cb19"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-studio/includes/install-promptflow.md&quot;</span><span class="fu">,</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Prompt Flow SDKのインストール手順追加&quot;</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-9">Explanation</h3>
<p>この変更は、Prompt Flow
SDKをインストールするための手順を記載した新しいファイル
<code>install-promptflow.md</code>
を追加するものです。このファイルでは、指定された仮想環境に対して
<code>pip</code> コマンドを用いてPrompt Flow
SDKおよび関連パッケージをインストールする方法が説明されています。</p>
<p>具体的には、Prompt Flow
SDKをインストールするための基本的なコマンドが示されており、さらにこのSDKの動作に必要な複数の依存パッケージの紹介も行われています。それぞれの名称と役割が明確に記述されており、ユーザーが必要に応じて個別にパッケージを選んでインストールできるようになっています。主なパッケージとしては、コアのランタイムである
<code>promptflow-core</code>、OpenTelemetryトレースを emit するための
<code>promptflow-tracing</code>、ローカル開発環境用のテストベッドおよびトレースビューワーツールを含む
<code>promptflow-devkit</code>、Azure
OpenAIサービス向けのクライアントライブラリである
<code>openai</code>、および <code>.env</code>
ファイルから環境変数を読み込むための <code>python-dotenv</code>
があります。</p>
<p>この新しいファイルにより、ユーザーはPrompt Flow
SDKのセットアップ手順を簡単に理解し、実施できるようになります。また、これによりAzure
AI
Studioを利用する際の開発環境が強化され、ユーザーの作業効率が向上することを目的としています。</p>
<h2 id="item-f5f09e">articles/ai-studio/includes/install-python.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb20"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -0,0 +1,49 @@</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="va">+title: include file</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="va">+description: include file</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="va">+author: sdgilley</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.reviewer: sgilley</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.author: esgiley</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.service: azure-ai-studio</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: include</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 08/29/2024</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.custom: include</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="va">+First we need to create a new Python environment we can use to install the prompt flow SDK packages. DO NOT install packages into your global python installation. You should always use a virtual or conda environment when installing python packages, otherwise you can break your global install of Python.</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="va">+### If needed, install Python</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="va">+We recommend using Python 3.10 or later, but having at least Python 3.8 is required. If you don&#39;t have a suitable version of Python installed, you can follow the instructions in the [VS Code Python Tutorial](https://code.visualstudio.com/docs/python/python-tutorial#_install-a-python-interpreter) for the easiest way of installing Python on your operating system.</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="va">+### Create a virtual environment</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="va">+If you already have Python 3.10 or higher installed, you can create a virtual environment using the following commands:</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Windows](#tab/windows)</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="va">+```bash</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="va">+py -3 -m venv .venv</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="va">+.venv\scripts\activate</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a><span class="va">+# [Linux](#tab/linux)</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="va">+```bash</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a><span class="va">+python3 -m venv .venv</span></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a><span class="va">+source .venv/bin/activate</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a><span class="va">+# [macOS](#tab/macos)</span></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a><span class="va">+```bash</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a><span class="va">+python3 -m venv .venv</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a><span class="va">+source .venv/bin/activate</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a><span class="va">+```</span></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a><span class="va">+Activating the Python environment means that when you run ```python``` or ```pip``` from the command line, you then use the Python interpreter contained in the ```.venv``` folder of your application.</span></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!NOTE]</span></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; You can use the ```deactivate``` command to exit the python virtual environment, and can later reactivate it when needed.</span></span></code></pre></div>
</details>
<h3 id="summary-9">Summary</h3>
<div class="sourceCode" id="cb21"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-studio/includes/install-python.md&quot;</span><span class="fu">,</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Python環境の設定手順追加&quot;</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-10">Explanation</h3>
<p>この変更は、Python環境を設定し、Prompt Flow
SDKパッケージをインストールするための手順を記載した新しいファイル
<code>install-python.md</code>
を追加するものです。このファイルでは、グローバルなPythonインストールにパッケージをインストールしないように警告し、常に仮想環境やconda環境を使用することが推奨されています。これにより、グローバルなPython環境が破損するのを防ぎます。</p>
<p>ファイルの初めでは、Pythonの適切なバージョン（Python
3.10以上が推奨、少なくともPython
3.8が必要）をインストールする必要がある場合について言及しています。指示に従って、VS
CodeのPythonチュートリアルを参考にすることで、オペレーティングシステム上にPythonを簡単にインストールできることが示されています。</p>
<p>具体的な手順としては、Windows、Linux、macOSそれぞれのプラットフォームにおける仮想環境の作成方法が示されています。仮想環境をアクティブにすることで、コマンドラインから実行する
<code>python</code> や <code>pip</code> がアプリケーションの
<code>.venv</code>
フォルダに含まれるPythonインタープリターを使用するようになります。最後には、仮想環境からの退出や再アクティベートについての注意事項も記載されています。</p>
<p>この新しいファイルの追加により、ユーザーはPrompt Flow
SDKを利用するためのPython環境を適切に設定できるようになり、Pythonの使用に関する理解が深まることが期待されます。全体として、ユーザーの開発効率の向上に寄与することを目的としています。</p>
<h2
id="item-8a5082">articles/ai-studio/quickstarts/get-started-code.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb22"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -66,94 +66,19 @@ To grant yourself access to the Azure AI Services resource that you&#39;re using:</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a> ## Install the Azure CLI and sign in </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="st">-You install the Azure CLI and sign in from your local development environment, so that you can use your user credentials to call the Azure OpenAI service.</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="st">-In most cases you can install the Azure CLI from your terminal using the following command: </span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="st">-# [Windows](#tab/windows)</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="st">-```powershell </span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="st">-winget install -e --id Microsoft.AzureCLI</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="st">-# [Linux](#tab/linux)</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="st">-```bash</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="st">-curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a><span class="st">-# [macOS](#tab/macos)</span></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="st">-```bash</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="st">-brew update &amp;&amp; brew install azure-cli</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="st">-You can follow instructions [How to install the Azure CLI](/cli/azure/install-azure-cli) if these commands don&#39;t work for your particular operating system or setup.</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="st">-After you install the Azure CLI, sign in using the ``az login`` command and sign-in using the browser:</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="st">-az login</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Install the Azure CLI](../includes/install-cli.md)]</span></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a> Now we create our app and call the Azure OpenAI Service from code.</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a> ## Create a new Python environment</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a><span class="st">-First we need to create a new Python environment we can use to install the prompt flow SDK packages. DO NOT install packages into your global python installation. You should always use a virtual or conda environment when installing python packages, otherwise you can break your global install of Python.</span></span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a><span class="st">-### If needed, install Python</span></span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a><span class="st">-We recommend using Python 3.10 or later, but having at least Python 3.8 is required. If you don&#39;t have a suitable version of Python installed, you can follow the instructions in the [VS Code Python Tutorial](https://code.visualstudio.com/docs/python/python-tutorial#_install-a-python-interpreter) for the easiest way of installing Python on your operating system.</span></span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a><span class="st">-### Create a virtual environment</span></span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a><span class="st">-If you already have Python 3.10 or higher installed, you can create a virtual environment using the following commands:</span></span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a><span class="st">-# [Windows](#tab/windows)</span></span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a><span class="st">-```bash</span></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a><span class="st">-py -3 -m venv .venv</span></span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a><span class="st">-.venv\scripts\activate</span></span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a><span class="st">-# [Linux](#tab/linux)</span></span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a><span class="st">-```bash</span></span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a><span class="st">-python3 -m venv .venv</span></span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a><span class="st">-source .venv/bin/activate</span></span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a><span class="st">-# [macOS](#tab/macos)</span></span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a><span class="st">-```bash</span></span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a><span class="st">-python3 -m venv .venv</span></span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a><span class="st">-source .venv/bin/activate</span></span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a><span class="kw">----</span></span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a><span class="st">-Activating the Python environment means that when you run ```python``` or ```pip``` from the command line, you then use the Python interpreter contained in the ```.venv``` folder of your application.</span></span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!NOTE]</span></span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; You can use the ```deactivate``` command to exit the python virtual environment, and can later reactivate it when needed.</span></span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Install Python](../includes/install-python.md)]</span></span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a> ## Install the prompt flow SDK</span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a> In this section, we use prompt flow to build our application. [Prompt flow](https://microsoft.github.io/promptflow) is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring.</span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a><span class="st">-Use pip to install the prompt flow SDK into the virtual environment that you created.</span></span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a><span class="st">-pip install promptflow</span></span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a><span class="st">-pip install azure-identity</span></span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a><span class="st">-```</span></span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a><span class="st">-The prompt flow SDK takes a dependency on multiple packages, that you can choose to separately install if you don&#39;t want all of them:</span></span>
<span id="cb22-90"><a href="#cb22-90" aria-hidden="true" tabindex="-1"></a><span class="st">- * ```promptflow-core```: contains the core prompt flow runtime used for executing LLM code</span></span>
<span id="cb22-91"><a href="#cb22-91" aria-hidden="true" tabindex="-1"></a><span class="st">- * ```promptflow-tracing```: lightweight library used for emitting OpenTelemetry traces in standards</span></span>
<span id="cb22-92"><a href="#cb22-92" aria-hidden="true" tabindex="-1"></a><span class="st">- * ```promptflow-devkit```: contains the prompt flow test bed and trace viewer tools for local development environments</span></span>
<span id="cb22-93"><a href="#cb22-93" aria-hidden="true" tabindex="-1"></a><span class="st">- * ```openai```: client libraries for using the Azure OpenAI service</span></span>
<span id="cb22-94"><a href="#cb22-94" aria-hidden="true" tabindex="-1"></a><span class="st">- * ```python-dotenv```: used to set environment variables by reading them from ```.env``` files</span></span>
<span id="cb22-95"><a href="#cb22-95" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Install prompt flow](../includes/install-promptflow.md)]</span></span>
<span id="cb22-96"><a href="#cb22-96" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb22-97"><a href="#cb22-97" aria-hidden="true" tabindex="-1"></a> ## Configure your environment variables</span>
<span id="cb22-98"><a href="#cb22-98" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-10">Summary</h3>
<div class="sourceCode" id="cb23"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-studio/quickstarts/get-started-code.md&quot;</span><span class="fu">,</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Azure CLIおよびPython環境設定の指示を統合&quot;</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-11">Explanation</h3>
<p>この変更は、Azure
CLIおよびPython環境の設定に関する指示を、他の共通のドキュメントファイルにリンクする形で簡素化したものです。具体的には、元の手順から78行が削除され、新たに3行が追加されました。これにより、同じ内容を持つ他のファイル（<code>install-cli.md</code>
と
<code>install-python.md</code>）を参照する形式に変更されています。</p>
<p>例えば、Azure
CLIのインストールやサインイン手順は、<code>[!INCLUDE [Install the Azure CLI](../includes/install-cli.md)]</code>
として新しいファイルにリンクされています。これにより、ユーザーは一貫した情報を得やすくなり、複数のドキュメントに同じ内容を繰り返す必要がなくなります。</p>
<p>また、Python環境の設定に関する実用的なコマンドと手順も、<code>[!INCLUDE [Install Python](../includes/install-python.md)]</code>
として参照されるようになりました。この変更は、ドキュメントの可読性を向上させ、保守性を高め、ユーザーが必要な情報を効果的に見つけられるようにすることを目的としています。</p>
<p>全体として、この改訂はドキュメントの整理およびデータの一貫性を促進し、ユーザーにとっての理解を深める助けとなります。</p>
<h2 id="item-2745cd">articles/ai-studio/toc.yml</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb24"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -29,12 +29,15 @@ items:</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>   items:</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>   - name: Deploy an enterprise chat web app</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>     href: tutorials/deploy-chat-web-app.md</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="st">-  - name: Build your own copilot with the prompt flow SDK</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="va">+  - name: Build a custom chat app with the prompt flow SDK</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>     items:</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="st">-      - name: &quot;Part 1: Build a custom copilot that implements RAG&quot;</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="va">+      - name: &quot;Part 1: Set up resources&quot;</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="va">+        href: tutorials/copilot-sdk-create-resources.md</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="va">+        displayName: code,sdk</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="va">+      - name: &quot;Part 2: Add data retrieval to a chat app&quot;</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>         href: tutorials/copilot-sdk-build-rag.md</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>         displayName: code,sdk</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="st">-      - name: &quot;Part 2: Evaluate and deploy your custom copilot&quot;</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="va">+      - name: &quot;Part 3: Evaluate and deploy a chat app&quot;</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>         href: tutorials/copilot-sdk-evaluate-deploy.md</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>         displayName: code,sdk</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a> - name: How-to</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -125,7 +128,7 @@ items:</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>       displayName: maas</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>     - name: JAIS model</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>       href: how-to/deploy-models-jais.md</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a><span class="st">-    - name: Jamba instruct model</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a><span class="va">+    - name: AI21 Jamba models</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>       href: how-to/deploy-models-jamba.md</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>     - name: TimeGEN-1 model</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>       href: how-to/deploy-models-timegen-1.md</span></code></pre></div>
</details>
<h3 id="summary-11">Summary</h3>
<div class="sourceCode" id="cb25"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-studio/toc.yml&quot;</span><span class="fu">,</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;チャットアプリに関する手順の名称変更とリンク追加&quot;</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-12">Explanation</h3>
<p>この変更では、<code>toc.yml</code>
ファイルにおける手順やリソースの名称を一部変更し、関連するリンクを追加することで、ドキュメントの構造を見直しています。具体的には、チャットアプリに関連する項目のタイトルが「Build
your own copilot with the prompt flow SDK」から「Build a custom chat app
with the prompt flow
SDK」へ変更され、これに伴いその下にある手順も適宜整備されています。</p>
<p>追加された部分としては、リソースの設定を明示するために「Part 1: Set
up
resources」として新しい手順が設けられ、対応するリンク（<code>href: tutorials/copilot-sdk-create-resources.md</code>）も添付されています。この変更により、ユーザーはプロジェクト開始時に必要なリソースの設定を容易に理解できるようになります。</p>
<p>さらに、元々の「Part 2: Evaluate and deploy your custom
copilot」というセクション名が「Part 3: Evaluate and deploy a chat
app」に変更されています。このように、手順の名称が具体的かつ明確になることで、利用者がさまざまな手順をよりスムーズに辿れるよう意図されています。</p>
<p>また、AI21モデルに関連するセクション名も変更され、「Jamba instruct
model」から「AI21 Jamba
models」に改められています。このような変更は、ドキュメントの一貫性を高め、ユーザーが正確な情報を収集しやすくするための重要なステップです。全体として、この更新はユーザーのナビゲーション体験を向上させることを目的としています。</p>
<h2
id="item-b77dba">articles/ai-studio/tutorials/copilot-sdk-build-rag.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb26"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,52 +1,39 @@</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="st">-title: &quot;Part 1: Build a RAG-based copilot with the prompt flow SDK&quot;</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="va">+title: &quot;Part 2: Build a custom chat app with the prompt flow SDK&quot;</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure AI Studio</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="st">-description:  Learn how to build a RAG-based copilot using the prompt flow SDK. This tutorial is part 1 of a 2-part tutorial.</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="va">+description:  Learn how to build a RAG-based chat app using the prompt flow SDK. This tutorial is part 2 of a 3-part tutorial series.</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a> manager: scottpolly</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-studio</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a> ms.topic: tutorial</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 8/6/2024</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 08/29/2024</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a> ms.reviewer: lebaro</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a> ms.author: sgilley</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a> author: sdgilley</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="st">-#customer intent: As a developer, I want to learn how to use the prompt flow SDK so that I can build a RAG-based copilot.</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="va">+#customer intent: As a developer, I want to learn how to use the prompt flow SDK so that I can build a RAG-based chat app.</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="st">-# Tutorial:  Part 1 - Build a RAG-based copilot with the prompt flow SDK</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="va">+# Tutorial:  Part 2 - Build a custom chat application with the prompt flow SDK</span></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="st">-In this [Azure AI Studio](https://ai.azure.com) tutorial, you use the prompt flow SDK (and other libraries) to build, configure, evaluate, and deploy a copilot for your retail company called Contoso Trek. Your retail company specializes in outdoor camping gear and clothing. The copilot should answer questions about your products and services. For example, the copilot can answer questions such as &quot;which tent is the most waterproof?&quot; or &quot;what is the best sleeping bag for cold weather?&quot;.</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a><span class="va">+In this tutorial, you use the prompt flow SDK (and other libraries) to build, configure, evaluate, and deploy a chat app for your retail company called Contoso Trek. Your retail company specializes in outdoor camping gear and clothing. The chat app should answer questions about your products and services. For example, the chat app can answer questions such as &quot;which tent is the most waterproof?&quot; or &quot;what is the best sleeping bag for cold weather?&quot;.</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="st">-This tutorial is part one of a two-part tutorial.</span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!TIP]</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; Be sure to set aside enough time to complete the prerequisites before starting this tutorial. If you&#39;re new to Azure AI Studio, you might need to spend additional time to get familiar with the platform. </span></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a><span class="st">-This part one shows you how to enhance a basic chat application by adding [retrieval augmented generation (RAG)](../concepts/retrieval-augmented-generation.md) to ground the responses in your custom data.</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a><span class="st">-In this part one, you learn how to:</span></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a><span class="va">+This part two shows you how to enhance a basic chat application by adding [retrieval augmented generation (RAG)](../concepts/retrieval-augmented-generation.md) to ground the responses in your custom data. Retrieval Augmented Generation (RAG) is a pattern that uses your data with a large language model (LLM) to generate answers specific to your data. In this part two, you learn how to:</span></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a> &gt; [!div class=&quot;checklist&quot;]</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; - [Deploy an embedding model](#deploy-an-embedding-model)</span></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; - [Create an Azure AI Search index](#create-an-azure-ai-search-index)</span></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; - [Develop custom RAG code](#develop-custom-rag-code)</span></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; - [Use prompt flow to test your copilot](#use-prompt-flow-to-test-your-copilot)</span></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Deploy AI models in Azure AI Studio to use in your app</span></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Develop custom RAG code</span></span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Use prompt flow to test your chat app</span></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a><span class="va">+This tutorial is part two of a three-part tutorial.</span></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a> ## Prerequisites</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!IMPORTANT]</span></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; You must have the necessary permissions to add role assignments in your Azure subscription. Granting permissions by role assignment is only allowed by the **Owner** of the specific Azure resources. You might need to ask your Azure subscription owner (who might be your IT admin) for help with completing the [assign access](#configure-access-for-the-azure-ai-search-service) section.</span></span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a><span class="st">-- You need to complete the [Build a custom chat app in Python using the prompt flow SDK quickstart](../quickstarts/get-started-code.md) to set up your environment. </span></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a><span class="st">-    &gt; [!IMPORTANT]</span></span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a><span class="st">-    &gt; This tutorial builds on the code and environment you set up in the quickstart.</span></span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a><span class="va">+* Complete [Tutorial:  Part 1 - Create resources for building a custom chat application with the prompt flow SDK](copilot-sdk-create-resources.md).</span></span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a><span class="st">-- You need a local copy of product data. The [Azure-Samples/rag-data-openai-python-promptflow repository on GitHub](https://github.com/Azure-Samples/rag-data-openai-python-promptflow/) contains sample retail product information that&#39;s relevant for this tutorial scenario. [Download the example Contoso Trek retail product data in a ZIP file](https://github.com/Azure-Samples/rag-data-openai-python-promptflow/tree/main/tutorial/data) to your local machine.</span></span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a><span class="va">+* You need a local copy of product data. The [Azure-Samples/rag-data-openai-python-promptflow repository on GitHub](https://github.com/Azure-Samples/rag-data-openai-python-promptflow/) contains sample retail product information that&#39;s relevant for this tutorial scenario. [Download the example Contoso Trek retail product data in a ZIP file](https://github.com/Azure-Samples/rag-data-openai-python-promptflow/tree/main/tutorial/data) to your local machine.</span></span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a> ## Application code structure</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a><span class="st">-Create a folder called **rag-tutorial** on your local machine. This tutorial series walks through creation of the contents of each file. If you complete the tutorial series, your folder structure looks like this:</span></span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a><span class="va">+Create a folder called **rag-tutorial** on your local machine. This tutorial series walks through creation of the contents of each file. When you complete the tutorial series, your folder structure looks like this:</span></span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a> ```text</span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a> rag-tutorial/</span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -71,158 +58,102 @@ rag-tutorial/</span></span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a> |   └─── [Your own data or sample data as described in the prerequisites.]</span></code></pre></div>
<p>-The implementation in this tutorial uses prompt flow’s flex flow,
which is the code-first approach to implementing flows. You specify an
entry function (which will be defined in <strong>copilot.py</strong>),
and then use prompt flow’s testing, evaluation, and tracing capabilities
for your flow. This flow is in code and doesn’t have a DAG (Directed
Acyclic Graph) or other visual component. Learn more about how to
develop a flex flow in the <a
href="https://microsoft.github.io/promptflow/how-to-guides/develop-a-flex-flow/index.html">prompt
flow documentation on GitHub</a>.<br />
+The implementation in this tutorial uses prompt flow’s flex flow, which
is the code-first approach to implementing flows. You specify an entry
function (which is in <strong>copilot.py</strong>), and then use prompt
flow’s testing, evaluation, and tracing capabilities for your flow. This
flow is in code and doesn’t have a DAG (Directed Acyclic Graph) or other
visual component. Learn more about how to develop a flex flow in the <a
href="https://microsoft.github.io/promptflow/how-to-guides/develop-a-flex-flow/index.html">prompt
flow documentation on GitHub</a>.</p>
<p>## Set initial environment variables</p>
<h2
id="theres-a-collection-of-environment-variables-used-across-the-different-code-snippets.-lets-set-them-now.">-There’s
a collection of environment variables used across the different code
snippets. Let’s set them now.</h2>
<h2
id="you-created-an-.env-file-with-the-following-environment-variables-via-the-build-a-custom-chat-app-in-python-using-the-prompt-flow-sdk-quickstart.-if-you-havent-already-create-an-.env-file-in-your-rag-tutorial-folder-with-the-following-environment-variables">-1.
You created an <strong>.env</strong> file with the following environment
variables via the <a href="../quickstarts/get-started-code.md">Build a
custom chat app in Python using the prompt flow SDK quickstart</a>. If
you haven’t already, create an <strong>.env</strong> file in your
<strong>rag-tutorial</strong> folder with the following environment
variables:</h2>
<ul class="incremental">
<li>```</li>
<li>AZURE_OPENAI_ENDPOINT=endpoint_value</li>
<li>AZURE_OPENAI_DEPLOYMENT_NAME=chat_model_deployment_name</li>
<li>AZURE_OPENAI_API_VERSION=api_version</li>
<li>```</li>
<li>-1. Copy the <strong>.env</strong> file into your
<strong>rag-tutorial</strong> folder.<br />
-1. In the <strong>.env</strong> file enter more environment variables
for the copilot application:</li>
<li><ul class="incremental">
<li><strong>AZURE_SUBSCRIPTION_ID</strong>: Your Azure subscription
ID</li>
</ul></li>
<li><ul class="incremental">
<li><strong>AZURE_RESOURCE_GROUP</strong>: Your Azure resource
group</li>
</ul></li>
<li><ul class="incremental">
<li><strong>AZUREAI_PROJECT_NAME</strong>: Your Azure AI Studio project
name</li>
</ul></li>
<li><ul class="incremental">
<li><strong>AZURE_OPENAI_CONNECTION_NAME</strong>: Use the same
<strong>AIServices</strong> or <strong>Azure OpenAI</strong> connection
that you used <a
href="../quickstarts/get-started-playground.md#deploy-a-chat-model">to
deploy the chat model</a>.</li>
</ul></li>
<li>-You can find the subscription ID, resource group name, and project
name from your project view in AI Studio.<br />
-1. In <a href="https://ai.azure.com">AI Studio</a>, go to your project
and select <strong>Settings</strong> from the left pane.<br />
-1. In the <strong>Project details</strong> section, you can find the
<strong>Subscription ID</strong> and <strong>Resource
group</strong>.<br />
-1. In the <strong>Project settings</strong> section, you can find the
<strong>Project name</strong>.</li>
<li>-By now, you should have the following environment variables in your
<em>.env</em> file:<br />
+There’s a collection of environment variables used across the different
code snippets. Add them all into an <strong>.env</strong> file.</li>
</ul>
<p>-<code>env -AZURE_OPENAI_ENDPOINT=endpoint_value -AZURE_OPENAI_DEPLOYMENT_NAME=chat_model_deployment_name -AZURE_OPENAI_API_VERSION=api_version -AZURE_SUBSCRIPTION_ID=&lt;your subscription id&gt; -AZURE_RESOURCE_GROUP=&lt;your resource group&gt; -AZUREAI_PROJECT_NAME=&lt;your project name&gt; -AZURE_OPENAI_CONNECTION_NAME=&lt;your AIServices or Azure OpenAI connection name&gt; -</code><br />
-<br />
-## Deploy an embedding model<br />
+&gt; [!IMPORTANT]<br />
+&gt; If you create this in a git repository, ensure that
<code>.env</code> is in your <code>.gitignore</code> file so that you
don’t accidentally check it into the repository.</p>
<p>-For the <a
href="../concepts/retrieval-augmented-generation.md">retrieval augmented
generation (RAG)</a> capability, we need to be able to embed the search
query to search the Azure AI Search index we create.<br />
+Start with these values. You’ll add a few more values as you progress
through the tutorial.</p>
<p>-1. Deploy an Azure OpenAI embedding model. Follow the <a
href="../how-to/deploy-models-openai.md">deploy Azure OpenAI models
guide</a> and deploy the <strong>text-embedding-ada-002</strong> model.
Use the same <strong>AIServices</strong> or <strong>Azure
OpenAI</strong> connection that you used <a
href="../quickstarts/get-started-playground.md#deploy-a-chat-model">to
deploy the chat model</a>.<br />
-2. Add embedding model environment variables in your <em>.env</em>
file. For the <em>AZURE_OPENAI_EMBEDDING_DEPLOYMENT</em> value, enter
the name of the embedding model that you deployed.<br />
+1. Create an <strong>.env</strong> file into your
<strong>rag-tutorial</strong> folder. Add these variables:</p>
<pre><code> ```env</code></pre>
<ul class="incremental">
<li>AZURE_OPENAI_EMBEDDING_DEPLOYMENT=embedding_model_deployment_name</li>
<li>AZURE_SUBSCRIPTION_ID=<your subscription id></li>
<li>AZURE_RESOURCE_GROUP=<your resource group></li>
<li>AZUREAI_PROJECT_NAME=<your project name></li>
<li>AZURE_OPENAI_CONNECTION_NAME=<your AIServices or Azure OpenAI connection name></li>
<li>AZURE_SEARCH_ENDPOINT=<your Azure Search endpoint></li>
<li>AZURE_SEARCH_CONNECTION_NAME=<your Azure Search connection name><br />
```<br />
+Replace the placeholders with the following values:</li>
</ul>
<h2
id="for-more-information-about-the-embedding-model-see-the-azure-openai-service-embeddings-documentation.">-For
more information about the embedding model, see the <a
href="../../ai-services/openai/how-to/embeddings.md">Azure OpenAI
Service embeddings documentation</a>.</h2>
<h2 id="create-an-azure-ai-search-index">-## Create an Azure AI Search
index</h2>
<h2
id="the-goal-with-this-rag-based-application-is-to-ground-the-model-responses-in-your-custom-data.-you-use-an-azure-ai-search-index-that-stores-vectorized-data-from-the-embeddings-model.-the-search-index-is-used-to-retrieve-relevant-documents-based-on-the-users-question.">-The
goal with this RAG-based application is to ground the model responses in
your custom data. You use an Azure AI Search index that stores
vectorized data from the embeddings model. The search index is used to
retrieve relevant documents based on the user’s question.</h2>
<h2
id="you-need-an-azure-ai-search-service-and-connection-in-order-to-create-a-search-index.">-You
need an Azure AI Search service and connection in order to create a
search index.</h2>
<p>-&gt; [!NOTE]<br />
-&gt; Creating an <a href="/azure/search/">Azure AI Search service</a>
and subsequent search indexes has associated costs. You can see details
about pricing and pricing tiers for the Azure AI Search service on the
creation page, to confirm cost before creating the resource.<br />
-<br />
-### Create an Azure AI Search service<br />
-<br />
-If you already have an Azure AI Search service in the same location as
your project, you can skip to the <a
href="#create-an-azure-ai-search-connection">next section</a>.<br />
+* Find the <code>&lt;your subscription id&gt;</code>,
<code>&lt;your resource group&gt;</code>, and
<code>&lt;your project name&gt;</code> from your project view in AI
Studio:<br />
+ 1. In <a href="https://ai.azure.com">AI Studio</a>, go to your project
and select <strong>Settings</strong> from the left pane.<br />
+ 1. In the <strong>Project properties</strong> section, find the
<strong>Subscription ID</strong> and <strong>Resource group</strong>.
The <strong>Name</strong> field is
<code>&lt;your project name&gt;</code><br />
+* Still in your project <strong>Settings</strong>, in the
<strong>Connected resources</strong> section, you’ll see an entry for
either Azure AIServices or Azure OpenAI. Select the name to open the
<strong>Connection Details</strong>. The connection name appears at the
top of the <strong>Connection Details</strong> page. Copy this name to
use for
<code>&lt;your AIServices or Azure OpenAI connection name&gt;</code>.<br />
+* Go back to the project <strong>Settings</strong> page. In the
<strong>Connected resources</strong> section, select the link for the
Azure AI Search.<br />
+ * Copy the <strong>Target</strong> URL for
<code>&lt;your Azure Search endpoint&gt;</code>.<br />
+ * Copy the name at the top for
<code>&lt;your Azure Search connection name&gt;</code>.</p>
<h2
id="otherwise-you-can-create-an-azure-ai-search-service-using-the-azure-portal-or-the-azure-cli-which-you-installed-previously-for-the-quickstart.">-Otherwise,
you can create an Azure AI Search service using the <a
href="https://portal.azure.com">Azure portal</a> or the Azure CLI (which
you installed previously for the <a
href="../quickstarts/get-started-code.md">quickstart</a>).</h2>
<p>-&gt; [!IMPORTANT]<br />
-&gt; Use the same location as your project for the Azure AI Search
service. Find your project’s location in the top-right project picker of
the Azure AI Studio in the project view.<br />
-<br />
-## <a href="#tab/azure-portal">Portal</a><br />
-<br />
-1. Go to the <a href="https://portal.azure.com">Azure portal</a>.<br />
-1. <a href="https://portal.azure.com/#create/Microsoft.Search">Create
an Azure AI Search service</a> in the Azure portal.<br />
-1. Select your resource group and instance details. You can see details
about pricing and pricing tiers on this page.<br />
-1. Continue through the wizard and select <strong>Review +
assign</strong> to create the resource.<br />
-1. Confirm the details of your Azure AI Search service, including
estimated cost.<br />
-<br />
-## <a href="#tab/cli">Azure CLI</a><br />
-<br />
-1. Open a terminal on your local machine.<br />
-1. Type <code>az</code> and then enter to verify that the Azure CLI
tool is installed. If it’s installed, a help menu with <code>az</code>
commands appears. If you get an error, make sure you followed the <a
href="../quickstarts/get-started-code.md#install-the-azure-cli-and-sign-in">steps
for installing the Azure CLI in the quickstart</a>.<br />
-1. Follow the steps to create an Azure AI Search service using the <a
href="/azure/search/search-manage-azure-cli#create-or-delete-a-service"><code>az search service create</code></a>
command.<br />
-<br />
—-<br />
-<br />
-### Create an Azure AI Search connection<br />
+ :::image type=“content”
source=“../media/tutorials/develop-rag-copilot-sdk/search-settings.png”
alt-text=“Screenshot shows endpoint and connection names.”:::</p>
<p>-If you already have an Azure AI Search connection in your project,
you can skip to <a
href="#configure-access-for-the-azure-ai-search-service">configure
access for the Azure AI Search service</a>. Only use an existing
connection if it’s in the same location as your project.<br />
+## Deploy models</p>
<p>-In the Azure AI Studio, check for an Azure AI Search connected
resource.<br />
+You need two models to build a RAG-based chat app: an Azure OpenAI chat
model (<code>gpt-3.5-turbo</code>) and an Azure OpenAI embedding model
(<code>text-embedding-ada-002</code>). Deploy these models in your Azure
AI Studio project, using this set of steps for each model.</p>
<p>-1. In <a href="https://ai.azure.com">AI Studio</a>, go to your
project and select <strong>Settings</strong> from the left pane.<br />
-1. In the <strong>Connected resources</strong> section, look to see if
you have a connection of type Azure AI Search.<br />
-1. If you have an Azure AI Search connection, verify that it is in the
same location as your project. If so, you can skip ahead to <a
href="#configure-access-for-the-azure-ai-search-service">configure
access for the Azure AI Search service</a>.<br />
-1. Otherwise, select <strong>New connection</strong> and then
<strong>Azure AI Search</strong>.<br />
-1. Find your Azure AI Search service in the options and select
<strong>Add connection</strong>.<br />
-1. Continue through the wizard to create the connection. For more
information about adding connections, see <a
href="../how-to/connections-add.md#create-a-new-connection">this how-to
guide</a>.<br />
+These steps deploy a model to a real-time endpoint from the AI Studio
<a href="../how-to/model-catalog-overview.md">model catalog</a>:</p>
<p>-### Configure access for the Azure AI Search service<br />
+1. Sign in to <a href="https://ai.azure.com">AI Studio</a> and go to
the <strong>Home</strong> page.<br />
+1. Select <strong>Model catalog</strong> from the left sidebar.<br />
+1. In the <strong>Collections</strong> filter, select <strong>Azure
OpenAI</strong>.</p>
<p>-We recommend using <a href="/entra/fundamentals/whatis">Microsoft
Entra ID</a> instead of using API keys. In order to use this
authentication, you need to set the right access controls and assign the
right roles for your Azure AI Search service.<br />
+ :::image type=“content”
source=“../media/deploy-monitor/catalog-filter-azure-openai.png”
alt-text=“A screenshot showing how to filter by Azure OpenAI models in
the catalog.”
lightbox=“../media/deploy-monitor/catalog-filter-azure-openai.png”:::</p>
<p>-&gt; [!WARNING]<br />
-&gt; You can use role-based access control locally because you run
<code>az login</code> later in this tutorial. But when you deploy your
app in <a href="./copilot-sdk-evaluate-deploy.md">part 2 of the
tutorial</a>, the deployment is authenticated using API keys from your
Azure AI Search service. Support for Microsoft Entra ID authentication
of the deployment is coming soon.<br />
+1. Select the model from the Azure OpenAI collection. The first time
through, select the <code>gpt-3.5-turbo</code> model. The second time,
select the <code>text-embedding-ada-002</code> model.<br />
+1. Select <strong>Deploy</strong> to open the deployment window.<br />
+1. Select the hub that you want to deploy the model to. Use the same
hub as your project.<br />
+1. Specify the deployment name and modify other default settings
depending on your requirements.<br />
+1. Select <strong>Deploy</strong>.<br />
+1. You land on the deployment details page. Select <strong>Open in
playground</strong>.<br />
+1. Select <strong>View Code</strong> to obtain code samples that can be
used to consume the deployed model in your application.<br />
+<br />
+When you deploy the <code>gpt-3.5-turbo</code> model, find the
following values in the <strong>View Code</strong> section, and add them
to your <strong>.env</strong> file:</p>
<p>-To enable role-based access control for your Azure AI Search
service, follow these steps:<br />
+<code>env +AZURE_OPENAI_ENDPOINT=&lt;chat_model_endpoint_value&gt; +AZURE_OPENAI_CHAT_DEPLOYMENT=&lt;chat_model_deployment_name&gt; +AZURE_OPENAI_API_VERSION=&lt;api_version&gt; +</code></p>
<p>-1. On your Azure AI Search service in the <a
href="https://portal.azure.com">Azure portal</a>, select
<strong>Settings &gt; Keys</strong> from the left pane.<br />
-1. Select <strong>Both</strong> to ensure that API keys and role-based
access control are both enabled for your Azure AI Search service.<br />
+When you deploy the <code>text-embedding-ada-002</code> model, add the
name to your <strong>.env</strong> file:</p>
<ul class="incremental">
<li>:::image type=“content”
source=“../media/tutorials/develop-rag-copilot-sdk/search-access-control.png”
alt-text=“Screenshot shows API Access control setting.”:::<br />
+<code>env +AZURE_OPENAI_EMBEDDING_DEPLOYMENT=&lt;embedding_model_deployment_name&gt; +</code></li>
</ul>
<p>-You or your administrator needs to grant your user identity the
<strong>Search Index Data Contributor</strong> and <strong>Search
Service Contributor</strong> roles on your Azure AI Search service.
These roles enable you to call the Azure AI Search service using your
user identity.<br />
+## Install the Azure CLI and sign in</p>
<p>-&gt; [!NOTE]<br />
-&gt; These steps are similar to how you assigned a role for your user
identity to use the Azure OpenAI Service in the <a
href="../quickstarts/get-started-code.md">quickstart</a>.<br />
+[!INCLUDE <a href="../includes/install-cli.md">Install the Azure
CLI</a>]</p>
<p>-In the Azure portal, follow these steps to assign the <strong>Search
Index Data Contributor</strong> role to your Azure AI Search
service:<br />
+Now we create our app and call the Azure OpenAI Service from code.</p>
<p>-1. Select your Azure AI Search service in the <a
href="https://portal.azure.com">Azure portal</a>.<br />
-1. From the left page in the Azure portal, select <strong>Access
control (IAM)</strong> &gt; <strong>+ Add</strong> &gt; <strong>Add role
assignment</strong>.<br />
-1. Search for the <strong>Search Index Data Contributor</strong> role
and then select it. Then select <strong>Next</strong>.<br />
-1. Select <strong>User, group, or service principal</strong>. Then
select <strong>Select members</strong>.<br />
-1. In the <strong>Select members</strong> pane that opens, search for
the name of the user that you want to add the role assignment for.
Select the user and then select <strong>Select</strong>.<br />
-1. Continue through the wizard and select <strong>Review +
assign</strong> to add the role assignment.<br />
+## Create a new Python environment</p>
<p>-Repeat the previous steps to add the <strong>Search Service
Contributor</strong> role.<br />
+[!INCLUDE <a href="../includes/install-python.md">Install
Python</a>]</p>
<p>-&gt; [!IMPORTANT]<br />
-&gt; After you assign these roles, run <code>az login</code> in your
console to ensure the changes propagate in your development environment.
This also ensures that you can use your user identity locally to
authenticate with the Azure AI Search service.<br />
+## Upgrade pip</p>
<p>-### Set search environment variables<br />
+To make sure you have the latest version of pip, run the following
command:</p>
<p>-You need to set environment variables for the Azure AI Search
service and connection in your <strong>.env</strong> file.<br />
+<code>bash +python -m pip install --upgrade pip +</code></p>
<p>-1. In <a href="https://ai.azure.com">AI Studio</a>, go to your
project and select <strong>Settings</strong> from the left pane.<br />
-1. In the <strong>Connected resources</strong> section, select the link
for the Azure AI Search service that you created previously.<br />
-1. Copy the <strong>Target</strong> URL for
<code>&lt;your Azure Search endpoint&gt;</code>.<br />
-1. Copy the name at the top for
<code>&lt;your Azure Search connection name&gt;</code>.<br />
+## Install the prompt flow SDK</p>
<ul class="incremental">
<li>:::image type=“content”
source=“../media/tutorials/develop-rag-copilot-sdk/search-settings.png”
alt-text=“Screenshot shows endpoint and connection names.”:::<br />
+<a href="https://microsoft.github.io/promptflow">Prompt flow</a> is a
suite of development tools designed to streamline the end-to-end
development cycle of LLM-based AI applications, from ideation,
prototyping, testing, evaluation to production deployment and
monitoring.</li>
</ul>
<p>-1. Add these environment variables to your <strong>.env</strong>
file:<br />
+[!INCLUDE <a href="../includes/install-promptflow.md">Install prompt
flow</a>]</p>
<ul class="incremental">
<li>```env</li>
<li>AZURE_SEARCH_ENDPOINT=<your Azure Search endpoint></li>
<li>AZURE_SEARCH_CONNECTION_NAME=<your Azure Search connection name></li>
<li>```<br />
+## Create an Azure AI Search index</li>
</ul>
<p>-### Create the search index<br />
+The goal with this RAG-based application is to ground the model
responses in your custom data. You use an Azure AI Search index that
stores vectorized data from the embeddings model. The search index is
used to retrieve relevant documents based on the user’s question.</p>
<p>-If you don’t have an Azure AI Search index already created, we walk
through how to create one. If you already have an index to use, you can
skip to the <a href="#set-search-environment-variables">set the search
environment variables</a> section. The search index is created on the
Azure AI Search service that was either created or referenced in the
previous step.<br />
+If you don’t have an Azure AI Search index already created, we walk
through how to create one. If you already have an index to use, you can
skip to the <a href="#set-search-index">set the search environment
variable</a> section. The search index is created on the Azure AI Search
service that was either created or referenced in the previous step.</p>
<ol class="incremental" type="1">
<li>Use your own data or <a
href="https://github.com/Azure-Samples/rag-data-openai-python-promptflow/tree/main/tutorial/data">download
the example Contoso Trek retail product data in a ZIP file</a> to your
local machine. Unzip the file into your <strong>rag-tutorial</strong>
folder. This data is a collection of markdown files that represent
product information. The data is structured in a way that is easy to
ingest into a search index. You build a search index from this
data.</li>
</ol>
<p>@@ -232,12 +163,6 @@ If you don’t have an Azure AI Search index
already created, we walk through how<br />
pip install promptflow-rag<br />
```</p>
<h2
id="upgrade-the-azure-ai-ml-package-to-the-latest-version.-run-the-following-command-in-your-terminal">-1.
Upgrade the <em>azure-ai-ml</em> package to the latest version. Run the
following command in your terminal:</h2>
<ul class="incremental">
<li>```bash</li>
<li>pip install azure-ai-ml -U</li>
<li>```</li>
<li><ol class="incremental" type="1">
<li>Create the <strong>build_index.py</strong> file in your
<strong>rag-tutorial</strong> folder.</li>
<li>Copy and paste the following code into your
<strong>build_index.py</strong> file.</li>
</ol></li>
</ul>
<p>@@ -259,7 +184,7 @@ If you don’t have an Azure AI Search index
already created, we walk through how</p>
<ol class="incremental" type="1">
<li>If you run the script again with the same index name, it creates a
new version of the same index.</li>
</ol>
<p>-### Set the search index environment variable<br />
+### <a name="set-search-index"></a> Set the search index environment
variable</p>
<p>Once you have the index name you want to use (either by creating a
new one, or referencing an existing one), add it to your
<strong>.env</strong> file, like this:</p>
<p>@@ -271,17 +196,17 @@ AZUREAI_SEARCH_INDEX_NAME=<index-name></p>
<p>Next you create custom code to add retrieval augmented generation
(RAG) capabilities to a basic chat application. In the quickstart, you
created <strong>chat.py</strong> and <strong>chat.prompty</strong>
files. Here you expand on that code to include RAG capabilities.</p>
<p>-The copilot with RAG implements the following general logic:<br />
+The chat app with RAG implements the following general logic:</p>
<ol class="incremental" type="1">
<li>Generate a search query based on user query intent and any chat
history</li>
<li>Use an embedding model to embed the query</li>
<li>Retrieve relevant documents from the search index, given the
query</li>
<li>Pass the relevant context to the Azure OpenAI chat completion
model</li>
<li>Return the response from the Azure OpenAI model</li>
</ol>
<p>-### The copilot implementation logic<br />
+### The chat app implementation logic</p>
<p>-The copilot implementation logic is in the
<strong>copilot.py</strong> file. This file contains the core logic for
the RAG-based copilot.<br />
+The chat app implementation logic is in the <strong>copilot.py</strong>
file. This file contains the core logic for the RAG-based chat app.</p>
<ol class="incremental" type="1">
<li>Create a folder named <strong>copilot_flow</strong> in the
<strong>rag-tutorial</strong> folder.</li>
<li>Then create a file called <strong>copilot.py</strong> in the
<strong>copilot_flow</strong> folder.<br />
@@ -338,7 +263,7 @@ Create the file <strong>requirements.txt</strong> in
the <strong>copilot_flow</strong> folder. Add this co</li>
</ol>
<p>:::code language=“txt”
source=“~/rag-data-openai-python-promptflow-main/tutorial/copilot_flow/requirements.txt”:::</p>
<p>-These are the packages required for the flow to run locally and in a
deployed environment.<br />
+These packages are required for the flow to run locally and in a
deployed environment.</p>
<p>### Use flex flow</p>
<p>@@ -350,9 +275,9 @@ Create the file <strong>flow.flex.yaml</strong>
in the <strong>copilot_flow</strong> folder. Add this cont</p>
<p>:::code language=“yaml”
source=“~/rag-data-openai-python-promptflow-main/tutorial/copilot_flow/flow.flex.yaml”:::</p>
<p>-## Use prompt flow to test your copilot<br />
+## Use prompt flow to test your chat app</p>
<p>-Use prompt flow’s testing capability to see how your copilot
performs as expected on sample inputs. By using your
<strong>flow.flex.yaml</strong> file, you can use prompt flow to test
with your specified inputs.<br />
+Use prompt flow’s testing capability to see how your chat app performs
as expected on sample inputs. By using your
<strong>flow.flex.yaml</strong> file, you can use prompt flow to test
with your specified inputs.</p>
<p>Run the flow using this prompt flow command:</p>
<p>@@ -394,17 +319,17 @@ The expected output is something like: “The
Alpine Explorer Tent is priced at $3</p>
<p>This system is able to interpret the intent of the query “how much
does it cost?” to know that “it” refers to the Alpine Explorer Tent,
which was the latest context in the chat history. Then the system
constructs a search query for the price of the Alpine Explorer Tent to
retrieve the relevant documents for the Alpine Explorer Tent’s cost, and
we get the response.</p>
<p>-If you navigate to the trace from this flow run, you see this in
action. The local traces link shows in the console output before the
result of the flow test run.<br />
+If you navigate to the trace from this flow run, you see the
conversation in action. The local traces link shows in the console
output before the result of the flow test run.</p>
<p>-:::image type=“content”
source=“../media/tutorials/develop-rag-copilot-sdk/trace-for-chat-history.png”
alt-text=“Screenshot shows the console output for the pf flow.”
lightbox=“../media/tutorials/develop-rag-copilot-sdk/trace-for-chat-history.png”
:::<br />
+:::image type=“content”
source=“../media/tutorials/develop-rag-copilot-sdk/trace-for-chat-history.png”
alt-text=“Screenshot shows the console output for the prompt flow.”
lightbox=“../media/tutorials/develop-rag-copilot-sdk/trace-for-chat-history.png”
:::</p>
<p>## Clean up resources</p>
<p>To avoid incurring unnecessary Azure costs, you should delete the
resources you created in this tutorial if they’re no longer needed. To
manage resources, you can use the <a
href="https://portal.azure.com?azure-portal=true">Azure portal</a>.</p>
<p>-But don’t delete them yet, if you want to deploy your copilot to
Azure in <a href="copilot-sdk-evaluate-deploy.md">the next part of this
tutorial series</a>.<br />
+But don’t delete them yet, if you want to deploy your chat app to Azure
in <a href="copilot-sdk-evaluate-deploy.md">the next part of this
tutorial series</a>.</p>
<p>## Next step</p>
<blockquote>
<p>[!div class=“nextstepaction”]<br />
-&gt; <a href="copilot-sdk-evaluate-deploy.md">Evaluate and deploy your
copilot to Azure</a><br />
+&gt; <a href="copilot-sdk-evaluate-deploy.md">Part 3: Evaluate and
deploy your chat app to Azure</a></p>
</blockquote>
<pre><code>&lt;/details&gt;

### Summary

```json
{
    &quot;filename&quot;: &quot;articles/ai-studio/tutorials/copilot-sdk-build-rag.md&quot;,
    &quot;modification_type&quot;: &quot;minor update&quot;,
    &quot;modification_title&quot;: &quot;チュートリアル内容のリネームと構造のアップデート&quot;
}</code></pre>
<h3 id="explanation-13">Explanation</h3>
<p>この変更により、<code>copilot-sdk-build-rag.md</code>
ファイルの内容が更新されました。具体的には、チュートリアルのタイトルと説明が変更され、セクションの構成も見直されています。タイトルは「Part
1: Build a RAG-based copilot with the prompt flow SDK」から「Part 2:
Build a custom chat app with the prompt flow
SDK」に変更され、このチュートリアルが3部構成であることが明確に示されています。</p>
<p>変更の中で、新しく追加された部分では、ユーザーが「RAG」（Retrieval
Augmented
Generation）を使用してカスタムチャットアプリを構築する方法に関する指示が含まれており、これにより、チュートリアルがより分かりやすくなっています。たとえば、新しい情報に基づいてユーザーの意図に沿った応答を生成するフローが説明されています。</p>
<p>また、以前のバージョンで含まれていた162行のテキストが削除され、87行の新しいコンテンツが追加されることにより、ファイルの全体的なボリュームが効率化されています。これらの変更により、開発者がプロジェクトを進める過程での理解を深められるようになり、必要な手順や情報を迅速に把握できるようになっています。</p>
<p>全体的に、このアップデートはドキュメントの可読性を向上させ、ユーザーにとっての学習曲線を緩和することを目指しています。明確なステップを通じて、ユーザーがカスタムチャットアプリの開発プロセスを容易に追跡できるようになっています。</p>
<h2
id="item-552960">articles/ai-studio/tutorials/copilot-sdk-create-resources.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb29"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -0,0 +1,153 @@</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="va">+title: &quot;Part 1: Create resources to build a custom chat app&quot;</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="va">+titleSuffix: Azure AI Studio</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="va">+description:  Build a custom chat app using the prompt flow SDK. Part 1 of a 3-part tutorial series, which shows how to create the resources you&#39;ll need for parts 2 and 3.</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="va">+manager: scottpolly</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.service: azure-ai-studio</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: tutorial</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 08/29/2024</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.reviewer: lebaro</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.author: sgilley</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="va">+author: sdgilley</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="va">+#customer intent: As a developer, I want to learn how to use the prompt flow SDK so that I can build a RAG-based chat app.</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="va">+# Tutorial:  Part 1 - Create resources for building a custom chat application with the prompt flow SDK</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="va">+In this tutorial, you use the prompt flow SDK (and other libraries) to build, configure, evaluate, and deploy a chat app for your retail company called Contoso Trek. Your retail company specializes in outdoor camping gear and clothing. The chat app should answer questions about your products and services. For example, the chat app can answer questions such as &quot;which tent is the most waterproof?&quot; or &quot;what is the best sleeping bag for cold weather?&quot;.</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="va">+This tutorial is part one of a three-part tutorial.  This part one shows how an administrator of an Azure subscription creates and configures the resources needed for parts two and three of the tutorial series. Parts two and three show how a developer uses the resources. In many organizations, the same person might take on both of these roles. In this part one, you learn how to:</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!div class=&quot;checklist&quot;]</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Create an Azure AI Studio hub</span></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Create a project</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Create an Azure AI Search index</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Configure access for the Azure AI Studio and Azure AI Search resources</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a><span class="va">+If you&#39;ve completed other tutorials or quickstarts, you might have already created some of the resources needed for this tutorial. If you have, feel free to skip those steps here.</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a><span class="va">+This tutorial is part one of a three-part tutorial.</span></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="va">+## Prerequisites</span></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a><span class="va">+* An Azure account with an active subscription. If you don&#39;t have one, [create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F).</span></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!IMPORTANT]</span></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; You must have the necessary permissions to add role assignments in your Azure subscription. Granting permissions by role assignment is only allowed by the **Owner** of the specific Azure resources. You might need to ask your Azure subscription owner (who might be your IT admin) to complete this tutorial for you.  </span></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a><span class="va">+## Azure AI Studio and Azure portal</span></span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a><span class="va">+In this tutorial, you use Azure resources to build the chat app.  You&#39;ll use both Azure AI Studio and Azure portal to create and configure these resources.</span></span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a><span class="va">+- As an administrator, you use Azure portal to configure access to resources.</span></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a><span class="va">+- As a developer, you use Azure AI Studio to group together those resources needed to build, evaluate, and deploy the chat app. You can also interact with your models and deployments in AI Studio.</span></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create an Azure AI Studio hub</span></span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [Create Azure AI Studio hub](../includes/create-hub.md)]</span></span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create a project</span></span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a><span class="va">+To create a project in [Azure AI Studio](https://ai.azure.com), follow these steps:</span></span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Go to the **Home** page of [Azure AI Studio](https://ai.azure.com). </span></span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select **+ New project**.</span></span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Enter a name for the project.</span></span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select the hub you created in the previous step.</span></span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a><span class="va">+Once a project is created, you can access the playground, tools, and other assets in the left navigation panel.</span></span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a><span class="va">+## Create an Azure AI Search index</span></span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a><span class="va">+The goal with this application is to ground the model responses in your custom data. The search index is used to retrieve relevant documents based on the user&#39;s question.</span></span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a><span class="va">+You need an Azure AI Search service and connection in order to create a search index.</span></span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!NOTE]</span></span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; Creating an [Azure AI Search service](/azure/search/) and subsequent search indexes has associated costs. You can see details about pricing and pricing tiers for the Azure AI Search service on the creation page, to confirm cost before creating the resource.</span></span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a><span class="va">+### Create an Azure AI Search service</span></span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a><span class="va">+If you already have an Azure AI Search service, you can skip to the [next section](#connect).</span></span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a><span class="va">+Otherwise, you can create an Azure AI Search service using the Azure portal.</span></span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a><span class="va">+1. [Create an Azure AI Search service](https://portal.azure.com/#create/Microsoft.Search) in the Azure portal.</span></span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select your resource group and instance details. You can see details about pricing and pricing tiers on this page.</span></span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Continue through the wizard and select **Review + assign** to create the resource.</span></span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Confirm the details of your Azure AI Search service, including estimated cost.</span></span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select **Create** to create the Azure AI Search service.</span></span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a><span class="va">+### &lt;a name=&quot;connect&quot;&gt;&lt;/a&gt;Connect the Azure AI Search to your project</span></span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a><span class="va">+If you already have an Azure AI Search connection in your project, you can skip to [configure access for the Azure AI Search service](#configure).</span></span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-86"><a href="#cb29-86" aria-hidden="true" tabindex="-1"></a><span class="va">+In the Azure AI Studio, check for an Azure AI Search connected resource.</span></span>
<span id="cb29-87"><a href="#cb29-87" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a><span class="va">+1. In [AI Studio](https://ai.azure.com), go to your project and select **Settings** from the left pane.</span></span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a><span class="va">+1. In the **Connected resources** section, look to see if you have a connection of type Azure AI Search.</span></span>
<span id="cb29-90"><a href="#cb29-90" aria-hidden="true" tabindex="-1"></a><span class="va">+1. If you have an Azure AI Search connection, you can skip ahead to [configure access for resources](#configure).</span></span>
<span id="cb29-91"><a href="#cb29-91" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Otherwise, select **New connection** and then **Azure AI Search**.</span></span>
<span id="cb29-92"><a href="#cb29-92" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Find your Azure AI Search service in the options and select **Add connection**.</span></span>
<span id="cb29-93"><a href="#cb29-93" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Continue through the wizard to create the connection. For more information about adding connections, see [this how-to guide](../how-to/connections-add.md#create-a-new-connection).</span></span>
<span id="cb29-94"><a href="#cb29-94" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-95"><a href="#cb29-95" aria-hidden="true" tabindex="-1"></a><span class="va">+## &lt;a name=&quot;configure&quot;&gt;&lt;/a&gt; Configure access for resources</span></span>
<span id="cb29-96"><a href="#cb29-96" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-97"><a href="#cb29-97" aria-hidden="true" tabindex="-1"></a><span class="va">+This section shows how to configure the various access controls needed for the resources you created in the previous sections.</span></span>
<span id="cb29-98"><a href="#cb29-98" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-99"><a href="#cb29-99" aria-hidden="true" tabindex="-1"></a><span class="va">+We recommend using [Microsoft Entra ID](/entra/fundamentals/whatis) instead of using API keys. In order to use this authentication, you need to set the right access controls and assign the right roles for your services. </span></span>
<span id="cb29-100"><a href="#cb29-100" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-101"><a href="#cb29-101" aria-hidden="true" tabindex="-1"></a><span class="va">+### Configure access for Azure AI Services</span></span>
<span id="cb29-102"><a href="#cb29-102" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-103"><a href="#cb29-103" aria-hidden="true" tabindex="-1"></a><span class="va">+Start in the project to find the AI Services resource:</span></span>
<span id="cb29-104"><a href="#cb29-104" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-105"><a href="#cb29-105" aria-hidden="true" tabindex="-1"></a><span class="va">+1. In [AI Studio](https://ai.azure.com), go to your project and select **Settings** from the left pane.</span></span>
<span id="cb29-106"><a href="#cb29-106" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select **Connected resources**.</span></span>
<span id="cb29-107"><a href="#cb29-107" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select the **AI Services** or **Azure OpenAI** name in the connected resources list to open the resource details page.  Then select the resource name again in the **Connection Details** page, which opens the resource in the Azure portal.</span></span>
<span id="cb29-108"><a href="#cb29-108" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-109"><a href="#cb29-109" aria-hidden="true" tabindex="-1"></a><span class="va">+Specify the access control in the Azure portal:</span></span>
<span id="cb29-110"><a href="#cb29-110" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-111"><a href="#cb29-111" aria-hidden="true" tabindex="-1"></a><span class="va">+1. From the left page in the Azure portal, select **Access control (IAM)** &gt; **+ Add** &gt; **Add role assignment**.</span></span>
<span id="cb29-112"><a href="#cb29-112" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Search for the role **Cognitive Services OpenAI User** and then select it. Then select **Next**.</span></span>
<span id="cb29-113"><a href="#cb29-113" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select **User, group, or service principal**. Then select **Select members**.</span></span>
<span id="cb29-114"><a href="#cb29-114" aria-hidden="true" tabindex="-1"></a><span class="va">+1. In the **Select members** pane that opens, search for the name of the user that you want to add the role assignment for. Select the user and then select **Select**.</span></span>
<span id="cb29-115"><a href="#cb29-115" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Continue through the wizard and select **Review + assign** to add the role assignment.</span></span>
<span id="cb29-116"><a href="#cb29-116" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-117"><a href="#cb29-117" aria-hidden="true" tabindex="-1"></a><span class="va">+### Configure access for Azure AI Search</span></span>
<span id="cb29-118"><a href="#cb29-118" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-119"><a href="#cb29-119" aria-hidden="true" tabindex="-1"></a><span class="va">+Now go back to [AI Studio](https://ai.azure.com) **Settings** &gt; **Connected Resources**.  This time select the **Azure AI Search** name in the connected resources list to open the resource details page.  Then select the resource name again in the **Connection Details** page, which opens the resource in the Azure portal.</span></span>
<span id="cb29-120"><a href="#cb29-120" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-121"><a href="#cb29-121" aria-hidden="true" tabindex="-1"></a><span class="va">+To enable role-based access control for your Azure AI Search service, follow these steps:</span></span>
<span id="cb29-122"><a href="#cb29-122" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-123"><a href="#cb29-123" aria-hidden="true" tabindex="-1"></a><span class="va">+1. On your Azure AI Search service in the [Azure portal](https://portal.azure.com), select **Settings &gt; Keys** from the left pane.</span></span>
<span id="cb29-124"><a href="#cb29-124" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select **Both** to ensure that API keys and role-based access control are both enabled for your Azure AI Search service. </span></span>
<span id="cb29-125"><a href="#cb29-125" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-126"><a href="#cb29-126" aria-hidden="true" tabindex="-1"></a><span class="va">+    :::image type=&quot;content&quot; source=&quot;../media/tutorials/develop-rag-copilot-sdk/search-access-control.png&quot; alt-text=&quot;Screenshot shows API Access control setting.&quot;:::</span></span>
<span id="cb29-127"><a href="#cb29-127" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-128"><a href="#cb29-128" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!WARNING]</span></span>
<span id="cb29-129"><a href="#cb29-129" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; You can use role-based access control locally because you run `az login` later in this tutorial series. But when you deploy your app in [part 3 of the tutorial](./copilot-sdk-evaluate-deploy.md), the deployment is authenticated using API keys from your Azure AI Search service. Support for Microsoft Entra ID authentication of the deployment is coming soon. For now, you need to enable both keys and endpoints.</span></span>
<span id="cb29-130"><a href="#cb29-130" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-131"><a href="#cb29-131" aria-hidden="true" tabindex="-1"></a><span class="va">+Next grant your user identity (or the identity of the developer who will complete parts two and three) the **Search Index Data Contributor** and **Search Service Contributor** roles on the Azure AI Search service. These roles enable you to call the Azure AI Search service the associated user identity.</span></span>
<span id="cb29-132"><a href="#cb29-132" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-133"><a href="#cb29-133" aria-hidden="true" tabindex="-1"></a><span class="va">+Still in the Azure portal for the Azure AI Search service, assign the **Search Index Data Contributor** role to your Azure AI Search service. (These are the same steps you did previously for the Azure OpenAI service.)</span></span>
<span id="cb29-134"><a href="#cb29-134" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-135"><a href="#cb29-135" aria-hidden="true" tabindex="-1"></a><span class="va">+1. From the left page in the Azure portal, select **Access control (IAM)** &gt; **+ Add** &gt; **Add role assignment**.</span></span>
<span id="cb29-136"><a href="#cb29-136" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Search for the **Search Index Data Contributor** role and then select it. Then select **Next**.</span></span>
<span id="cb29-137"><a href="#cb29-137" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select **User, group, or service principal**. Then select **Select members**.</span></span>
<span id="cb29-138"><a href="#cb29-138" aria-hidden="true" tabindex="-1"></a><span class="va">+1. In the **Select members** pane that opens, search for the name of the user that you want to add the role assignment for. Select the user and then select **Select**.</span></span>
<span id="cb29-139"><a href="#cb29-139" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Continue through the wizard and select **Review + assign** to add the role assignment. </span></span>
<span id="cb29-140"><a href="#cb29-140" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-141"><a href="#cb29-141" aria-hidden="true" tabindex="-1"></a><span class="va">+Repeat these steps to also add the **Search Service Contributor** role to the Azure AI Search service.</span></span>
<span id="cb29-142"><a href="#cb29-142" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-143"><a href="#cb29-143" aria-hidden="true" tabindex="-1"></a><span class="va">+You&#39;re now ready to hand off the project to a developer to build the chat application.  The developer will use the prompt flow SDK to build, configure, evaluate, and deploy the chat app for your retail company called Contoso Trek.</span></span>
<span id="cb29-144"><a href="#cb29-144" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-145"><a href="#cb29-145" aria-hidden="true" tabindex="-1"></a><span class="va">+## Clean up resources</span></span>
<span id="cb29-146"><a href="#cb29-146" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-147"><a href="#cb29-147" aria-hidden="true" tabindex="-1"></a><span class="va">+To avoid incurring unnecessary Azure costs, you should delete the resources you created in this tutorial if they&#39;re no longer needed. To manage resources, you can use the [Azure portal](https://portal.azure.com?azure-portal=true).</span></span>
<span id="cb29-148"><a href="#cb29-148" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-149"><a href="#cb29-149" aria-hidden="true" tabindex="-1"></a><span class="va">+But don&#39;t delete them yet, if you want to build a chat app in [the next part of this tutorial series](copilot-sdk-build-rag.md).</span></span>
<span id="cb29-150"><a href="#cb29-150" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-151"><a href="#cb29-151" aria-hidden="true" tabindex="-1"></a><span class="va">+## Next step</span></span>
<span id="cb29-152"><a href="#cb29-152" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb29-153"><a href="#cb29-153" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!div class=&quot;nextstepaction&quot;]</span></span>
<span id="cb29-154"><a href="#cb29-154" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [Part 2: Build a custom chat app with the prompt flow SDK](copilot-sdk-build-rag.md)</span></span></code></pre></div>
</details>
<h3 id="summary-12">Summary</h3>
<div class="sourceCode" id="cb30"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/ai-studio/tutorials/copilot-sdk-create-resources.md&quot;</span><span class="fu">,</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;カスタムチャットアプリ構築のためのリソース作成ガイド&quot;</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-14">Explanation</h3>
<p>この変更では、新たに <code>copilot-sdk-create-resources.md</code>
ファイルが追加され、Azure AI
Studioを使用してカスタムチャットアプリの構築に必要なリソースを作成するための具体的な手順が提供されています。このチュートリアルは3部構成のうちの第1部であり、リソース作成に焦点を当てています。</p>
<p>チュートリアルでは、まずAzureアカウントとその権限が必要であることが述べられています。次に、AzureポータルやAzure
AI
Studioを用いて、以下のリソースを作成・設定する手順が詳述されています：</p>
<ul class="incremental">
<li>Azure AI Studioのハブの作成</li>
<li>プロジェクトの作成</li>
<li>Azure AI Searchインデックスの作成</li>
<li>Azure AI StudioおよびAzure AI
Searchリソースへのアクセス設定の構成</li>
</ul>
<p>ここで重要な点は、プロジェクトとそのリソースの管理に関する役割の違いを明確にしている点です。管理者はAzureポータルを使用してリソースのアクセスを設定し、開発者はAzure
AI
Studioを使ってリソースをグループ化してチャットアプリを構築することに特化しています。</p>
<p>また、適切なアクセス制御を設定するための推奨として、Microsoft Entra
IDを使用することが挙げられています。このように、ユーザーはこのチュートリアルを通じて、カスタムチャットアプリの基盤となるリソースを効率的に準備することができるようになります。</p>
<p>全体として、この新しいガイドは、ユーザーがチャットアプリ開発の準備を整えるための重要なステップを示しており、次のチュートリアルへとスムーズに進むための基盤を提供しています。</p>
<h2
id="item-96e7b3">articles/ai-studio/tutorials/copilot-sdk-evaluate-deploy.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb31"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,47 +1,45 @@</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="st">-title: &quot;Part 2: Evaluate and deploy copilot with the prompt flow SDK&quot;</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="va">+title: &quot;Part 3: Evaluate and deploy chat app with the prompt flow SDK&quot;</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure AI Studio</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="st">-description: Evaluate and deploy a RAG-based copilot with the prompt flow SDK. This tutorial is part 2 of a two-part tutorial.</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="va">+description: Evaluate and deploy a custom chat app with the prompt flow SDK. This tutorial is part 3 of a 3-part tutorial series.</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a> manager: scottpolly</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a> ms.service: azure-ai-studio</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a> ms.topic: tutorial</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 8/6/2024</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 08/29/2024</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a> ms.reviewer: lebaro</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a> ms.author: sgilley</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a> author: sdgilley</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="st">-#customer intent: As a developer, I want to learn how to use the prompt flow SDK so that I can evaluate and deploy a copilot.</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="va">+#customer intent: As a developer, I want to learn how to use the prompt flow SDK so that I can evaluate and deploy a chat app.</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="st">-# Tutorial: Part 2 - Evaluate and deploy a RAG-based copilot with the prompt flow SDK</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="va">+# Tutorial: Part 3 - Evaluate and deploy a custom chat application with the prompt flow SDK</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="st">-In this [Azure AI Studio](https://ai.azure.com) tutorial, you use the prompt flow SDK (and other libraries) to  evaluate and deploy the copilot you built in [Part 1 of the tutorial series](copilot-sdk-build-rag.md).</span></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a><span class="st">-This tutorial is part two of a two-part tutorial.</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a><span class="st">-In this part two, you learn how to:</span></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="va">+In this tutorial, you use the prompt flow SDK (and other libraries) to  evaluate and deploy the chat app you built in [Part 2 of the tutorial series](copilot-sdk-build-rag.md). In this part three, you learn how to:</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a> &gt; [!div class=&quot;checklist&quot;]</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; - [Evaluate the quality of copilot responses](#evaluate-the-quality-of-copilot-responses)</span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; - [Deploy the copilot to Azure](#deploy-the-copilot-to-azure)</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; - [Verify the deployment](#verify-the-deployment)</span></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Evaluate the quality of chat app responses</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Deploy the chat app to Azure</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; - Verify the deployment</span></span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a><span class="va">+This tutorial is part three of a three-part tutorial.</span></span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a> ## Prerequisites</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a><span class="st">-- You must complete [part 1 of the tutorial series](copilot-sdk-build-rag.md) to build the copilot application.</span></span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a><span class="va">+- Complete [part 2 of the tutorial series](copilot-sdk-build-rag.md) to build the chat application.</span></span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a> - You must have the necessary permissions to add role assignments in your Azure subscription. Granting permissions by role assignment is only allowed by the **Owner** of the specific Azure resources. You might need to ask your Azure subscription owner (who might be your IT admin) for help with endpoint access later in the tutorial.</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a><span class="st">-## Evaluate the quality of copilot responses</span></span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a><span class="va">+## &lt;a name=&quot;evaluate&quot;&gt;&lt;/a&gt; Evaluate the quality of the chat app responses</span></span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a><span class="st">-Now that you know your copilot responds well to your queries, including with chat history, it&#39;s time to evaluate how it does across a few different metrics and more data.</span></span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a><span class="va">+Now that you know your chat app responds well to your queries, including with chat history, it&#39;s time to evaluate how it does across a few different metrics and more data.</span></span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a> You use the prompt flow evaluator with an evaluation dataset and the `get_chat_response()` target function, then assess the evaluation results.</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a><span class="st">-Once you run an evaluation, you can then make improvements to your logic, like improving your system prompt, and observing how the copilot responses change and improve.</span></span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a><span class="va">+Once you run an evaluation, you can then make improvements to your logic, like improving your system prompt, and observing how the chat app responses change and improve.</span></span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a> ### Set your evaluation model</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a><span class="st">-Choose the evaluation model you want to use. It can be the same as the chat model you deployed before. If you want a different model for evaluation, you need to deploy it, or specify it if it already exists. For example, you might be using gpt-35-turbo for your chat completions, but want to use gpt-4 for evaluation since it might perform better.</span></span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a><span class="va">+Choose the evaluation model you want to use. It can be the same as a chat model you used to build the app. If you want a different model for evaluation, you need to deploy it, or specify it if it already exists. For example, you might be using `gpt-35-turbo` for your chat completions, but want to use `gpt-4` for evaluation since it might perform better.</span></span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a> Add your evaluation model name in your **.env** file:</span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -64,9 +62,9 @@ Now define an evaluation script that will:</span></span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a> - Import the `evaluate` function and evaluators from the Prompt flow `evals` package.</span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a> - Load the sample `.jsonl` dataset.</span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a><span class="st">-- Generate a target function wrapper around our copilot logic.</span></span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a><span class="st">-- Run the evaluation, which takes the target function, and merges the evaluation dataset with the responses from the copilot.</span></span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a><span class="st">-- Generate a set of GPT-assisted metrics (relevance, groundedness, and coherence) to evaluate the quality of the copilot responses.</span></span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a><span class="va">+- Generate a target function wrapper around our chat app logic.</span></span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a><span class="va">+- Run the evaluation, which takes the target function, and merges the evaluation dataset with the responses from the chat app.</span></span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a><span class="va">+- Generate a set of GPT-assisted metrics (relevance, groundedness, and coherence) to evaluate the quality of the chat app responses.</span></span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a> - Output the results locally, and logs the results to the cloud project.</span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a> The script allows you to review the results locally, by outputting the results in the command line, and to a json file.</span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -88,10 +86,11 @@ The main function at the end allows you to view the evaluation result locally, a</span></span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>     az login</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>     ```</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Install the required package:</span></span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Install the required packages:</span></span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>     ```bash</span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>     pip install promptflow-evals</span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a><span class="va">+    pip install promptflow-azure</span></span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>     ```</span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a> 1. Now run the evaluation script:</span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -147,11 +146,11 @@ You can also look at the individual rows and see metric scores per row, and view</span></span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a> For more information about evaluation results in AI Studio, see [How to view evaluation results in AI Studio](../how-to/evaluate-flow-results.md).</span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a><span class="st">-Now that you verified your copilot behaves as expected, you&#39;re ready to deploy your application.</span></span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a><span class="va">+Now that you verified your chat app behaves as expected, you&#39;re ready to deploy your application.</span></span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a><span class="st">-## Deploy the copilot to Azure</span></span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a><span class="va">+## &lt;a name=&quot;deploy&quot;&gt;&lt;/a&gt;Deploy the chat app to Azure</span></span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a><span class="st">-Now let&#39;s go ahead and deploy this copilot to a managed endpoint so that it can be consumed by an external application or website. </span></span>
<span id="cb31-102"><a href="#cb31-102" aria-hidden="true" tabindex="-1"></a><span class="va">+Now let&#39;s go ahead and deploy this chat app to a managed endpoint so that it can be consumed by an external application or website. </span></span>
<span id="cb31-103"><a href="#cb31-103" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-104"><a href="#cb31-104" aria-hidden="true" tabindex="-1"></a> The deploy script will:</span>
<span id="cb31-105"><a href="#cb31-105" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-106"><a href="#cb31-106" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -161,7 +160,7 @@ The deploy script will:</span></span>
<span id="cb31-107"><a href="#cb31-107" aria-hidden="true" tabindex="-1"></a> - Route all traffic to that deployment</span>
<span id="cb31-108"><a href="#cb31-108" aria-hidden="true" tabindex="-1"></a> - Output the link to view and test the deployment in the Azure AI Studio</span>
<span id="cb31-109"><a href="#cb31-109" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-110"><a href="#cb31-110" aria-hidden="true" tabindex="-1"></a><span class="st">-The deployment defines a build context (Dockerfile) that relies on the `requirement.txt` specified in our flow folder, and also sets our environment variables to the deployed environment, so we can be confident that our copilot application runs the same in a production environment as it did locally.</span></span>
<span id="cb31-111"><a href="#cb31-111" aria-hidden="true" tabindex="-1"></a><span class="va">+The deployment defines a build context (Dockerfile) that relies on the `requirement.txt` specified in our flow folder, and also sets our environment variables to the deployed environment, so we can be confident that our chat app runs the same in a production environment as it did locally.</span></span>
<span id="cb31-112"><a href="#cb31-112" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-113"><a href="#cb31-113" aria-hidden="true" tabindex="-1"></a> ### Build context for the deployment (Dockerfile)</span>
<span id="cb31-114"><a href="#cb31-114" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-115"><a href="#cb31-115" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -174,11 +173,11 @@ COPY ./requirements.txt .</span></span>
<span id="cb31-116"><a href="#cb31-116" aria-hidden="true" tabindex="-1"></a> RUN pip install -r requirements.txt</span></code></pre></div>
<p>-### Deploy copilot to a managed endpoint<br />
+### Deploy chat app to a managed endpoint</p>
<p>To deploy your application to a managed endpoint in Azure, create an
online endpoint, then create a deployment in that endpoint, and then
route all traffic to that deployment.</p>
<p>-As part of creating the deployment, your copilot_flow folder is
packaged as a model and a cloud environment is built. The endpoint is
set up with Microsoft Entra ID authentication. You can update the auth
mode you want in the code, or in the Azure AI Studio on the endpoint
details page.<br />
+As part of creating the deployment, your <strong>copilot_flow</strong>
folder is packaged as a model and a cloud environment is built. The
endpoint is set up with Microsoft Entra ID authentication. You can
update the auth mode you want in the code, or in the Azure AI Studio on
the endpoint details page.</p>
<blockquote>
<p>[!IMPORTANT]<br />
Deploying your application to a managed endpoint in Azure has associated
compute cost based on the instance type you choose. Make sure you are
aware of the associated cost and have quota for the instance type you
specify. Learn more about <a
href="/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list">online
endpoints</a>.<br />
@@ -207,7 +206,7 @@ python deploy.py</p>
</blockquote>
<p>Once the deployment is completed, you get a link to the Azure AI
Studio deployment page, where you can test your deployment.</p>
<p>-## Verify the deployment<br />
+## <a name="verify"></a>Verify the deployment</p>
<p>We recommend you test your application in the Azure AI Studio. If you
prefer to test your deployed endpoint locally, you can invoke it with
some custom code.</p>
<p>@@ -259,7 +258,7 @@ To grant yourself access to the Azure AI Services
resource that you’re using:</p>
<p>You might need to ask your Azure subscription owner (who might be
your IT admin) for help with this section.</p>
<p>-Similar to how you assigned the <strong>Search Index Data
Contributor</strong> <a
href="./copilot-sdk-build-rag.md#configure-access-for-the-azure-ai-search-service">role
to your Azure AI Search service</a>, you need to assign the same role
for your endpoint.<br />
+Similar to how you assigned the <strong>Search Index Data
Contributor</strong> <a
href="./copilot-sdk-create-resources.md#configure">role to your Azure AI
Search service</a>, you need to assign the same role for your
endpoint.</p>
<ol class="incremental" type="1">
<li>In Azure AI Studio, select <strong>Settings</strong> and navigate to
the connected <strong>Azure AI Search</strong> service.</li>
<li>Select the link to open a summary of the resource. Select the link
on the summary page to open the resource in the Azure portal.<br />
@@ -300,7 +299,7 @@ If you get an error, select the
<strong>Logs</strong> tab to get more details.<br />
&gt; [!NOTE]<br />
&gt; If you get an unauthorized error, your endpoint access may not have
been applied yet. Try again in a few minutes.</li>
</ol>
<p>-### Invoke the deployed copilot locally<br />
+### Invoke the deployed chat app locally</p>
<p>If you prefer to verify your deployment locally, you can invoke it
via a Python script.</p>
<p>@@ -313,7 +312,7 @@ Create an <strong>invoke-local.py</strong> file
in your <strong>rag-tutorial</strong> folder, with the fol</p>
<p>:::code language=“python”
source=“~/rag-data-openai-python-promptflow-main/tutorial/invoke-local.py”:::</p>
<p>-You should see the copilot reply to your query in the console.<br />
+You should see the chat app reply to your query in the console.</p>
<blockquote>
<p>[!NOTE]<br />
If you get an unauthorized error, your endpoint access may not have been
applied yet. Try again in a few minutes.<br />
@@ -325,4 +324,4 @@ To avoid incurring unnecessary Azure costs, you
should delete the resources you<br />
## Related content</p>
</blockquote>
<ul class="incremental">
<li><a href="../how-to/prompt-flow.md">Learn more about prompt
flow</a><br />
– For a sample copilot application that implements RAG, see <a
href="https://github.com/Azure-Samples/rag-data-openai-python-promptflow">Azure-Samples/rag-data-openai-python-promptflow</a><br />
 No newline at end of file<br />
+- For a sample chat app application that implements RAG, see <a
href="https://github.com/Azure-Samples/rag-data-openai-python-promptflow">Azure-Samples/rag-data-openai-python-promptflow</a></li>
</ul>
<pre><code>&lt;/details&gt;

### Summary

```json
{
    &quot;filename&quot;: &quot;articles/ai-studio/tutorials/copilot-sdk-evaluate-deploy.md&quot;,
    &quot;modification_type&quot;: &quot;minor update&quot;,
    &quot;modification_title&quot;: &quot;チャットアプリの評価とデプロイに関するガイドの更新&quot;
}</code></pre>
<h3 id="explanation-15">Explanation</h3>
<p>この変更は、<code>copilot-sdk-evaluate-deploy.md</code>ファイルに対する修正を含んでおり、主にタイトル、内容、手順の焦点がカスタムチャットアプリに移行されたことを反映しています。具体的には、チュートリアルの名称が「Part
2: Evaluate and deploy copilot with the prompt flow SDK」から「Part 3:
Evaluate and deploy chat app with the prompt flow
SDK」に変更され、全体の内容が3部構成のシリーズにおける第3部として位置付けられました。</p>
<p>このチュートリアルでは、ユーザーがプロンプトフローSDKを使用して、前のパートで構築したチャットアプリを評価し、Azureにデプロイする手順を学ぶことができます。評価する際は、アプリの応答の質を評価し、デプロイメントを行い、最終的にその実行結果を確認することが強調されています。</p>
<p>また、手順に関する重要な部分では、評価モデルの選定、評価スクリプトの実行、デプロイメント手順がチャットアプリに特化して表現され、元の「copilot」という用語は「chat
app」に置き換えられています。これにより、カスタムチャットアプリの構築と評価に関する具体的な指針が示されており、開発者が学習過程をより効果的に進めることができるようになっています。</p>
<p>さらに、リソースが削除される可能性があるとの注意喚起も含まれており、Azureでのコストを抑えるために不要なリソースを削除することが強調されています。このように、変更はドキュメントの内容を明確にし、ユーザーが求める情報をより直感的に得られるよう改善されています。</p>
<h2
id="item-9b3912">articles/machine-learning/concept-soft-delete.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb33"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,15 +1,16 @@</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a> title: &#39;Workspace soft deletion&#39;</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure Machine Learning</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="st">-description: Soft delete allows you to recover workspace data after accidental deletion </span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="va">+description: Soft delete allows you to recover workspace data after accidental deletion. Learn how to use the soft delete feature in Azure Machine Learning.</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a> services: machine-learning</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a> ms.service: azure-machine-learning</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a> ms.subservice: core</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.topic: conceptual</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.topic: concept-article</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a> ms.author: larryfr</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a> author: Blackmist</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a> ms.reviewer: deeikele</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 01/22/2024</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.custom: FY25Q1-Linter</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a> monikerRange: &#39;azureml-api-2 || azureml-api-1&#39;</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a> #Customer intent: As an IT pro, understand how to enable data protection capabilities, to protect against accidental deletion.</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -20,45 +21,45 @@ The soft delete feature for Azure Machine Learning workspace provides a data pro</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a> ## How workspace soft delete works</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a><span class="st">-When a workspace is soft deleted, data and metadata stored service-side get soft deleted, but some configurations get hard deleted. Below table provides an overview of which configurations and objects get soft deleted, and which are hard deleted.</span></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a><span class="st">-Data / configuration | Soft deleted | Hard deleted</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a><span class="kw">----|---|---</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a><span class="st">-Run History | ✓ | </span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a><span class="st">-Models | ✓ | </span></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a><span class="st">-Data | ✓ | </span></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a><span class="st">-Environments | ✓ | </span></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a><span class="st">-Components | ✓ |</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a><span class="st">-Notebooks | ✓ | </span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a><span class="st">-Pipelines | ✓ |</span></span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a><span class="st">-Designer pipelines | ✓ | </span></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a><span class="st">-AutoML jobs | ✓ |</span></span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a><span class="st">-Data labeling projects | ✓ | </span></span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a><span class="st">-Datastores | ✓ | </span></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a><span class="st">-Queued or running jobs | | ✓</span></span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a><span class="st">-Role assignments | | ✓*</span></span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a><span class="st">-Internal cache | | ✓ </span></span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a><span class="st">-Compute instance |  | ✓ </span></span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a><span class="st">-Compute clusters |  | ✓ </span></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a><span class="st">-Inference endpoints | | ✓ </span></span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a><span class="st">-Linked Databricks workspaces | | ✓*</span></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a><span class="va">+When a workspace is soft deleted, data and metadata stored service-side get soft deleted, but some configurations get hard deleted. The following table provides an overview of which configurations and objects get soft deleted, and which are hard deleted.</span></span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a><span class="va">+| Data / configuration | Soft deleted | Hard deleted |</span></span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a><span class="va">+|---|---|---|</span></span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a><span class="va">+| Run History | ✓ | |</span></span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a><span class="va">+| Models | ✓ | |</span></span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a><span class="va">+| Data | ✓ | |</span></span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a><span class="va">+| Environments | ✓ | |</span></span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a><span class="va">+| Components | ✓ | |</span></span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a><span class="va">+| Notebooks | ✓ | |</span></span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a><span class="va">+| Pipelines | ✓ | |</span></span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a><span class="va">+| Designer pipelines | ✓ | |</span></span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a><span class="va">+| AutoML jobs | ✓ | |</span></span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a><span class="va">+| Data labeling projects | ✓ | |</span></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a><span class="va">+| Datastores | ✓ | |</span></span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a><span class="va">+| Queued or running jobs | | ✓ |</span></span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a><span class="va">+| Role assignments | | ✓* |</span></span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a><span class="va">+| Internal cache | | ✓ |</span></span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a><span class="va">+| Compute instance |  | ✓ |</span></span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a><span class="va">+| Compute clusters |  | ✓ |</span></span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a><span class="va">+| Inference endpoints | | ✓ |</span></span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a><span class="va">+| Linked Databricks workspaces | | ✓* |</span></span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a> \* *Microsoft attempts recreation or reattachment when a workspace is recovered. Recovery isn&#39;t guaranteed, and a best effort attempt.*</span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a><span class="st">-After soft deletion, the service keeps necessary data and metadata during the recovery [retention period](#soft-delete-retention-period). When the retention period expires, or in case you permanently delete a workspace, data and metadata will be actively deleted.</span></span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a><span class="va">+After soft deletion, the service keeps necessary data and metadata during the recovery [retention period](#soft-delete-retention-period). When the retention period expires, or in case you permanently delete a workspace, data and metadata are actively deleted.</span></span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a> ## Soft delete retention period</span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a><span class="st">-A default retention period of 14 days holds for deleted workspaces. The retention period indicates how long workspace data remains available after it&#39;s deleted. The clock starts on the retention period as soon as a workspace is soft deleted.</span></span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a><span class="va">+A default retention period of 14 days holds for deleted workspaces. The retention period indicates how long workspace data remains available after deletion. The clock starts on the retention period as soon as a workspace is soft deleted.</span></span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a><span class="st">-During the retention period, soft deleted workspaces can be recovered or permanently deleted. Any other operations on the workspace, like submitting a training job, will fail. </span></span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a><span class="va">+During the retention period, soft deleted workspaces can be recovered or permanently deleted. Any other operations on the workspace, like submitting a training job, fail. </span></span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a> &gt; [!IMPORTANT]    </span>
<span id="cb33-84"><a href="#cb33-84" aria-hidden="true" tabindex="-1"></a> &gt; You can&#39;t reuse the name of a workspace that has been soft deleted until the retention period has passed or the workspace is permanently deleted. Once the retention period elapses, a soft deleted workspace automatically gets permanently deleted.</span>
<span id="cb33-85"><a href="#cb33-85" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a> ## Deleting a workspace</span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a><span class="st">-The default deletion behavior when deleting a workspace is soft delete. Optionally, you may override the soft delete behavior by permanently deleting your workspace. Permanently deleting a workspace ensures workspace data is immediately deleted. Use this option to meet related compliance requirements, or whenever you require a workspace name to be reused immediately after deletion. This may be useful in dev/test scenarios where you want to create and later delete a workspace.</span></span>
<span id="cb33-89"><a href="#cb33-89" aria-hidden="true" tabindex="-1"></a><span class="va">+The default deletion behavior when deleting a workspace is soft delete. Optionally, you might override the soft delete behavior by permanently deleting your workspace. Permanently deleting a workspace ensures workspace data is immediately deleted. Use this option to meet related compliance requirements, or whenever you require a workspace name to be reused immediately after deletion. Overriding the default behavior might be useful in dev/test scenarios where you want to create and later delete a workspace.</span></span>
<span id="cb33-90"><a href="#cb33-90" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-91"><a href="#cb33-91" aria-hidden="true" tabindex="-1"></a> When deleting a workspace from the Azure portal, check __Delete the workspace permanently__. You can permanently delete only one workspace at a time, and not using a batch operation. </span>
<span id="cb33-92"><a href="#cb33-92" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-93"><a href="#cb33-93" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -70,7 +71,7 @@ When deleting a workspace from the Azure portal, check __Delete the workspace pe</span></span>
<span id="cb33-94"><a href="#cb33-94" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-95"><a href="#cb33-95" aria-hidden="true" tabindex="-1"></a> :::moniker-end  </span>
<span id="cb33-96"><a href="#cb33-96" aria-hidden="true" tabindex="-1"></a> :::moniker range=&quot;azureml-api-2&quot;</span>
<span id="cb33-97"><a href="#cb33-97" aria-hidden="true" tabindex="-1"></a><span class="st">-If you are using the [Azure Machine Learning SDK or CLI](/python/api/azure-ai-ml/azure.ai.ml.operations.workspaceoperations#azure-ai-ml-operations-workspaceoperations-begin-delete), you can set the `permanently_delete` flag.</span></span>
<span id="cb33-98"><a href="#cb33-98" aria-hidden="true" tabindex="-1"></a><span class="va">+If you&#39;re using the [Azure Machine Learning SDK or CLI](/python/api/azure-ai-ml/azure.ai.ml.operations.workspaceoperations#azure-ai-ml-operations-workspaceoperations-begin-delete), you can set the `permanently_delete` flag.</span></span>
<span id="cb33-99"><a href="#cb33-99" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-100"><a href="#cb33-100" aria-hidden="true" tabindex="-1"></a> ```python</span>
<span id="cb33-101"><a href="#cb33-101" aria-hidden="true" tabindex="-1"></a> from azure.ai.ml import MLClient</span>
<span id="cb33-102"><a href="#cb33-102" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -109,22 +110,22 @@ Soft deleted workspaces can be managed under the Azure Machine Learning resource</span></span>
<span id="cb33-103"><a href="#cb33-103" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-104"><a href="#cb33-104" aria-hidden="true" tabindex="-1"></a> ## Recover a soft deleted workspace</span>
<span id="cb33-105"><a href="#cb33-105" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-106"><a href="#cb33-106" aria-hidden="true" tabindex="-1"></a><span class="st">-When you select *Recover* on a soft deleted workspace, it initiates an operation to restore the workspace state. The service attempts recreation or reattachment of a subset of resources, including Azure RBAC role assignments. Hard-deleted resources including compute clusters should be recreated by you.</span></span>
<span id="cb33-107"><a href="#cb33-107" aria-hidden="true" tabindex="-1"></a><span class="va">+When you select *Recover* on a soft deleted workspace, it initiates an operation to restore the workspace state. The service attempts recreation or reattachment of a subset of resources, including Azure RBAC role assignments. You must recreate hard-deleted resources, including compute clusters.</span></span>
<span id="cb33-108"><a href="#cb33-108" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-109"><a href="#cb33-109" aria-hidden="true" tabindex="-1"></a><span class="st">-Azure Machine Learning recovers Azure RBAC role assignments for the workspace identity, but doesn&#39;t recover role assignments you have added on the workspace. It may take up to 15 minutes for role assignments to propagate after workspace recovery.</span></span>
<span id="cb33-110"><a href="#cb33-110" aria-hidden="true" tabindex="-1"></a><span class="va">+Azure Machine Learning recovers Azure RBAC role assignments for the workspace identity, but doesn&#39;t recover role assignments you added on the workspace. It might take up to 15 minutes for role assignments to propagate after workspace recovery.</span></span>
<span id="cb33-111"><a href="#cb33-111" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-112"><a href="#cb33-112" aria-hidden="true" tabindex="-1"></a><span class="st">-Recovery of a workspace may not always be possible. Azure Machine Learning stores workspace metadata on [other Azure resources associated with the workspace](concept-workspace.md#associated-resources). In the event these dependent Azure resources were deleted, it may prevent the workspace from being recovered or correctly restored. Dependencies of the Azure Machine Learning workspace must be recovered first, before recovering a deleted workspace. The following table outlines recovery options for each dependency of the Azure Machine Learning workspace.</span></span>
<span id="cb33-113"><a href="#cb33-113" aria-hidden="true" tabindex="-1"></a><span class="va">+Recovery of a workspace isn&#39;t always possible. Azure Machine Learning stores workspace metadata on [other Azure resources associated with the workspace](concept-workspace.md#associated-resources). In the event these dependent Azure resources were deleted, it might prevent the workspace from being recovered or correctly restored. Dependencies of the Azure Machine Learning workspace must be recovered first, before recovering a deleted workspace. The following table outlines recovery options for each dependency of the Azure Machine Learning workspace.</span></span>
<span id="cb33-114"><a href="#cb33-114" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-115"><a href="#cb33-115" aria-hidden="true" tabindex="-1"></a> |Dependency|Recovery approach|</span>
<span id="cb33-116"><a href="#cb33-116" aria-hidden="true" tabindex="-1"></a> |---|---|</span>
<span id="cb33-117"><a href="#cb33-117" aria-hidden="true" tabindex="-1"></a> |Azure Key Vault| [Recover a deleted Azure Key Vault instance](/azure/key-vault/general/soft-delete-overview) |</span>
<span id="cb33-118"><a href="#cb33-118" aria-hidden="true" tabindex="-1"></a> |Azure Storage|[Recover a deleted Azure storage account](/azure/storage/common/storage-account-recover).|</span>
<span id="cb33-119"><a href="#cb33-119" aria-hidden="true" tabindex="-1"></a><span class="st">-|Azure Container Registry|Azure Container Registry is not a hard requirement for workspace recovery. Azure Machine Learning can regenerate images for custom environments.|</span></span>
<span id="cb33-120"><a href="#cb33-120" aria-hidden="true" tabindex="-1"></a><span class="va">+|Azure Container Registry|Azure Container Registry isn&#39;t a hard requirement for workspace recovery. Azure Machine Learning can regenerate images for custom environments.|</span></span>
<span id="cb33-121"><a href="#cb33-121" aria-hidden="true" tabindex="-1"></a> |Azure Application Insights| First, [recover your log analytics workspace](/azure/azure-monitor/logs/delete-workspace). Then recreate an application insights with the original name.|</span>
<span id="cb33-122"><a href="#cb33-122" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-123"><a href="#cb33-123" aria-hidden="true" tabindex="-1"></a> ## Billing implications</span>
<span id="cb33-124"><a href="#cb33-124" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-125"><a href="#cb33-125" aria-hidden="true" tabindex="-1"></a><span class="st">-In general, when a workspace is in soft deleted state, there are only two operations possible: &#39;permanently delete&#39; and &#39;recover&#39;. All other operations will fail. Therefore, even though the workspace exists, no compute operations can be performed and hence no usage will occur. When a workspace is soft deleted, any cost-incurring resources including compute clusters are hard deleted.</span></span>
<span id="cb33-126"><a href="#cb33-126" aria-hidden="true" tabindex="-1"></a><span class="va">+In general, when a workspace is in soft deleted state, there are only two operations possible: &#39;permanently delete&#39; and &#39;recover&#39;. All other operations fail. Therefore, even though the workspace exists, no compute operations can be performed, and hence no usage occurs. When a workspace is soft deleted, any cost-incurring resources including compute clusters are hard deleted.</span></span>
<span id="cb33-127"><a href="#cb33-127" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-128"><a href="#cb33-128" aria-hidden="true" tabindex="-1"></a> &gt; [!IMPORTANT]    </span>
<span id="cb33-129"><a href="#cb33-129" aria-hidden="true" tabindex="-1"></a> &gt; Workspaces that use [customer-managed keys for encryption](concept-data-encryption.md) store additional service data in your subscription in a managed resource group. When a workspace is soft deleted, the managed resource group and resources in it will not be deleted and will incur cost until the workspace is hard-deleted.</span>
<span id="cb33-130"><a href="#cb33-130" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -133,11 +134,11 @@ In general, when a workspace is in soft deleted state, there are only two operat</span></span>
<span id="cb33-131"><a href="#cb33-131" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-132"><a href="#cb33-132" aria-hidden="true" tabindex="-1"></a> After soft deletion, the service keeps necessary data and metadata during the recovery [retention period](#soft-delete-retention-period). From a GDPR and privacy perspective, a request to delete personal data should be interpreted as a request for *permanent* deletion of a workspace and not soft delete.</span>
<span id="cb33-133"><a href="#cb33-133" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-134"><a href="#cb33-134" aria-hidden="true" tabindex="-1"></a><span class="st">-When the retention period expires, or in case you permanently delete a workspace, data and metadata will be actively deleted. You could choose to permanently delete a workspace at the time of deletion.</span></span>
<span id="cb33-135"><a href="#cb33-135" aria-hidden="true" tabindex="-1"></a><span class="va">+When the retention period expires, or in case you permanently delete a workspace, data and metadata are actively deleted. You could choose to permanently delete a workspace at the time of deletion.</span></span>
<span id="cb33-136"><a href="#cb33-136" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-137"><a href="#cb33-137" aria-hidden="true" tabindex="-1"></a> For more information, see the [Export or delete workspace data](how-to-export-delete-data.md) article.</span>
<span id="cb33-138"><a href="#cb33-138" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-139"><a href="#cb33-139" aria-hidden="true" tabindex="-1"></a><span class="st">-## Next steps</span></span>
<span id="cb33-140"><a href="#cb33-140" aria-hidden="true" tabindex="-1"></a><span class="va">+## Related content</span></span>
<span id="cb33-141"><a href="#cb33-141" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb33-142"><a href="#cb33-142" aria-hidden="true" tabindex="-1"></a> + [Create and manage a workspace](how-to-manage-workspace.md)</span>
<span id="cb33-143"><a href="#cb33-143" aria-hidden="true" tabindex="-1"></a> + [Export or delete workspace data](how-to-export-delete-data.md)</span></code></pre></div>
</details>
<h3 id="summary-13">Summary</h3>
<div class="sourceCode" id="cb34"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/concept-soft-delete.md&quot;</span><span class="fu">,</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;ワークスペースのソフト削除に関するガイドの更新&quot;</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-16">Explanation</h3>
<p>この変更は、<code>concept-soft-delete.md</code>ファイルに対する修正を含み、Azure
Machine
Learningにおけるソフト削除機能についての説明を明確にしています。主な変更点は以下の通りです：</p>
<ol class="incremental" type="1">
<li><strong>タイトルとメタデータの修正</strong>：
<ul class="incremental">
<li>タイトルや説明文に具体性を持たせ、ソフト削除機能の使用方法を学ぶことを明記しました。</li>
<li>作成日が2024年1月22日から2024年9月9日に変更され、リリースの最新化が反映されています。</li>
</ul></li>
<li><strong>内容の整理</strong>：
<ul class="incremental">
<li>ソフト削除されたワークスペースにおけるデータとメタデータの管理方法に関する情報が整理され、視覚的に分かりやすい表形式で提供されています。これにより、どの構成とオブジェクトがソフト削除され、どれがハード削除されるかが一目でわかるようになりました。</li>
</ul></li>
<li><strong>文言の簡潔化</strong>：
<ul class="incremental">
<li>文中の表現の見直しが行われ、特に「データが削除された後」や「削除する際」など、読みやすくなるように普通の表現が使われています。</li>
</ul></li>
<li><strong>関連情報の強調</strong>：
<ul class="incremental">
<li>データ保護やGDPRに関連する重要な行を強調し、個人データ削除のリクエストがワークスペースの恒久的削除に該当することを明記しています。</li>
</ul></li>
<li><strong>次のステップから関連コンテンツへの変更</strong>：
<ul class="incremental">
<li>「次のステップ」というセクションから「関連コンテンツ」に変更され、関連情報を見つけやすくなっています。</li>
</ul></li>
</ol>
<p>全体的に、この変更はドキュメントの明瞭さと有用性を向上させており、ユーザーがAzure
Machine
Learningのソフト削除機能を理解しやすくすることを目的としています。</p>
<h2
id="item-edd02a">articles/machine-learning/how-to-auto-train-forecast.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb35"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,7 +1,7 @@</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a> title: Set up AutoML for time-series forecasting</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure Machine Learning</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="st">-description: Set up Azure Machine Learning automated ML to train time-series forecasting models with the Azure Machine Learning CLI and Python SDK</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="va">+description: Set up Azure Machine Learning automated ML to train time-series forecasting models with the Azure Machine Learning CLI and Python SDK.</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a> services: machine-learning</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a> author: ssalgadodev</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a> ms.author: ssalgado</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -10,45 +10,42 @@ ms.service: azure-machine-learning</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a> ms.subservice: automl</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a> ms.topic: how-to</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a> ms.custom: automl, sdkv2, build-2023, devx-track-python, devx-track-azurecli</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 08/01/2023</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a> show_latex: true</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="va">+#customer intent: As a data scientist, I want to train time-series forecasting models and understand the options available for training them by using AutoML.</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a> # Set up AutoML to train a time-series forecasting model with SDK and CLI</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a> [!INCLUDE [dev v2](includes/machine-learning-dev-v2.md)]</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="va">+AutoML uses standard machine learning models along with well-known time series models to create forecasts. This approach incorporates historical information about the target variable, user-provided features in the input data, and automatically engineered features. Model search algorithms work to find a model with the best predictive accuracy. For more information, see [forecasting methodology](./concept-automl-forecasting-methods.md) and [model search](concept-automl-forecasting-sweeping.md).</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="st">-In this article, you&#39;ll learn how to set up AutoML for time-series forecasting with Azure Machine Learning automated ML in the [Azure Machine Learning Python SDK](/python/api/overview/azure/ai-ml-readme).</span></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a><span class="va">+In this article, you learn how to set up AutoML for time-series forecasting with Azure Machine Learning automated ML in the [Azure Machine Learning Python SDK](/python/api/overview/azure/ai-ml-readme).</span></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a><span class="st">-To do so, you: </span></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a><span class="va">+To do so, you:</span></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!div class=&quot;checklist&quot;]</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; * Prepare data for training.</span></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; * Configure specific time-series parameters in a [Forecasting Job](/python/api/azure-ai-ml/azure.ai.ml.automl.forecastingjob).</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; * Orchestrate training, inference, and model evaluation using components and pipelines.</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a><span class="va">+- Prepare data for training.</span></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a><span class="va">+- Configure specific time-series parameters in a [Forecasting Job](/python/api/azure-ai-ml/azure.ai.ml.automl.forecastingjob).</span></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a><span class="va">+- Orchestrate training, inference, and model evaluation using components and pipelines.</span></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a><span class="st">-For a low code experience, see the [Tutorial: Forecast demand with automated machine learning](tutorial-automated-ml-forecast.md) for a time-series forecasting example using automated ML in the [Azure Machine Learning studio](https://ml.azure.com/).</span></span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a><span class="st">-AutoML uses standard machine learning models along with well-known time series models to create forecasts. Our approach incorporates historical information about the target variable, user-provided features in the input data, and automatically engineered features. Model search algorithms then work to find a model with the best predictive accuracy. For more details, see our articles on [forecasting methodology](./concept-automl-forecasting-methods.md) and [model search](concept-automl-forecasting-sweeping.md). </span></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a><span class="va">+For a low code experience, see [Tutorial: Forecast demand with automated machine learning](tutorial-automated-ml-forecast.md). This resource is a time-series forecasting example that uses automated ML in the [Azure Machine Learning studio](https://ml.azure.com/).</span></span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a> ## Prerequisites</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a><span class="st">-For this article you need, </span></span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a><span class="st">-* An Azure Machine Learning workspace. To create the workspace, see [Create workspace resources](quickstart-create-resources.md).</span></span>
<span id="cb35-50"><a href="#cb35-50" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb35-51"><a href="#cb35-51" aria-hidden="true" tabindex="-1"></a><span class="st">-* The ability to launch AutoML training jobs. Follow the [how-to guide for setting up AutoML](how-to-configure-auto-train.md) for details.</span></span>
<span id="cb35-52"><a href="#cb35-52" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure Machine Learning workspace. To create a workspace, see [Create workspace resources](quickstart-create-resources.md).</span></span>
<span id="cb35-53"><a href="#cb35-53" aria-hidden="true" tabindex="-1"></a><span class="va">+- The ability to launch AutoML training jobs. For more information, see [how-to guide for setting up AutoML](how-to-configure-auto-train.md).</span></span>
<span id="cb35-54"><a href="#cb35-54" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-55"><a href="#cb35-55" aria-hidden="true" tabindex="-1"></a> ## Training and validation data</span>
<span id="cb35-56"><a href="#cb35-56" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-57"><a href="#cb35-57" aria-hidden="true" tabindex="-1"></a><span class="st">-Input data for AutoML forecasting must contain valid time series in tabular format. Each variable must have its own corresponding column in the data table. AutoML requires at least two columns: a **time column** representing the time axis and the **target column** which is the quantity to forecast. Other columns can serve as predictors. For more details, see [how AutoML uses your data](./concept-automl-forecasting-methods.md#how-automl-uses-your-data). </span></span>
<span id="cb35-58"><a href="#cb35-58" aria-hidden="true" tabindex="-1"></a><span class="va">+Input data for AutoML forecasting must contain a valid time series in tabular format. Each variable must have its own corresponding column in the data table. AutoML requires at least two columns: a *time column* that represents the time axis and the *target column, which is the quantity to forecast. Other columns can serve as predictors. For more information, see [how AutoML uses your data](./concept-automl-forecasting-methods.md#how-automl-uses-your-data).</span></span>
<span id="cb35-59"><a href="#cb35-59" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-60"><a href="#cb35-60" aria-hidden="true" tabindex="-1"></a> &gt; [!IMPORTANT]</span>
<span id="cb35-61"><a href="#cb35-61" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; When training a model for forecasting future values, ensure all the features used in training can be used when running predictions for your intended horizon. &lt;br&gt; &lt;br&gt; For example, a feature for current stock price could massively increase training accuracy. However, if you intend to forecast with a long horizon, you may not be able to accurately predict future stock values corresponding to future time-series points, and model accuracy could suffer.</span></span>
<span id="cb35-62"><a href="#cb35-62" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb35-63"><a href="#cb35-63" aria-hidden="true" tabindex="-1"></a><span class="st">-AutoML forecasting jobs require that your training data is represented as an **MLTable** object. An MLTable specifies a data source and steps for loading the data. For more information and use cases, see the [MLTable how-to guide](./how-to-mltable.md). As a simple example, suppose your training data is contained in a CSV file in a local directory, `./train_data/timeseries_train.csv`. </span></span>
<span id="cb35-64"><a href="#cb35-64" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; When you train a model for forecasting future values, ensure that all the features used in training can be used when running predictions for your intended horizon.</span></span>
<span id="cb35-65"><a href="#cb35-65" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt;</span></span>
<span id="cb35-66"><a href="#cb35-66" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; For example, a feature for current stock price could massively increase training accuracy. However, if you intend to forecast with a long horizon, you might not be able to accurately predict future stock values that correspond to future time-series points. Model accuracy could suffer.</span></span>
<span id="cb35-67"><a href="#cb35-67" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-68"><a href="#cb35-68" aria-hidden="true" tabindex="-1"></a><span class="va">+AutoML forecasting jobs require that your training data is represented as an *MLTable* object. An MLTable specifies a data source and steps for loading the data. For more information and use cases, see [Working with tables in Azure Machine Learning](./how-to-mltable.md). As an example, suppose your training data is contained in a CSV file in a local directory, *./train_data/timeseries_train.csv*.</span></span>
<span id="cb35-69"><a href="#cb35-69" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-70"><a href="#cb35-70" aria-hidden="true" tabindex="-1"></a> # [Python SDK](#tab/python)</span>
<span id="cb35-71"><a href="#cb35-71" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb35-72"><a href="#cb35-72" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -65,9 +62,9 @@ train_table = mltable.from_delimited_files(paths)</span></span>
<span id="cb35-73"><a href="#cb35-73" aria-hidden="true" tabindex="-1"></a> train_table.save(&#39;./train_data&#39;)</span></code></pre></div>
<p>-This code creates a new file, <code>./train_data/MLTable</code>,
which contains the file format and loading instructions.<br />
+This code creates a new file, <em>./train_data/MLTable</em>, which
contains the file format and loading instructions.</p>
<p>-You now define an input data object, which is required to start a
training job, using the Azure Machine Learning Python SDK as
follows:<br />
+In order to start the training job, define an input data object by
using the Azure Machine Learning Python SDK as follows:</p>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> azure.ai.ml.constants <span class="im">import</span> AssetTypes</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="op">@@</span> <span class="op">-</span><span class="dv">77</span>,<span class="dv">11</span> <span class="op">+</span><span class="dv">74</span>,<span class="dv">11</span> <span class="op">@@</span> <span class="im">from</span> azure.ai.ml <span class="im">import</span> Input</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>my_training_data_input <span class="op">=</span> Input(</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">type</span><span class="op">=</span>AssetTypes.MLTABLE, path<span class="op">=</span><span class="st">&quot;./train_data&quot;</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>``` </span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="op">+</span>```</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co"># [Azure CLI](#tab/cli)</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>You can define a new MLTable by copying the following YAML text to a new <span class="bu">file</span>, `.<span class="op">/</span>train_data<span class="op">/</span>MLTable`:</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="op">+</span>You can define a new MLTable by copying the following YAML text to a new <span class="bu">file</span>, <span class="op">*</span>.<span class="op">/</span>train_data<span class="op">/</span>MLTable<span class="op">*</span>:</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>```yml</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>$schema: https:<span class="op">//</span>azuremlschemas.azureedge.net<span class="op">/</span>latest<span class="op">/</span>MLTable.schema.json</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="op">@@</span> <span class="op">-</span><span class="dv">96</span>,<span class="dv">7</span> <span class="op">+</span><span class="dv">93</span>,<span class="dv">7</span> <span class="op">@@</span> transformations:</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>        encoding: <span class="bu">ascii</span></span></code></pre></div>
<p>-You now begin building the YAML configuration file for the AutoML
job, with the training data specified as shown in the following
example:<br />
+Begin building the YAML configuration file for the AutoML job with the
training data specified as shown in the following example:</p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode yml"><code class="sourceCode yaml"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">$schema</span><span class="kw">:</span><span class="at"> https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLJob.schema.json</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -130,16 +127,17 @@ training</span><span class="kw">:</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co">    # training settings </span></span></code></pre></div>
<p>-We add more detail to this configuration in subsequent sections of
this how-to guide, assuming the YAML text is stored at the path,
<code>./automl-forecasting-job.yml</code>.<br />
+Add more detail to this configuration in subsequent sections of this
how-to guide. In this example, the location is
<em>./automl-forecasting-job.yml</em>.</p>
<hr />
<p>-You specify <a
href="concept-automated-ml.md#training-validation-and-test-data">validation
data</a> in a similar way, by creating a MLTable and specifying a
validation data input. Alternatively, if you don’t supply validation
data, AutoML automatically creates cross-validation splits from your
training data to use for model selection. See our article on <a
href="./concept-automl-forecasting-sweeping.md#model-selection">forecasting
model selection</a> for more details. Also see <a
href="./concept-automl-forecasting-methods.md#data-length-requirements">training
data length requirements</a> for details on how much training data you
need to successfully train a forecasting model.<br />
+You specify <a
href="concept-automated-ml.md#training-validation-and-test-data">validation
data</a> in a similar way. Create a MLTable and specify a validation
data input. Alternatively, if you don’t supply validation data, AutoML
automatically creates cross-validation splits from your training data to
use for model selection. For more information, see <a
href="./concept-automl-forecasting-sweeping.md#model-selection">forecasting
model selection</a>. For more information about how much training data
you need, see <a
href="./concept-automl-forecasting-methods.md#data-length-requirements">training
data length requirements</a>.</p>
<p>Learn more about how AutoML applies cross validation to <a
href="concept-manage-ml-pitfalls.md#prevent-overfitting">prevent over
fitting</a>.</p>
<p>## Compute to run experiment<br />
-AutoML uses Azure Machine Learning Compute, which is a fully managed
compute resource, to run the training job. In the following example, a
compute cluster named <code>cpu-compute</code> is created:<br />
+<br />
+AutoML uses Azure Machine Learning Compute, which is a fully managed
compute resource, to run the training job. Create a compute cluster
named <code>cpu-compute</code>.</p>
<p># <a href="#tab/python">Python SDK</a></p>
<p>@@ -153,7 +151,7 @@ You can create a new compute called
<code>cpu-compute</code> with the following CLI command<br />
az ml compute create -n cpu-compute –type amlcompute –min-instances 0
–max-instances 4<br />
```</p>
<p>-Then, you reference this compute in the job definition as
follows:<br />
+Reference this compute in the job definition as follows:</p>
<div class="sourceCode" id="cb38"><pre
class="sourceCode yml"><code class="sourceCode yaml"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">$schema</span><span class="kw">:</span><span class="at"> https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLJob.schema.json</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -184,7 +182,7 @@ forecasting</span><span class="kw">:</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="fu">training</span><span class="kw">:</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co">    # training settings</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="at">-``` </span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="at">+```</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="at">@@ -217,7 +215,14 @@ forecasting_job.set_limits(</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co"># [Azure CLI](#tab/cli)</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="at">-We now configure general properties of the AutoML job like the [primary metric](how-to-configure-auto-train.md</span><span class="co">#primary-metric), the name of the target column in the training data, the cross-validation settings, and resource limits on the job. See the [forecasting job](reference-automated-ml-forecasting.md), [training parameters](reference-automated-ml-forecasting.md#training), and [limits](reference-automated-ml-forecasting.md#limits) reference documents for more information and a full list of parameters.</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="fu">+Configure general properties of the AutoML job, including</span><span class="kw">:</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="at">+</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="at">+- The [primary metric](how-to-configure-auto-train.md</span><span class="co">#primary-metric)</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="at">+- The name of the target column in the training data</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="at">+- The cross-validation settings</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="at">+- Resource limits on the job</span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="at">+</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="at">+For more information, see the [forecasting job](reference-automated-ml-forecasting.md), [training parameters](reference-automated-ml-forecasting.md</span><span class="co">#training), and [limits](reference-automated-ml-forecasting.md#limits).</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a><span class="at">```yml</span></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a><span class="fu">$schema</span><span class="kw">:</span><span class="at"> https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLJob.schema.json</span></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -252,10 +257,12 @@ training</span><span class="kw">:</span></span></code></pre></div>
<h2 id="section">—</h2>
<p>-### Forecasting job settings</p>
<p>-Forecasting tasks have many settings that are specific to
forecasting. The most basic of these settings are the name of the time
column in the training data and the forecast horizon.<br />
+<a name="forecasting-job-settings"></a><br />
+<br />
+### Forecast job settings<br />
+<br />
+Forecasting tasks have many settings that are specific to forecasting.
The most basic of these settings are the name of the time column in the
training data and the forecast horizon.</p>
<p># <a href="#tab/python">Python SDK</a></p>
<p>@@ -271,7 +278,7 @@ forecasting_job.set_forecast_settings(</p>
<p># <a href="#tab/cli">Azure CLI</a></p>
<p>-These settings are configured in the <code>forecasting</code>
section of the job YAML:<br />
+These settings are configured in the <code>forecasting</code> section
of the job YAML:</p>
<div class="sourceCode" id="cb39"><pre
class="sourceCode yml"><code class="sourceCode yaml"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">$schema</span><span class="kw">:</span><span class="at"> https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLJob.schema.json</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -308,7 +315,7 @@ training</span><span class="kw">:</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="fu">-The time column name is a required setting and you should generally set the forecast horizon according to your prediction scenario. If your data contains multiple time series, you can specify the names of the **time series ID columns**. These columns, when grouped, define the individual series. For example, suppose that you have data consisting of hourly sales from different stores and brands. The following sample shows how to set the time series ID columns assuming the data contains columns named &quot;store&quot; and &quot;brand&quot;</span><span class="kw">:</span><span class="at"> </span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="fu">+The time column name is a required setting. You should generally set the forecast horizon according to your prediction scenario. If your data contains multiple time series, you can specify the names of the *time series ID columns*. These columns, when grouped, define the individual series. For example, suppose that you have data that consists of hourly sales from different stores and brands. The following sample shows how to set the time series ID columns assuming that the data contains columns named *store* and *brand*</span><span class="kw">:</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -333,17 +340,17 @@ forecasting</span><span class="kw">:</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="at">-AutoML tries to automatically detect time series ID columns in your data if none are specified.</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="at">+AutoML tries to automatically detect time series ID columns in your data if none is specified.</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="at">Other settings are optional and reviewed in the next section.</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="co">### Optional forecasting job settings</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a><span class="at">-Optional configurations are available for forecasting tasks, such as enabling deep learning and specifying a target rolling window aggregation. A complete list of parameters is available in the forecasting [reference documentation](reference-automated-ml-forecasting.md</span><span class="co">#forecasting) documentation.</span></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a><span class="at">+Optional configurations are available for forecasting tasks, such as enabling deep learning and specifying a target rolling window aggregation. A complete list of parameters is available in the [reference documentation](reference-automated-ml-forecasting.md</span><span class="co">#forecasting) documentation.</span></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a><span class="co">#### Model search settings</span></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a><span class="fu">-There are two optional settings that control the model space where AutoML searches for the best model, `allowed_training_algorithms` and `blocked_training_algorithms`. To restrict the search space to a given set of model classes, use the `allowed_training_algorithms` parameter as in the following sample</span><span class="kw">:</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a><span class="fu">+There are two optional settings that control the model space where AutoML searches for the best model</span><span class="kw">:</span><span class="at"> `allowed_training_algorithms` and `blocked_training_algorithms`. To restrict the search space to a given set of model classes, use the `allowed_training_algorithms` parameter as in the following sample:</span></span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -392,7 +399,7 @@ training</span><span class="kw">:</span></span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a><span class="fu">-In this case, the forecasting job _only_ searches over Exponential Smoothing and Elastic Net model classes. To remove a given set of model classes from the search space, use the blocked_training_algorithms as in the following sample</span><span class="kw">:</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a><span class="fu">+In this case, the forecasting job *only* searches over Exponential Smoothing and Elastic Net model classes. To remove a given set of model classes from the search space, use the `blocked_training_algorithms` as in the following sample</span><span class="kw">:</span></span>
<span id="cb39-38"><a href="#cb39-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-39"><a href="#cb39-39" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb39-40"><a href="#cb39-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-41"><a href="#cb39-41" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -415,13 +422,13 @@ training</span><span class="kw">:</span></span>
<span id="cb39-42"><a href="#cb39-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-43"><a href="#cb39-43" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb39-44"><a href="#cb39-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-45"><a href="#cb39-45" aria-hidden="true" tabindex="-1"></a><span class="at">-Now, the job searches over all model classes _except_ Prophet. For a list of forecasting model names that are accepted in `allowed_training_algorithms` and `blocked_training_algorithms`, see the [training properties](reference-automated-ml-forecasting.md</span><span class="co">#training) reference documentation. Either, but not both, of `allowed_training_algorithms` and `blocked_training_algorithms` can be applied to a training run.</span></span>
<span id="cb39-46"><a href="#cb39-46" aria-hidden="true" tabindex="-1"></a><span class="at">+The job searches over all model classes *except* Prophet. For a list of forecasting model names that are accepted in `allowed_training_algorithms` and `blocked_training_algorithms`, see [training properties](reference-automated-ml-forecasting.md</span><span class="co">#training). You can apply either but not both `allowed_training_algorithms` and `blocked_training_algorithms` to a training run.</span></span>
<span id="cb39-47"><a href="#cb39-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-48"><a href="#cb39-48" aria-hidden="true" tabindex="-1"></a><span class="co">#### Enable deep learning</span></span>
<span id="cb39-49"><a href="#cb39-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-50"><a href="#cb39-50" aria-hidden="true" tabindex="-1"></a><span class="at">-AutoML ships with a custom deep neural network (DNN) model called `TCNForecaster`. This model is a [temporal convolutional network](https://arxiv.org/abs/1803.01271), or TCN, that applies common imaging task methods to time series modeling. Namely, one-dimensional &quot;causal&quot; convolutions form the backbone of the network and enable the model to learn complex patterns over long durations in the training history. For more details, see our [TCNForecaster article](./concept-automl-forecasting-deep-learning.md</span><span class="co">#introduction-to-tcnforecaster). </span></span>
<span id="cb39-51"><a href="#cb39-51" aria-hidden="true" tabindex="-1"></a><span class="at">+AutoML ships with a custom deep neural network (DNN) model called `TCNForecaster`. This model is a [temporal convolutional network](https://arxiv.org/abs/1803.01271) (TCN), that applies common imaging task methods to time series modeling. One-dimensional &quot;causal&quot; convolutions form the backbone of the network and enable the model to learn complex patterns over long durations in the training history. For more information, see [Introduction to TCNForecaster](./concept-automl-forecasting-deep-learning.md</span><span class="co">#introduction-to-tcnforecaster).</span></span>
<span id="cb39-52"><a href="#cb39-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-53"><a href="#cb39-53" aria-hidden="true" tabindex="-1"></a><span class="at">-:::image type=&quot;content&quot; source=&quot;media/how-to-auto-train-forecast/tcn-basic.png&quot; alt-text=&quot;Diagram showing major components of AutoML&#39;s TCNForecaster.&quot;:</span><span class="fu">:</span><span class="kw">:</span></span>
<span id="cb39-54"><a href="#cb39-54" aria-hidden="true" tabindex="-1"></a><span class="at">+:::image type=&quot;content&quot; source=&quot;media/how-to-auto-train-forecast/tcn-basic.png&quot; alt-text=&quot;Diagram showing major components of AutoML&#39;s TCNForecaster.&quot; lightbox=&quot;media/how-to-auto-train-forecast/tcn-basic.png&quot;:</span><span class="fu">:</span><span class="kw">:</span></span>
<span id="cb39-55"><a href="#cb39-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-56"><a href="#cb39-56" aria-hidden="true" tabindex="-1"></a><span class="at">The TCNForecaster often achieves higher accuracy than standard time series models when there are thousands or more observations in the training history. However, it also takes longer to train and sweep over TCNForecaster models due to their higher capacity.</span></span>
<span id="cb39-57"><a href="#cb39-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-58"><a href="#cb39-58" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -448,25 +455,25 @@ training</span><span class="kw">:</span></span>
<span id="cb39-59"><a href="#cb39-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-60"><a href="#cb39-60" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb39-61"><a href="#cb39-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-62"><a href="#cb39-62" aria-hidden="true" tabindex="-1"></a><span class="at">-By default, TCNForecaster training is limited to a single compute node and a single GPU, if available, per model trial. **For large data scenarios, we recommend distributing each TCNForecaster trial over multiple cores/GPUs** and nodes. See our [distributed training](how-to-configure-auto-train.md</span><span class="co">#distributed-training-for-forecasting) article section for more information and code samples.  </span></span>
<span id="cb39-63"><a href="#cb39-63" aria-hidden="true" tabindex="-1"></a><span class="at">+By default, TCNForecaster training is limited to a single compute node and a single GPU, if available, per model trial. For large data scenarios, we recommend distributing each TCNForecaster trial over multiple cores/GPUs and nodes. For more information and code samples, see [distributed training](how-to-configure-auto-train.md</span><span class="co">#distributed-training-for-forecasting).</span></span>
<span id="cb39-64"><a href="#cb39-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-65"><a href="#cb39-65" aria-hidden="true" tabindex="-1"></a><span class="at">To enable DNN for an AutoML experiment created in the Azure Machine Learning studio, see the [task type settings in the studio UI how-to](how-to-use-automated-ml-for-ml-models.md</span><span class="co">#create-and-run-experiment).</span></span>
<span id="cb39-66"><a href="#cb39-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-67"><a href="#cb39-67" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; [!NOTE]</span></span>
<span id="cb39-68"><a href="#cb39-68" aria-hidden="true" tabindex="-1"></a><span class="at">-&gt; * When you enable DNN for experiments created with the SDK, [best model explanations](./v1/how-to-machine-learning-interpretability-automl.md) are disabled.</span></span>
<span id="cb39-69"><a href="#cb39-69" aria-hidden="true" tabindex="-1"></a><span class="at">-&gt; * DNN support for forecasting in Automated Machine Learning is not supported for runs initiated in Databricks.</span></span>
<span id="cb39-70"><a href="#cb39-70" aria-hidden="true" tabindex="-1"></a><span class="at">-&gt; * GPU compute types are recommended when DNN training is enabled </span></span>
<span id="cb39-71"><a href="#cb39-71" aria-hidden="true" tabindex="-1"></a><span class="at">+&gt; - When you enable DNN for experiments created with the SDK, [best model explanations](./v1/how-to-machine-learning-interpretability-automl.md) are disabled.</span></span>
<span id="cb39-72"><a href="#cb39-72" aria-hidden="true" tabindex="-1"></a><span class="at">+&gt; - DNN support for forecasting in Automated Machine Learning is not supported for runs initiated in Databricks.</span></span>
<span id="cb39-73"><a href="#cb39-73" aria-hidden="true" tabindex="-1"></a><span class="at">+&gt; - We recommend GPU compute types when DNN training is enabled.</span></span>
<span id="cb39-74"><a href="#cb39-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-75"><a href="#cb39-75" aria-hidden="true" tabindex="-1"></a><span class="co">#### Lag and rolling window features</span></span>
<span id="cb39-76"><a href="#cb39-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-77"><a href="#cb39-77" aria-hidden="true" tabindex="-1"></a><span class="at">Recent values of the target are often impactful features in a forecasting model. Accordingly, AutoML can create time-lagged and rolling window aggregation features to potentially improve model accuracy.</span></span>
<span id="cb39-78"><a href="#cb39-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-79"><a href="#cb39-79" aria-hidden="true" tabindex="-1"></a><span class="at">Consider an energy demand forecasting scenario where weather data and historical demand are available.</span></span>
<span id="cb39-80"><a href="#cb39-80" aria-hidden="true" tabindex="-1"></a><span class="at">-The table shows resulting feature engineering that occurs when window aggregation is applied over the most recent three hours. Columns for **minimum, maximum,** and **sum** are generated on a sliding window of three hours based on the defined settings. For instance, for the observation valid on September 8, 2017 4:00am, the maximum, minimum, and sum values are calculated using the **demand values** for September 8, 2017 1:00AM - 3:00AM. This window of three hours shifts along to populate data for the remaining rows. For more details and examples, see the [lag feature article](concept-automl-forecasting-lags.md).</span></span>
<span id="cb39-81"><a href="#cb39-81" aria-hidden="true" tabindex="-1"></a><span class="at">+The table shows resulting feature engineering that occurs when window aggregation is applied over the most recent three hours. Columns for *minimum*, *maximum,* and *sum* are generated on a sliding window of three hours based on the defined settings. For instance, for the observation valid on September 8, 2017 4:00am, the maximum, minimum, and sum values are calculated using the *demand values* for September 8, 2017 1:00AM - 3:00AM. This window of three hours shifts along to populate data for the remaining rows. For more information and examples, see the [Lagged features for time series forecasting in AutoML](concept-automl-forecasting-lags.md).</span></span>
<span id="cb39-82"><a href="#cb39-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-83"><a href="#cb39-83" aria-hidden="true" tabindex="-1"></a><span class="at">-![target rolling window](./media/how-to-auto-train-forecast/target-roll.svg)</span></span>
<span id="cb39-84"><a href="#cb39-84" aria-hidden="true" tabindex="-1"></a><span class="at">+:::image type=&quot;content&quot; source=&quot;./media/how-to-auto-train-forecast/target-roll.svg&quot; alt-text=&quot;Screenshot shows the target rolling window with values for Demand called out.&quot;:</span><span class="fu">:</span><span class="kw">:</span></span>
<span id="cb39-85"><a href="#cb39-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-86"><a href="#cb39-86" aria-hidden="true" tabindex="-1"></a><span class="fu">-You can enable lag and rolling window aggregation features for the target by setting the rolling window size, which was three in the previous example, and the lag orders you want to create. You can also enable lags for features with the `feature_lags` setting. In the following sample, we set all of these settings to `auto` so that AutoML will automatically determine settings by analyzing the correlation structure of your data</span><span class="kw">:</span></span>
<span id="cb39-87"><a href="#cb39-87" aria-hidden="true" tabindex="-1"></a><span class="fu">+You can enable lag and rolling window aggregation features for the target by setting the rolling window size and the lag orders you want to create. The window size was three in the previous example. You can also enable lags for features with the `feature_lags` setting. In the following example, all of these settings are `auto` so that AutoML automatically determines settings by analyzing the correlation structure of your data</span><span class="kw">:</span></span>
<span id="cb39-88"><a href="#cb39-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-89"><a href="#cb39-89" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb39-90"><a href="#cb39-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-91"><a href="#cb39-91" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -495,18 +502,18 @@ forecasting</span><span class="kw">:</span></span>
<span id="cb39-92"><a href="#cb39-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-93"><a href="#cb39-93" aria-hidden="true" tabindex="-1"></a><span class="co">#### Short series handling</span></span>
<span id="cb39-94"><a href="#cb39-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-95"><a href="#cb39-95" aria-hidden="true" tabindex="-1"></a><span class="at">-Automated ML considers a time series a **short series** if there aren&#39;t enough data points to conduct the train and validation phases of model development. See [training data length requirements](./concept-automl-forecasting-methods.md</span><span class="co">#data-length-requirements) for more details on length requirements.</span></span>
<span id="cb39-96"><a href="#cb39-96" aria-hidden="true" tabindex="-1"></a><span class="at">+Automated ML considers a time series a *short series* if there aren&#39;t enough data points to conduct the train and validation phases of model development. For more information, see [training data length requirements](./concept-automl-forecasting-methods.md</span><span class="co">#data-length-requirements).</span></span>
<span id="cb39-97"><a href="#cb39-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-98"><a href="#cb39-98" aria-hidden="true" tabindex="-1"></a><span class="fu">-AutoML has several actions it can take for short series. These actions are configurable with the `short_series_handling_config` setting. The default value is &quot;auto.&quot; The following table describes the settings</span><span class="kw">:</span></span>
<span id="cb39-99"><a href="#cb39-99" aria-hidden="true" tabindex="-1"></a><span class="fu">+AutoML has several actions it can take for short series. These actions are configurable with the `short_series_handling_config` setting. The default value is `auto`. The following table describes the settings</span><span class="kw">:</span></span>
<span id="cb39-100"><a href="#cb39-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-101"><a href="#cb39-101" aria-hidden="true" tabindex="-1"></a><span class="at">-|Setting|Description</span></span>
<span id="cb39-102"><a href="#cb39-102" aria-hidden="true" tabindex="-1"></a><span class="at">-|---|---</span></span>
<span id="cb39-103"><a href="#cb39-103" aria-hidden="true" tabindex="-1"></a><span class="at">-|`auto`| The default value for short series handling. &lt;br&gt; - _If all series are short_, pad the data. &lt;br&gt; - _If not all series are short_, drop the short series. </span></span>
<span id="cb39-104"><a href="#cb39-104" aria-hidden="true" tabindex="-1"></a><span class="fu">-|`pad`| If `short_series_handling_config = pad`, then automated ML adds random values to each short series found. The following lists the column types and what they&#39;re padded with</span><span class="kw">:</span><span class="at"> &lt;br&gt; - Object columns with NaNs &lt;br&gt; - Numeric columns  with 0 &lt;br&gt; - Boolean/logic columns with False &lt;br&gt; - The target column is padded with white noise. </span></span>
<span id="cb39-105"><a href="#cb39-105" aria-hidden="true" tabindex="-1"></a><span class="at">-|`drop`| If `short_series_handling_config = drop`, then automated ML drops the short series, and it will not be used for training or prediction. Predictions for these series will return NaN&#39;s.</span></span>
<span id="cb39-106"><a href="#cb39-106" aria-hidden="true" tabindex="-1"></a><span class="at">-|`None`| No series is padded or dropped</span></span>
<span id="cb39-107"><a href="#cb39-107" aria-hidden="true" tabindex="-1"></a><span class="at">+| Setting | Description |</span></span>
<span id="cb39-108"><a href="#cb39-108" aria-hidden="true" tabindex="-1"></a><span class="at">+|:---|:---|</span></span>
<span id="cb39-109"><a href="#cb39-109" aria-hidden="true" tabindex="-1"></a><span class="at">+|`auto`| The default value for short series handling. &lt;br&gt; - *If all series are short*, pad the data. &lt;br&gt; - *If not all series are short*, drop the short series.|</span></span>
<span id="cb39-110"><a href="#cb39-110" aria-hidden="true" tabindex="-1"></a><span class="fu">+|`pad`| If `short_series_handling_config = pad`, automated ML adds random values to each short series found. The following lists the column types and what they&#39;re padded with</span><span class="kw">: </span><span class="at">&lt;br&gt; - Object columns with NaNs &lt;br&gt; - Numeric columns  with 0 &lt;br&gt; - Boolean/logic columns with False &lt;br&gt; - The target column is padded with white noise. </span><span class="ch">|</span></span>
<span id="cb39-111"><a href="#cb39-111" aria-hidden="true" tabindex="-1"></a><span class="at">+|`drop`| If `short_series_handling_config = drop`, automated ML drops the short series, and it isn&#39;t used for training or prediction. Predictions for these series return `NaN`. |</span></span>
<span id="cb39-112"><a href="#cb39-112" aria-hidden="true" tabindex="-1"></a><span class="at">+|`None`| No series is padded or dropped |</span></span>
<span id="cb39-113"><a href="#cb39-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-114"><a href="#cb39-114" aria-hidden="true" tabindex="-1"></a><span class="fu">-In the following example, we set the short series handling so that all short series are padded to the minimum length</span><span class="kw">:</span></span>
<span id="cb39-115"><a href="#cb39-115" aria-hidden="true" tabindex="-1"></a><span class="fu">+In the following example, set the short series handling so that all short series are padded to the minimum length</span><span class="kw">:</span></span>
<span id="cb39-116"><a href="#cb39-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-117"><a href="#cb39-117" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb39-118"><a href="#cb39-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-119"><a href="#cb39-119" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -529,26 +536,28 @@ forecasting</span><span class="kw">:</span></span>
<span id="cb39-120"><a href="#cb39-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-121"><a href="#cb39-121" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb39-122"><a href="#cb39-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-123"><a href="#cb39-123" aria-hidden="true" tabindex="-1"></a><span class="at">-&gt;[!WARNING]</span></span>
<span id="cb39-124"><a href="#cb39-124" aria-hidden="true" tabindex="-1"></a><span class="at">-&gt;Padding may impact the accuracy of the resulting model, since we are introducing artificial data to avoid training failures. If many of the series are short, then you may also see some impact in explainability results</span></span>
<span id="cb39-125"><a href="#cb39-125" aria-hidden="true" tabindex="-1"></a><span class="at">+&gt; [!CAUTION]</span></span>
<span id="cb39-126"><a href="#cb39-126" aria-hidden="true" tabindex="-1"></a><span class="at">+&gt; Padding can impact the accuracy of the resulting model, since you introduce artificial data to avoid training failures. If many of the series are short, you might also see some impact in explainability results.</span></span>
<span id="cb39-127"><a href="#cb39-127" aria-hidden="true" tabindex="-1"></a><span class="at">+</span></span>
<span id="cb39-128"><a href="#cb39-128" aria-hidden="true" tabindex="-1"></a><span class="at">+&lt;a name=&quot;frequency--target-data-aggregation&quot;&gt;&lt;/a&gt;</span></span>
<span id="cb39-129"><a href="#cb39-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-130"><a href="#cb39-130" aria-hidden="true" tabindex="-1"></a><span class="at">-</span><span class="co">#### Frequency &amp; target data aggregation</span></span>
<span id="cb39-131"><a href="#cb39-131" aria-hidden="true" tabindex="-1"></a><span class="at">+</span><span class="co">#### Frequency and target data aggregation</span></span>
<span id="cb39-132"><a href="#cb39-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-133"><a href="#cb39-133" aria-hidden="true" tabindex="-1"></a><span class="at">-Use the frequency and data aggregation options to avoid failures caused by irregular data. Your data is irregular if it doesn&#39;t follow a set cadence in time, like hourly or daily. Point-of-sales data is a good example of irregular data. In these cases, AutoML can aggregate your data to a desired frequency and then build a forecasting model from the aggregates. </span></span>
<span id="cb39-134"><a href="#cb39-134" aria-hidden="true" tabindex="-1"></a><span class="at">+Use the frequency and data aggregation options to avoid failures caused by irregular data. Your data is irregular if it doesn&#39;t follow a set cadence in time, like hourly or daily. Point-of-sales data is a good example of irregular data. In these cases, AutoML can aggregate your data to a desired frequency and then build a forecasting model from the aggregates.</span></span>
<span id="cb39-135"><a href="#cb39-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-136"><a href="#cb39-136" aria-hidden="true" tabindex="-1"></a><span class="at">You need to set the `frequency` and `target_aggregate_function` settings to handle irregular data. The frequency setting accepts [Pandas DateOffset strings](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html</span><span class="co">#dateoffset-objects) as input. Supported values for the aggregation function are:</span></span>
<span id="cb39-137"><a href="#cb39-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-138"><a href="#cb39-138" aria-hidden="true" tabindex="-1"></a><span class="at">-|Function | Description</span></span>
<span id="cb39-139"><a href="#cb39-139" aria-hidden="true" tabindex="-1"></a><span class="at">-|---|---</span></span>
<span id="cb39-140"><a href="#cb39-140" aria-hidden="true" tabindex="-1"></a><span class="at">-|`sum`| Sum of target values</span></span>
<span id="cb39-141"><a href="#cb39-141" aria-hidden="true" tabindex="-1"></a><span class="at">-|`mean`| Mean or average of target values</span></span>
<span id="cb39-142"><a href="#cb39-142" aria-hidden="true" tabindex="-1"></a><span class="at">-|`min`| Minimum value of a target  </span></span>
<span id="cb39-143"><a href="#cb39-143" aria-hidden="true" tabindex="-1"></a><span class="at">-|`max`| Maximum value of a target  </span></span>
<span id="cb39-144"><a href="#cb39-144" aria-hidden="true" tabindex="-1"></a><span class="at">+| Function | Description |</span></span>
<span id="cb39-145"><a href="#cb39-145" aria-hidden="true" tabindex="-1"></a><span class="at">+|:---|:---|</span></span>
<span id="cb39-146"><a href="#cb39-146" aria-hidden="true" tabindex="-1"></a><span class="at">+|`sum`| Sum of target values |</span></span>
<span id="cb39-147"><a href="#cb39-147" aria-hidden="true" tabindex="-1"></a><span class="at">+|`mean`| Mean or average of target values |</span></span>
<span id="cb39-148"><a href="#cb39-148" aria-hidden="true" tabindex="-1"></a><span class="at">+|`min`| Minimum value of a target |</span></span>
<span id="cb39-149"><a href="#cb39-149" aria-hidden="true" tabindex="-1"></a><span class="at">+|`max`| Maximum value of a target |</span></span>
<span id="cb39-150"><a href="#cb39-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-151"><a href="#cb39-151" aria-hidden="true" tabindex="-1"></a><span class="at">-* The target column values are aggregated according to the specified operation. Typically, sum is appropriate for most scenarios.</span></span>
<span id="cb39-152"><a href="#cb39-152" aria-hidden="true" tabindex="-1"></a><span class="at">-* Numerical predictor columns in your data are aggregated by sum, mean, minimum value, and maximum value. As a result, automated ML generates new columns suffixed with the aggregation function name and applies the selected aggregate operation.</span></span>
<span id="cb39-153"><a href="#cb39-153" aria-hidden="true" tabindex="-1"></a><span class="at">-* For categorical predictor columns, the data is aggregated by mode, the most prominent category in the window.</span></span>
<span id="cb39-154"><a href="#cb39-154" aria-hidden="true" tabindex="-1"></a><span class="at">-* Date predictor columns are aggregated by minimum value, maximum value and mode.</span></span>
<span id="cb39-155"><a href="#cb39-155" aria-hidden="true" tabindex="-1"></a><span class="at">+- The target column values are aggregated according to the specified operation. Typically, `sum` is appropriate for most scenarios.</span></span>
<span id="cb39-156"><a href="#cb39-156" aria-hidden="true" tabindex="-1"></a><span class="at">+- Sum, mean, minimum value, and maximum value aggregate numerical predictor columns in your data. As a result, automated ML generates new columns suffixed with the aggregation function name and applies the selected aggregate operation.</span></span>
<span id="cb39-157"><a href="#cb39-157" aria-hidden="true" tabindex="-1"></a><span class="at">+- Mode aggregates the data for categorical predictor columns. It&#39;s the most prominent category in the window.</span></span>
<span id="cb39-158"><a href="#cb39-158" aria-hidden="true" tabindex="-1"></a><span class="at">+- Minimum value, maximum value, and mode aggregate the data predictor columns.</span></span>
<span id="cb39-159"><a href="#cb39-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-160"><a href="#cb39-160" aria-hidden="true" tabindex="-1"></a><span class="fu">The following example sets the frequency to hourly and the aggregation function to summation</span><span class="kw">:</span></span>
<span id="cb39-161"><a href="#cb39-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-162"><a href="#cb39-162" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -578,7 +587,9 @@ forecasting</span><span class="kw">:</span></span>
<span id="cb39-163"><a href="#cb39-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-164"><a href="#cb39-164" aria-hidden="true" tabindex="-1"></a><span class="co">#### Custom cross-validation settings</span></span>
<span id="cb39-165"><a href="#cb39-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-166"><a href="#cb39-166" aria-hidden="true" tabindex="-1"></a><span class="fu">-There are two customizable settings that control cross-validation for forecasting jobs</span><span class="kw">:</span><span class="at"> the number of folds, `n_cross_validations`, and the step size defining the time offset between folds, `cv_step_size`. See [forecasting model selection](./concept-automl-forecasting-sweeping.md</span><span class="co">#model-selection) for more information on the meaning of these parameters. By default, AutoML sets both settings automatically based on characteristics of your data, but advanced users may want to set them manually. For example, suppose you have daily sales data and you want your validation setup to consist of five folds with a seven-day offset between adjacent folds. The following code sample shows how to set these:</span></span>
<span id="cb39-167"><a href="#cb39-167" aria-hidden="true" tabindex="-1"></a><span class="fu">+There are two customizable settings that control cross-validation for forecasting jobs</span><span class="kw">:</span><span class="at"> the number of folds, `n_cross_validations`, and the step size defining the time offset between folds, `cv_step_size`. For more information on the meaning of these parameters, see [forecasting model selection](./concept-automl-forecasting-sweeping.md</span><span class="co">#model-selection).</span></span>
<span id="cb39-168"><a href="#cb39-168" aria-hidden="true" tabindex="-1"></a><span class="at">+</span></span>
<span id="cb39-169"><a href="#cb39-169" aria-hidden="true" tabindex="-1"></a><span class="fu">+By default, AutoML sets both settings automatically based on characteristics of your data. Advanced users might want to set them manually. For example, suppose you have daily sales data and you want your validation setup to consist of five folds with a seven-day offset between adjacent folds. The following code sample shows how to set these values</span><span class="kw">:</span></span>
<span id="cb39-170"><a href="#cb39-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-171"><a href="#cb39-171" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb39-172"><a href="#cb39-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-173"><a href="#cb39-173" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -637,16 +648,16 @@ training</span><span class="kw">:</span></span>
<span id="cb39-174"><a href="#cb39-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-175"><a href="#cb39-175" aria-hidden="true" tabindex="-1"></a><span class="co">### Custom featurization</span></span>
<span id="cb39-176"><a href="#cb39-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-177"><a href="#cb39-177" aria-hidden="true" tabindex="-1"></a><span class="at">-By default, AutoML augments training data with engineered features to increase the accuracy of the models. See [automated feature engineering](./concept-automl-forecasting-methods.md</span><span class="co">#automated-feature-engineering) for more information. Some of the preprocessing steps can be customized using the [featurization](reference-automated-ml-forecasting.md#featurization) configuration of the forecasting job.</span></span>
<span id="cb39-178"><a href="#cb39-178" aria-hidden="true" tabindex="-1"></a><span class="at">+By default, AutoML augments training data with engineered features to increase the accuracy of the models. For more information, see [automated feature engineering](./concept-automl-forecasting-methods.md</span><span class="co">#automated-feature-engineering). Some of the preprocessing steps can be customized using the [featurization](reference-automated-ml-forecasting.md#featurization) configuration of the forecasting job.</span></span>
<span id="cb39-179"><a href="#cb39-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-180"><a href="#cb39-180" aria-hidden="true" tabindex="-1"></a><span class="fu">Supported customizations for forecasting are in the following table</span><span class="kw">:</span></span>
<span id="cb39-181"><a href="#cb39-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-182"><a href="#cb39-182" aria-hidden="true" tabindex="-1"></a><span class="at">-|Customization|Description|Options</span></span>
<span id="cb39-183"><a href="#cb39-183" aria-hidden="true" tabindex="-1"></a><span class="at">-|--|--|---</span></span>
<span id="cb39-184"><a href="#cb39-184" aria-hidden="true" tabindex="-1"></a><span class="at">-|**Column purpose update**|Override the auto-detected feature type for the specified column.|&quot;Categorical&quot;, &quot;DateTime&quot;, &quot;Numeric&quot;</span></span>
<span id="cb39-185"><a href="#cb39-185" aria-hidden="true" tabindex="-1"></a><span class="fu">-|**Transformer parameter update**|Update the parameters for the specified imputer.|`{&quot;strategy&quot;</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;constant&quot;</span><span class="er">,</span><span class="at"> </span><span class="er">&quot;fill_value&quot;:</span><span class="at"> </span><span class="er">&lt;value&gt;}`,</span><span class="at"> </span><span class="er">`{&quot;strategy&quot;:</span><span class="at"> </span><span class="er">&quot;median&quot;}`,</span><span class="at"> </span><span class="er">`{&quot;strategy&quot;:</span><span class="at"> </span><span class="er">&quot;ffill&quot;}`</span></span>
<span id="cb39-186"><a href="#cb39-186" aria-hidden="true" tabindex="-1"></a><span class="at">+| Customization | Description | Options |</span></span>
<span id="cb39-187"><a href="#cb39-187" aria-hidden="true" tabindex="-1"></a><span class="at">+|:--|:--|:---|</span></span>
<span id="cb39-188"><a href="#cb39-188" aria-hidden="true" tabindex="-1"></a><span class="at">+| Column purpose update |Override the autodetected feature type for the specified column. | Categorical, DateTime, Numeric |</span></span>
<span id="cb39-189"><a href="#cb39-189" aria-hidden="true" tabindex="-1"></a><span class="fu">+| Transformer parameter update | Update the parameters for the specified imputer. |`{&quot;strategy&quot;</span><span class="kw">: </span><span class="st">&quot;constant&quot;</span><span class="at">, </span><span class="st">&quot;fill_value&quot;</span><span class="at">: &lt;value&gt;}`, `</span><span class="kw">{</span><span class="fu">&quot;strategy&quot;</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;median&quot;</span><span class="kw">}</span><span class="at">`, `</span><span class="kw">{</span><span class="fu">&quot;strategy&quot;</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;ffill&quot;</span><span class="kw">}</span><span class="at">`</span><span class="ch">|</span></span>
<span id="cb39-190"><a href="#cb39-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-191"><a href="#cb39-191" aria-hidden="true" tabindex="-1"></a><span class="fu">-For example, suppose you have a retail demand scenario where the data includes prices, an &quot;on sale&quot; flag, and a product type. The following sample shows how you can set customized types and imputers for these features</span><span class="kw">:</span></span>
<span id="cb39-192"><a href="#cb39-192" aria-hidden="true" tabindex="-1"></a><span class="fu">+For example, suppose you have a retail demand scenario where the data includes prices, an `on sale` flag, and a product type. The following sample shows how you can set customized types and imputers for these features</span><span class="kw">:</span></span>
<span id="cb39-193"><a href="#cb39-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-194"><a href="#cb39-194" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb39-195"><a href="#cb39-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-196"><a href="#cb39-196" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -721,9 +732,9 @@ training</span><span class="kw">:</span></span>
<span id="cb39-197"><a href="#cb39-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-198"><a href="#cb39-198" aria-hidden="true" tabindex="-1"></a><span class="at">If you&#39;re using the Azure Machine Learning studio for your experiment, see [how to customize featurization in the studio](how-to-use-automated-ml-for-ml-models.md</span><span class="co">#customize-featurization).</span></span>
<span id="cb39-199"><a href="#cb39-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-200"><a href="#cb39-200" aria-hidden="true" tabindex="-1"></a><span class="at">-</span><span class="co">## Submitting a forecasting job </span></span>
<span id="cb39-201"><a href="#cb39-201" aria-hidden="true" tabindex="-1"></a><span class="at">+</span><span class="co">## Submitting a forecasting job</span></span>
<span id="cb39-202"><a href="#cb39-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-203"><a href="#cb39-203" aria-hidden="true" tabindex="-1"></a><span class="fu">-After all settings are configured, you launch the forecasting job as follows</span><span class="kw">:</span></span>
<span id="cb39-204"><a href="#cb39-204" aria-hidden="true" tabindex="-1"></a><span class="fu">+After all settings are configured, you run the forecasting job as follows</span><span class="kw">:</span></span>
<span id="cb39-205"><a href="#cb39-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-206"><a href="#cb39-206" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb39-207"><a href="#cb39-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-208"><a href="#cb39-208" aria-hidden="true" tabindex="-1"></a><span class="at">@@ -741,31 +752,33 @@ returned_job.services[&quot;Studio&quot;].endpoint</span></span>
<span id="cb39-209"><a href="#cb39-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-210"><a href="#cb39-210" aria-hidden="true" tabindex="-1"></a><span class="co"># [Azure CLI](#tab/cli)</span></span>
<span id="cb39-211"><a href="#cb39-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-212"><a href="#cb39-212" aria-hidden="true" tabindex="-1"></a><span class="at">-In following CLI command, we assume the job YAML configuration is in the current working directory at the path, `./automl-forecasting-job.yml`. If you run the command from a different directory, you will need to change the path accordingly.</span></span>
<span id="cb39-213"><a href="#cb39-213" aria-hidden="true" tabindex="-1"></a><span class="at">+In following CLI command, the job YAML configuration is in the current working directory at the path, *./automl-forecasting-job.yml*. If you run the command from a different directory, you need to change the path accordingly.</span></span>
<span id="cb39-214"><a href="#cb39-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-215"><a href="#cb39-215" aria-hidden="true" tabindex="-1"></a><span class="at">```azurecli</span></span>
<span id="cb39-216"><a href="#cb39-216" aria-hidden="true" tabindex="-1"></a><span class="at">run_id=$(az ml job create --file automl-forecasting-job.yml)</span></span></code></pre></div>
<p>-You can use the stored run ID to return information about the job.
The <code>--web</code> parameter opens the Azure Machine Learning studio
web UI where you can drill into details on the job:<br />
+You can use the stored run ID to return information about the job. The
<code>--web</code> parameter opens the Azure Machine Learning studio web
UI where you can see details on the job:</p>
<pre class="azurecli"><code>az ml job show -n $run_id --web</code></pre>
<hr />
<p>-Once the job is submitted, AutoML will provision compute resources,
apply featurization and other preparation steps to the input data, then
begin sweeping over forecasting models. For more details, see our
articles on <a
href="./concept-automl-forecasting-methods.md">forecasting
methodology</a> and <a
href="concept-automl-forecasting-sweeping.md">model search</a>.<br />
+After the job is submitted, AutoML provisions compute resources,
applies featurization and other preparation steps to the input data, and
begins sweeping over forecasting models. For more information, see <a
href="./concept-automl-forecasting-methods.md">forecasting
methodology</a> and <a
href="concept-automl-forecasting-sweeping.md">model search</a>.</p>
<p>-## Orchestrating training, inference, and evaluation with components
and pipelines<br />
+<a name="orchestrating-training-inference-and-evaluation-with-components-and-pipelines"></a><br />
+<br />
+## Orchestrate training, inference, and evaluation with components and
pipelines</p>
<p>[!INCLUDE <a
href="includes/machine-learning-preview-generic-disclaimer.md">preview
v2</a>]</p>
<p>-Your ML workflow likely requires more than just training. Inference,
or retrieving model predictions on newer data, and evaluation of model
accuracy on a test set with known target values are other common tasks
that you can orchestrate in AzureML along with training jobs. To support
inference and evaluation tasks, AzureML provides <a
href="concept-component.md">components</a>, which are self-contained
pieces of code that do one step in an AzureML <a
href="concept-ml-pipelines.md">pipeline</a>.<br />
+Your ML workflow likely requires more than just training. Inference, or
retrieving model predictions on newer data, and evaluation of model
accuracy on a test set with known target values are other common tasks
that you can orchestrate in Azure Machine Learning along with training
jobs. To support inference and evaluation tasks, Azure Machine Learning
provides <a href="concept-component.md">components</a>, which are
self-contained pieces of code that do one step in an Azure Machine
Learning <a href="concept-ml-pipelines.md">pipeline</a>.</p>
<p># <a href="#tab/python">Python SDK</a></p>
<p>-In the following example, we retrieve component code from a client
registry:<br />
+In the following example, retrieve component code from a client
registry:</p>
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> azure.ai.ml <span class="im">import</span> MLClient</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="op">@@</span> <span class="op">-</span><span class="dv">805</span>,<span class="dv">7</span> <span class="op">+</span><span class="dv">818</span>,<span class="dv">7</span> <span class="op">@@</span> compute_metrics_component <span class="op">=</span> ml_client_metrics_registry.components.get(</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>-Next, we define a factory function that creates pipelines
orchestrating training, inference, and metric computation. See the <a
href="#configure-experiment">training configuration</a> section for more
details on training settings.<br />
+Next, define a factory function that creates pipelines orchestrating
training, inference, and metric computation. For more information, see
<a href="#configure-experiment">Configure experiment</a>.</p>
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> azure.ai.ml <span class="im">import</span> automl</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="op">@@</span> <span class="op">-</span><span class="dv">873</span>,<span class="dv">7</span> <span class="op">+</span><span class="dv">886</span>,<span class="dv">7</span> <span class="op">@@</span> <span class="kw">def</span> forecasting_train_and_evaluate_factory(</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    }</span></code></pre></div>
<p>-Now, we define train and test data inputs assuming that they’re
contained in local folders, <code>./train_data</code> and
<code>./test_data</code>:<br />
+Define train and test data inputs contained in local folders:
<em>./train_data</em> and <em>./test_data</em>.</p>
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>my_train_data_input <span class="op">=</span> Input(</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="op">@@</span> <span class="op">-</span><span class="dv">887</span>,<span class="dv">7</span> <span class="op">+</span><span class="dv">900</span>,<span class="dv">7</span> <span class="op">@@</span> my_test_data_input <span class="op">=</span> Input(</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>-Finally, we construct the pipeline, set its default compute and
submit the job:<br />
+Finally, construct the pipeline, set its default compute, and submit
the job:</p>
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>pipeline_job <span class="op">=</span> forecasting_train_and_evaluate_factory(</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="op">@@</span> <span class="op">-</span><span class="dv">995</span>,<span class="dv">17</span> <span class="op">+</span><span class="dv">1008</span>,<span class="dv">17</span> <span class="op">@@</span> jobs:</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>            evaluation_result: ${{parent.outputs.metrics_result}}</span></code></pre></div>
<p>-Note that AutoML requires training data in <a
href="#training-and-validation-data">MLTable format</a> for
AutoML.<br />
+AutoML requires training data in <a
href="#training-and-validation-data">MLTable format</a> for AutoML.</p>
<p>-Now, you launch the pipeline run using the following command,
assuming the pipeline configuration is at the path
<code>./automl-forecasting-pipeline.yml</code>:<br />
+Launch the pipeline run using the following command. The pipeline
configuration is at the path
<em>./automl-forecasting-pipeline.yml</em>:</p>
<pre class="azurecli"><code>run_id=$(az ml job create --file automl-forecasting-pipeline.yml -w &lt;Workspace&gt; -g &lt;Resource Group&gt; --subscription &lt;Subscription&gt;)</code></pre>
<hr />
<p>-Once submitted, the pipeline runs AutoML training, rolling
evaluation inference, and metric calculation in sequence. You can
monitor and inspect the run in the studio UI. When the run is finished,
the rolling forecasts and the evaluation metrics can be downloaded to
the local working directory:<br />
+Once submitted, the pipeline runs AutoML training, rolling evaluation
inference, and metric calculation in sequence. You can monitor and
inspect the run in the studio UI. When the run is finished, you can
download the rolling forecasts and the evaluation metrics to the local
working directory:</p>
<p># <a href="#tab/python">Python SDK</a></p>
<p>@@ -1026,27 +1039,29 @@ az ml job download –name $run_id
–download-path . –output-name rolling_fcst_r</p>
<hr />
<p>-Then, you can find the metrics results in
<code>./named-outputs/metrics_results/evaluationResult/metrics.json</code>
and the forecasts, in JSON lines format, in
<code>./named-outputs/rolling_fcst_result/inference_output_file</code>.<br />
+You can find the metrics results in
<em>./named-outputs/metrics_results/evaluationResult/metrics.json</em>
and the forecasts, in JSON lines format, in
<em>./named-outputs/rolling_fcst_result/inference_output_file</em>.</p>
<h2
id="for-more-details-on-rolling-evaluation-see-our-forecasting-model-evaluation-article.">-For
more details on rolling evaluation, see our <a
href="concept-automl-forecasting-evaluation.md">forecasting model
evaluation article</a>.</h2>
<p>-## Forecasting at scale: many models<br />
+For more information on rolling evaluation, see <a
href="concept-automl-forecasting-evaluation.md">Inference and evaluation
of forecasting models</a>.</p>
<p>-[!INCLUDE <a
href="includes/machine-learning-preview-generic-disclaimer.md">preview
v2</a>]<br />
+<a name="forecasting-at-scale-many-models"></a></p>
<p>-The many models components in AutoML enable you to train and manage
millions of models in parallel. For more information on many models
concepts, see the <a
href="concept-automl-forecasting-at-scale.md#many-models">many models
article section</a>.<br />
+## Forecast at scale: many models</p>
<p>+[!INCLUDE <a
href="includes/machine-learning-preview-generic-disclaimer.md">preview
v2</a>]<br />
+<br />
+The many models components in AutoML enable you to train and manage
millions of models in parallel. For more information on many models
concepts, see <a
href="concept-automl-forecasting-at-scale.md#many-models">Many
models</a>.</p>
<p>### Many models training configuration</p>
<p>-The many models training component accepts a YAML format
configuration file of AutoML training settings. The component applies
these settings to each AutoML instance it launches. This YAML file has
the same specification as the <a
href="reference-automated-ml-forecasting.md">Forecasting Job</a> plus
additional parameters <code>partition_column_names</code> and
<code>allow_multi_partitions</code>.<br />
+The many models training component accepts a YAML format configuration
file of AutoML training settings. The component applies these settings
to each AutoML instance it launches. This YAML file has the same
specification as the <a
href="reference-automated-ml-forecasting.md">Forecasting Job</a> plus
parameters <code>partition_column_names</code> and
<code>allow_multi_partitions</code>.</p>
<table>
<thead>
<tr>
<th>-Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>-</td>
<td><strong>partition_column_names</strong></td>
</tr>
<tr>
<td>-</td>
<td><strong>allow_multi_partitions</strong></td>
</tr>
<tr>
<td>+</td>
<td>Parameter</td>
</tr>
<tr>
<td>+</td>
<td>:–</td>
</tr>
<tr>
<td>+</td>
<td>partition_column_names</td>
</tr>
<tr>
<td>+</td>
<td>allow_multi_partitions</td>
</tr>
</tbody>
</table>
<p>The following sample provides a configuration template:<br />
+<br />
<code>yml  $schema: https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLJob.schema.json  type: automl @@ -1078,21 +1093,20 @@ partition_column_names: ["state", "store"]  allow_multi_partitions: false</code></p>
<h2
id="in-subsequent-examples-we-assume-that-the-configuration-is-stored-at-the-path-.automl_settings_mm.yml.">-In
subsequent examples, we assume that the configuration is stored at the
path, <code>./automl_settings_mm.yml</code>.</h2>
<p>+In subsequent examples, the configuration is stored at the path,
<em>./automl_settings_mm.yml</em>`.</p>
<p>### Many models pipeline</p>
<p>-Next, we define a factory function that creates pipelines for
orchestration of many models training, inference, and metric
computation. The parameters of this factory function are detailed in the
following table:<br />
+Next, define a factory function that creates pipelines for
orchestration of many models training, inference, and metric
computation. The parameters of this factory function are detailed in the
following table:</p>
<table>
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr>
<th>-Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>-<strong>max_nodes</strong></td>
<td>Number of compute nodes to use in the training job</td>
</tr>
<tr>
<td>-<strong>max_concurrency_per_node</strong></td>
<td>Number of AutoML processes to run on each node. Hence, the total
concurrency of a many models jobs is
<code>max_nodes * max_concurrency_per_node</code>.</td>
</tr>
<tr>
<td>-<strong>parallel_step_timeout_in_seconds</strong></td>
<td>Many models component timeout given in number of seconds.</td>
</tr>
<tr>
<td>-<strong>retrain_failed_models</strong></td>
<td>Flag to enable re-training for failed models. This is useful if
you’ve done previous many models runs that resulted in failed AutoML
jobs on some data partitions. When this flag is enabled, many models
will only launch training jobs for previously failed partitions.</td>
</tr>
<tr>
<td>-<strong>forecast_mode</strong></td>
<td>Inference mode for model evaluation. Valid values are
<code>"recursive"</code> and “<code>rolling</code>”. See the <a
href="concept-automl-forecasting-evaluation.md">model evaluation
article</a> for more information.</td>
</tr>
<tr>
<td>-<strong>forecast_step</strong></td>
<td>Step size for rolling forecast. See the <a
href="concept-automl-forecasting-evaluation.md">model evaluation
article</a> for more information.</td>
</tr>
<tr>
<td>+</td>
<td>Parameter</td>
</tr>
<tr>
<td>+</td>
<td>:–</td>
</tr>
<tr>
<td>+</td>
<td>max_nodes</td>
</tr>
<tr>
<td>+</td>
<td>max_concurrency_per_node</td>
</tr>
<tr>
<td>+</td>
<td>parallel_step_timeout_in_seconds</td>
</tr>
<tr>
<td>+</td>
<td>retrain_failed_models</td>
</tr>
<tr>
<td>+</td>
<td>forecast_mode</td>
</tr>
<tr>
<td>+</td>
<td>forecast_step</td>
</tr>
</tbody>
</table>
<p>The following sample illustrates a factory method for constructing
many models training and model evaluation pipelines:</p>
<p>@@ -1178,7 +1192,7 @@ def many_models_train_evaluate_factory(<br />
}<br />
```</p>
<p>-Now, we construct the pipeline via the factory function, assuming
the training and test data are in local folders,
<code>./data/train</code> and <code>./data/test</code>, respectively.
Finally, we set the default compute and submit the job as in the
following sample:<br />
+Construct the pipeline via the factory function. The training and test
data are in local folders <em>./data/train</em> and
<em>./data/test</em>, respectively. Finally, set the default compute and
submit the job as in the following sample:</p>
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>pipeline_job <span class="op">=</span> many_models_train_evaluate_factory(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="op">@@</span> <span class="op">-</span><span class="dv">1293</span>,<span class="dv">37</span> <span class="op">+</span><span class="dv">1307</span>,<span class="dv">40</span> <span class="op">@@</span> jobs:</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>            evaluation_result: ${{parent.outputs.metrics_result}}</span></code></pre></div>
<p>-You launch the pipeline job with the following command, assuming the
many models pipeline configuration is at the path
<code>./automl-mm-forecasting-pipeline.yml</code>:<br />
+You launch the pipeline job with the following command. The many models
pipeline configuration is at the path
<em>./automl-mm-forecasting-pipeline.yml</em>:</p>
<pre class="azurecli"><code>az ml job create --file automl-mm-forecasting-pipeline.yml -w &lt;Workspace&gt; -g &lt;Resource Group&gt; --subscription &lt;Subscription&gt;</code></pre>
<hr />
<p>-After the job finishes, the evaluation metrics can be downloaded
locally using the same procedure as in the <a
href="#orchestrating-training-inference-and-evaluation-with-components-and-pipelines">single
training run pipeline</a>.<br />
+After the job finishes, the evaluation metrics can be downloaded
locally using the same procedure as in the <a
href="#orchestrating-training-inference-and-evaluation-with-components-and-pipelines">single
training run pipeline</a>.</p>
<p>-Also see the <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/pipelines/1k_demand_forecast_pipeline/aml-demand-forecast-mm-pipeline/aml-demand-forecast-mm-pipeline.ipynb">demand
forecasting with many models notebook</a> for a more detailed
example.<br />
+For a more detailed example, see the <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/pipelines/1k_demand_forecast_pipeline/aml-demand-forecast-mm-pipeline/aml-demand-forecast-mm-pipeline.ipynb">demand
forecasting with many models notebook</a> for a more detailed
example.</p>
<blockquote>
<p>[!NOTE]<br />
The many models training and inference components conditionally
partition your data according to the <code>partition_column_names</code>
setting so that each partition is in its own file. This process can be
very slow or fail when data is very large. In this case, we recommend
partitioning your data manually before running many models training or
inference.</p>
</blockquote>
<p>-## Forecasting at scale: hierarchical time series<br />
+<a name="forecasting-at-scale-hierarchical-time-series"></a><br />
+<br />
+## Forecast at scale: hierarchical time series</p>
<p>[!INCLUDE <a
href="includes/machine-learning-preview-generic-disclaimer.md">preview
v2</a>]</p>
<p>The hierarchical time series (HTS) components in AutoML enable you to
train a large number of models on data with hierarchical structure. For
more information, see the <a
href="concept-automl-forecasting-at-scale.md#hierarchical-time-series-forecasting">HTS
article section</a>.</p>
<p>### HTS training configuration</p>
<p>-The HTS training component accepts a YAML format configuration file
of AutoML training settings. The component applies these settings to
each AutoML instance it launches. This YAML file has the same
specification as the <a
href="reference-automated-ml-forecasting.md#">Forecasting Job</a> plus
additional parameters related to the hierarchy information:<br />
+The HTS training component accepts a YAML format configuration file of
AutoML training settings. The component applies these settings to each
AutoML instance it launches. This YAML file has the same specification
as the <a href="reference-automated-ml-forecasting.md">Forecasting
Job</a> plus other parameters related to the hierarchy information:</p>
<table>
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr>
<th>-Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>-</td>
<td><strong>hierarchy_column_names</strong></td>
</tr>
<tr>
<td>-<strong>hierarchy_training_level</strong></td>
<td>The hierarchy level to use for forecast model training.</td>
</tr>
<tr>
<td>+</td>
<td>Parameter</td>
</tr>
<tr>
<td>+</td>
<td>:–</td>
</tr>
<tr>
<td>+</td>
<td>hierarchy_column_names</td>
</tr>
<tr>
<td>+</td>
<td>hierarchy_training_level</td>
</tr>
</tbody>
</table>
<p>The following shows a sample configuration:<br />
+<br />
<code>yml  $schema: https://azuremlsdk2.blob.core.windows.net/preview/0.0.1/autoMLJob.schema.json  type: automl @@ -1356,21 +1373,21 @@ hierarchy_column_names: ["state", "store", "SKU"]  hierarchy_training_level: "store"</code></p>
<p>-In subsequent examples, we assume that the configuration is stored
at the path, <code>./automl_settings_hts.yml</code>.<br />
+In subsequent examples, the configuration is stored at the path,
<em>./automl_settings_hts.yml</em>.</p>
<p>### HTS pipeline</p>
<p>-Next, we define a factory function that creates pipelines for
orchestration of HTS training, inference, and metric computation. The
parameters of this factory function are detailed in the following
table:<br />
+Next, define a factory function that creates pipelines for
orchestration of HTS training, inference, and metric computation. The
parameters of this factory function are detailed in the following
table:</p>
<table>
<colgroup>
<col style="width: 60%" />
<col style="width: 40%" />
</colgroup>
<thead>
<tr>
<th>-Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>-<strong>forecast_level</strong></td>
<td>The level of the hierarchy to retrieve forecasts for</td>
</tr>
<tr>
<td>-<strong>allocation_method</strong></td>
<td>Allocation method to use when forecasts are disaggregated. Valid
values are <code>"proportions_of_historical_average"</code> and
<code>"average_historical_proportions"</code>.</td>
</tr>
<tr>
<td>-<strong>max_nodes</strong></td>
<td>Number of compute nodes to use in the training job</td>
</tr>
<tr>
<td>-<strong>max_concurrency_per_node</strong></td>
<td>Number of AutoML processes to run on each node. Hence, the total
concurrency of an HTS job is
<code>max_nodes * max_concurrency_per_node</code>.</td>
</tr>
<tr>
<td>-<strong>parallel_step_timeout_in_seconds</strong></td>
<td>Many models component timeout given in number of seconds.</td>
</tr>
<tr>
<td>-<strong>forecast_mode</strong></td>
<td>Inference mode for model evaluation. Valid values are
<code>"recursive"</code> and “<code>rolling</code>”. See the <a
href="concept-automl-forecasting-evaluation.md">model evaluation
article</a> for more information.</td>
</tr>
<tr>
<td>-<strong>forecast_step</strong></td>
<td>Step size for rolling forecast. See the <a
href="concept-automl-forecasting-evaluation.md">model evaluation
article</a> for more information.</td>
</tr>
<tr>
<td>+</td>
<td>Parameter</td>
</tr>
<tr>
<td>+</td>
<td>:–</td>
</tr>
<tr>
<td>+</td>
<td>forecast_level</td>
</tr>
<tr>
<td>+</td>
<td>allocation_method</td>
</tr>
<tr>
<td>+</td>
<td>max_nodes</td>
</tr>
<tr>
<td>+</td>
<td>max_concurrency_per_node</td>
</tr>
<tr>
<td>+</td>
<td>parallel_step_timeout_in_seconds</td>
</tr>
<tr>
<td>+</td>
<td>forecast_mode</td>
</tr>
<tr>
<td>+</td>
<td>forecast_step</td>
</tr>
</tbody>
</table>
<p># <a href="#tab/python">Python SDK</a></p>
<p>@@ -1451,7 +1468,7 @@ def hts_train_evaluate_factory(<br />
}<br />
```</p>
<p>-Now, we construct the pipeline via the factory function, assuming
the training and test data are in local folders,
<code>./data/train</code> and <code>./data/test</code>, respectively.
Finally, we set the default compute and submit the job as in the
following sample:<br />
+Construct the pipeline by using the factory function. The training and
test data are in local folders <em>./data/train</em> and
<em>./data/test</em>, respectively. Finally, set the default compute and
submit the job as in the following sample:</p>
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>pipeline_job <span class="op">=</span> hts_train_evaluate_factory(</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="op">@@</span> <span class="op">-</span><span class="dv">1568</span>,<span class="dv">40</span> <span class="op">+</span><span class="dv">1585</span>,<span class="dv">40</span> <span class="op">@@</span> jobs:</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>            evaluation_result: ${{parent.outputs.metrics_result}}</span></code></pre></div>
<p>-You launch the pipeline job with the following command, assuming the
many models pipeline configuration is at the path
<code>./automl-hts-forecasting-pipeline.yml</code>:<br />
+You launch the pipeline job with the following command. The many models
pipeline configuration is at the path
<em>./automl-hts-forecasting-pipeline.yml</em>:</p>
<pre class="azurecli"><code>az ml job create --file automl-hts-forecasting-pipeline.yml -w &lt;Workspace&gt; -g &lt;Resource Group&gt; --subscription &lt;Subscription&gt;</code></pre>
<hr />
<p>-After the job finishes, the evaluation metrics can be downloaded
locally using the same procedure as in the <a
href="#orchestrating-training-inference-and-evaluation-with-components-and-pipelines">single
training run pipeline</a>.<br />
+After the job finishes, the evaluation metrics can be downloaded
locally using the same procedure as in the <a
href="#orchestrating-training-inference-and-evaluation-with-components-and-pipelines">single
training run pipeline</a>.</p>
<p>-Also see the <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/pipelines/1k_demand_forecast_pipeline/aml-demand-forecast-hts-pipeline/aml-demand-forecast-hts.ipynb">demand
forecasting with hierarchical time series notebook</a> for a more
detailed example.<br />
+For a more detailed example, see the <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/pipelines/1k_demand_forecast_pipeline/aml-demand-forecast-hts-pipeline/aml-demand-forecast-hts.ipynb">demand
forecasting with hierarchical time series notebook</a>.</p>
<blockquote>
<p>[!NOTE]<br />
-&gt; The HTS training and inference components conditionally partition
your data according to the <code>hierarchy_column_names</code> setting
so that each partition is in its own file. This process can be very slow
or fail when data is very large. In this case, we recommend partitioning
your data manually before running HTS training or inference.<br />
+&gt; The HTS training and inference components conditionally partition
your data according to the <code>hierarchy_column_names</code> setting
so that each partition is in its own file. This process can be very slow
or fail when data is very large. In this case, we recommend partitioning
your data manually before running HTS training or inference.</p>
</blockquote>
<p>-## Forecasting at scale: distributed DNN training<br />
+## Forecast at scale: distributed DNN training</p>
<p>-* To learn how distributed training works for forecasting tasks, see
our <a
href="concept-automl-forecasting-at-scale.md#distributed-dnn-training-preview">forecasting
at scale article</a>.<br />
-* See our <a
href="how-to-configure-auto-train.md#automl-at-scale-distributed-training">setup
distributed training for tabular data</a> article section for code
samples.<br />
+- To learn how distributed training works for forecasting tasks, see <a
href="concept-automl-forecasting-at-scale.md#distributed-dnn-training-preview">Distributed
DNN training</a>.<br />
+- To see code samples, see <a
href="how-to-configure-auto-train.md#automl-at-scale-distributed-training">AutoML
at scale: distributed training</a>.</p>
<p>## Example notebooks</p>
<p>-See the <a
href="https://github.com/Azure/azureml-examples/tree/main/sdk/python/jobs/automl-standalone-jobs">forecasting
sample notebooks</a> for detailed code examples of advanced forecasting
configuration including:<br />
+For detailed code examples of advanced forecasting configuration, see
the <a
href="https://github.com/Azure/azureml-examples/tree/main/sdk/python/jobs/automl-standalone-jobs">forecasting
sample notebooks</a>:</p>
<p>-* <a
href="https://github.com/Azure/azureml-examples/tree/main/sdk/python/jobs/pipelines/1k_demand_forecast_pipeline">Demand
forecasting pipeline examples</a><br />
-* <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-github-dau/auto-ml-forecasting-github-dau.ipynb">Deep
learning models</a><br />
-* <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-task-bike-share/auto-ml-forecasting-bike-share.ipynb">Holiday
detection and featurization</a><br />
-* <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-task-energy-demand/automl-forecasting-task-energy-demand-advanced.ipynb">Manual
configuration for lags and rolling window aggregation features</a><br />
+- <a
href="https://github.com/Azure/azureml-examples/tree/main/sdk/python/jobs/pipelines/1k_demand_forecast_pipeline">Demand
forecasting pipeline examples</a><br />
+- <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-github-dau/auto-ml-forecasting-github-dau.ipynb">Deep
learning models</a><br />
+- <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-task-bike-share/auto-ml-forecasting-bike-share.ipynb">Holiday
detection and featurization</a><br />
+- <a
href="https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs/automl-forecasting-task-energy-demand/automl-forecasting-task-energy-demand-advanced.ipynb">Manual
configuration for lags and rolling window aggregation features</a></p>
<p>-## Next steps<br />
+## Related content</p>
<p>-* Learn more about <a href="how-to-deploy-automl-endpoint.md">How to
deploy an AutoML model to an online endpoint</a>.<br />
-* Learn about <a
href="./v1/how-to-machine-learning-interpretability-automl.md">Interpretability:
model explanations in automated machine learning (preview)</a>.<br />
-* Learn about <a href="./concept-automl-forecasting-methods.md">how
AutoML builds forecasting models</a>.<br />
-* Learn about <a
href="./concept-automl-forecasting-at-scale.md">forecasting at
scale</a>.<br />
-* Learn how to <a
href="./how-to-automl-forecasting-faq.md#what-modeling-configuration-should-i-use">configure
AutoML for various forecasting scenarios</a>.<br />
-* Learn about <a
href="concept-automl-forecasting-evaluation.md">inference and evaluation
of forecasting models</a>.<br />
+- <a href="how-to-deploy-automl-endpoint.md">How to deploy an AutoML
model to an online endpoint</a><br />
+- <a
href="./v1/how-to-machine-learning-interpretability-automl.md">Interpretability:
model explanations in automated machine learning (preview)</a><br />
+- <a href="./concept-automl-forecasting-methods.md">Overview of
forecasting methods in AutoML</a><br />
+- <a href="./concept-automl-forecasting-at-scale.md">Forecasting at
scale: many models and distributed training</a><br />
+- <a
href="./how-to-automl-forecasting-faq.md#what-modeling-configuration-should-i-use">What
modeling configuration should I use?</a><br />
+- <a href="concept-automl-forecasting-evaluation.md">Inference and
evaluation of forecasting models (preview)</a></p>
<pre><code>&lt;/details&gt;

### Summary

```json
{
    &quot;filename&quot;: &quot;articles/machine-learning/how-to-auto-train-forecast.md&quot;,
    &quot;modification_type&quot;: &quot;minor update&quot;,
    &quot;modification_title&quot;: &quot;時系列予測のためのAutoML設定に関するガイドの更新&quot;
}</code></pre>
<h3 id="explanation-17">Explanation</h3>
<p>この変更は、<code>how-to-auto-train-forecast.md</code>ファイルに対する修正を含み、Azure
Machine
Learningでの時系列予測のためのAutoML設定に関するガイドを更新しています。主な変更点は以下の通りです：</p>
<ol class="incremental" type="1">
<li><strong>メタデータの更新</strong>：
<ul class="incremental">
<li>記事の説明文が追加され、AutoML機能を活用して時系列予測モデルをトレーニングする方法を学ぶことが明示されています。</li>
<li>日付が2023年8月1日から2024年9月9日に変更され、内容が最新に保たれています。</li>
</ul></li>
<li><strong>内容の整理と明確化</strong>：
<ul class="incremental">
<li>AutoMLの定義や利用方法についての説明が整理され、時系列予測を行うための具体的な手順がリスト形式で提供されています。</li>
<li>新たに、AutoMLが標準的な機械学習モデルや一般的な時系列モデルを使用して予測を行うことが明示され、その背景として履歴情報や特徴データの重要性が説明されています。</li>
</ul></li>
<li><strong>手順の詳細化</strong>：
<ul class="incremental">
<li>トレーニングデータやバリデーションデータに関する要件が明確になり、データ形式についての具体的な指示が提供されています。特に、MLTableオブジェクトとしてのデータの使用が強調されています。</li>
<li>ハイパーパラメータやモデルの評価に関する設定方法が詳述され、ユーザーが適切にAutoMLのトレーニングを行うための情報が充実しています。</li>
</ul></li>
<li><strong>関連リソースの追加</strong>：
<ul class="incremental">
<li>他の関連ドキュメントへのリンクが追加され、読者はさらに深い知識を得ることができるようになっています。また、具体的なコード例や、異なるモデル構成の使用に関する情報も含まれています。</li>
</ul></li>
</ol>
<p>このように、全体的に変更はドキュメントの明瞭性と使いやすさを向上させ、ユーザーがAzure
Machine
Learningを使用して効果的に時系列予測モデルを構築できるように設計されています。</p>
<h2 id="item-5aa1c8">articles/machine-learning/how-to-connection.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb51"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -539,6 +539,126 @@ wps_connection = WorkspaceConnection(</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a> ml_client.connections.create_or_update(workspace_connection=wps_connection)</span></code></pre></div>
<p>+—<br />
+<br />
+### Generic Container Registry<br />
+<br />
+Using the GenericContainerRegistry workspace connection, you can
specify an external registry, such as Nexus or Artifactory, for image
builds. Environment images will be pushed and served from the specified
registry, and the previous cache will be ignored.<br />
+<br />
+# <a href="#tab/cli">Azure CLI</a><br />
+<br />
+Create a connection using the following YAML files. Be sure to update
the appropriate values:<br />
+<code>yml +#myenv.yml +$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json  +name: docker-image-plus-conda-example  +image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04 +type: python_feed +conda_file: conda_dep.yml +description: Environment created from a Docker image plus Conda environment +</code><br />
+<br />
+<code>yml +#conda_dep.yml +name: project_environment +dependencies: +  - python=3.10 +  - pip: +    - azureml-defaults +channels: +  - anaconda +  - conda-forge +</code><br />
+<br />
+<code>yml +#connection.yml +name: ws_conn_generic_container_registry +type: container_registry +target: https://test-registry.com +credentials: +  type: username_password +  username: contoso +  password: pass +</code><br />
+<br />
+<code>yml +#hello_world_job.yml +$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json +command: echo "hello world" +environment: azureml:&lt;env name&gt;@latest +</code><br />
+<br />
+Create connection from YAML file with your credentials:<br />
+<br />
+<code>azurecli +az ml connection create --file connection.yaml --credentials username=&lt;username&gt; password=&lt;password&gt; --resource-group my-resource-group --workspace-name my-workspace +</code><br />
+<br />
+Create environment<br />
+<br />
+<code>azurecli +az ml environment create --name my-env --version 1 --file my_env.yml  --conda-file conda_dep.yml --image mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04 --resource-group my-resource-group --workspace-name my-workspace +</code><br />
+<br />
+You can verify that the environment was successfully created<br />
+<br />
+<code>azurecli +az ml environment show --name my-env --version 1 --resource-group my-resource-group --workspace-name my-workspace +</code><br />
+<br />
+# <a href="#tab/python">Python SDK</a><br />
+<br />
+The following example creates an Azure Container Registry connection. A
managed identity authenticates this connection:<br />
+<br />
+<code>python +import os +from azure.ai.ml import MLClient +from azure.identity import DefaultAzureCredential +from azure.ai.ml.entities import Environment +from azure.ai.ml.entities import WorkspaceConnection +from azure.ai.ml.entities import UsernamePasswordConfiguration +from azureml.core.conda_dependencies import CondaDependencies +from azure.ai.ml import command + +# Enter details of AML workspace +subscription_id = "&lt;SUBSCRIPTION_ID&gt;" +resource_group = "&lt;RESOURCE_GROUP&gt;" +workspace = "&lt;AML_WORKSPACE_NAME&gt;" + +ml_client = MLClient( DefaultAzureCredential(), subscription_id, resource_group, workspace) +# Fetching secrets from env var to secure access, these secrets can be set outside or source code +registry_username = os.environ["REGISTRY_USERNAME"] +registry_password = os.environ["REGISTRY_PASSWORD"] +credentials = UsernamePasswordConfiguration(username= registry_username, password= registry_password) + +# Create GenericContainerRegistry workspace connection for a generic registry +ws_connection = WorkspaceConnection(name="&lt;name&gt;", target="&lt;target&gt;", type="GenericContainerRegistry", credentials=credentials) +ml_client.connections.create_or_update(ws_connection) + +# Create an environment +env_docker_conda = Environment(image="&lt;base image&gt;", conda_file="&lt;yml file&gt;", name="docker-image-plus-conda-example", description="Environment created from a Docker image plus Conda environment.") +ml_client.environments.create_or_updat(env_docker_conda)  + +job = command(command="echo 'hello world'", environment=env_docker_conda,display_name="v2-job-example") +returned_job = ml_client.create_or_update(job) +</code><br />
+<br />
+# <a href="#tab/azure-studio">Studio</a><br />
+<br />
+1. Navigate to the <a href="https://ml.azure.com/">Azure Machine
Learning studio</a>.<br />
+<br />
+1. Under <strong>Manage</strong> in the left navigation, select
<strong>Connections</strong> and then select
<strong>Create</strong>.<br />
+<br />
+ :::image type=“content”
source=“media/how-to-connection/how-to-manage-connections-create.png”
lightbox=“media/how-to-connection/create-new-data-connection.png”
alt-text=“Screenshot showing the start of creating a new connection in
Azure Machine Learning studio UI.”:::<br />
+<br />
+1. Under <strong>Other resources types</strong>, select **Generic
Container Registry*<br />
+ :::image type=“content”
source=“media/how-to-connection/how-to-connect-generic-container-registry.png”
lightbox=“media/how-to-connection/create-new-data-connection.png”
alt-text=“Screenshot highlighting the option to connect to a generic
container registry in Azure Machine Learning studio UI.”:::<br />
+<br />
+1. Input the required information, and then select <strong>Add
connection</strong><br />
+ :::image type=“content”
source=“media/how-to-connection/how-to-connect-add-connection.png”
lightbox=“media/how-to-connection/create-new-data-connection.png”
alt-text=“Screenshot showing the input fields for connecting to a
generic container registry in Azure Machine Learning studio
UI.”:::<br />
+<br />
+—<br />
+<br />
## Related content</p>
<p>If you use a data connection (Snowflake DB, Amazon S3, or Azure SQL
DB), these articles offer more information:</p>
<pre><code>&lt;/details&gt;

### Summary

```json
{
    &quot;filename&quot;: &quot;articles/machine-learning/how-to-connection.md&quot;,
    &quot;modification_type&quot;: &quot;new feature&quot;,
    &quot;modification_title&quot;: &quot;汎用コンテナレジストリへの接続設定の追加&quot;
}</code></pre>
<h3 id="explanation-18">Explanation</h3>
<p>この変更は、<code>how-to-connection.md</code>ファイルに新しいコンテンツを追加し、汎用コンテナレジストリへの接続方法を詳述しています。主な変更点は以下の通りです：</p>
<ol class="incremental" type="1">
<li><strong>汎用コンテナレジストリのセクション追加</strong>：
<ul class="incremental">
<li>新たに汎用コンテナレジストリに関するセクションが追加され、NexusやArtifactoryなどの外部レジストリを指定して、イメージビルドを行う方法が紹介されています。</li>
<li>環境イメージは指定されたレジストリにプッシュされ、以前のキャッシュは無視されることが明記されています。</li>
</ul></li>
<li><strong>YAMLファイルによる接続の作成</strong>：
<ul class="incremental">
<li>Azure
CLIを使用して接続を作成する方法が具体的なYAMLファイルの例を通じて示されており、適切な値を設定するためのガイダンスが提供されています。</li>
<li>環境の作成に関する追加コマンドも示されており、接続を実行するための手順が直接的に示されています。</li>
</ul></li>
<li><strong>Python SDKを用いた接続作成の例</strong>：
<ul class="incremental">
<li>Azure SDKを使用してAzure Container
Registry接続を作成する方法が示され、マネージドアイデンティティによる認証の具体的な実装例が提供されています。</li>
<li>スクリプト内で環境変数から資格情報を取得し、安全に接続情報を設定する方法も説明されています。</li>
</ul></li>
<li><strong>Azure Machine Learning Studioでの設定手順</strong>：
<ul class="incremental">
<li>Azure Machine Learning
StudioのUIを利用した新しい接続の作成手順が、ステップバイステップで解説され、スクリーンショットも追加されて視覚的に理解しやすくなっています。</li>
</ul></li>
</ol>
<p>このように、全体的に文書は汎用コンテナレジストリへの接続を設定するための詳細な手順を含み、ユーザーが実際にこれを行う際の参考となる情報で充実しています。</p>
<h2
id="item-2fb579">articles/machine-learning/how-to-deploy-models-jamba.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb53"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,42 +1,53 @@</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="st">-title: How to deploy Jamba models with Azure Machine Learning studio</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="va">+title: How to deploy AI21&#39;s Jamba family models with Azure Machine Learning studio</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure Machine Learning studio</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="st">-description: How to deploy Jamba models with Azure Machine Learning studio</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="va">+description: How to deploy AI21&#39;s Jamba family models with Azure Machine Learning studio</span></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a> manager: scottpolly</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a> ms.service: azure-machine-learning</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a> ms.topic: how-to</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 06/19/2024</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/06/2024</span></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a> ms.author: ssalgado</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a> ms.reviewer: tgokal</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a> author: ssalgadodev</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a> ms.custom: references_regions</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a><span class="st">-# How to deploy AI21&#39;s Jamba-Instruct model with Azure Machine Learning studio</span></span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a><span class="va">+# How to deploy AI21&#39;s Jamba family models with Azure Machine Learning studio</span></span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a><span class="st">-In this article, you learn how to use Azure Machine Learning studio to deploy AI21&#39;s Jamba-Instruct model as a serverless API with pay-as-you-go billing.</span></span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [machine-learning-preview-generic-disclaimer](includes/machine-learning-preview-generic-disclaimer.md)]</span></span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a><span class="st">-The Jamba Instruct model is AI21&#39;s production-grade Mamba-based large language model (LLM) which leverages AI21&#39;s hybrid Mamba-Transformer architecture. It&#39;s an instruction-tuned version of AI21&#39;s hybrid structured state space model (SSM) transformer Jamba model. The Jamba Instruct model is built for reliable commercial use with respect to quality and performance.</span></span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a><span class="va">+In this article, you learn how to use Azure Machine Learning studio to deploy AI21&#39;s Jamba family models as a serverless API with pay-as-you-go billing.</span></span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a><span class="st">-[!INCLUDE [machine-learning-preview-generic-disclaimer](includes/machine-learning-preview-generic-disclaimer.md)]</span></span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a><span class="va">+The Jamba family models are AI21&#39;s production-grade Mamba-based large language model (LLM) which leverages AI21&#39;s hybrid Mamba-Transformer architecture. It&#39;s an instruction-tuned version of AI21&#39;s hybrid structured state space model (SSM) transformer Jamba model. The Jamba family models are built for reliable commercial use with respect to quality and performance.</span></span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; [!TIP]</span></span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; See our announcements of AI21&#39;s Jamba family models available now on Azure AI Model Catalog through [AI21&#39;s blog](https://aka.ms/ai21-jamba-1.5-large-announcement) and [Microsoft Tech Community Blog](https://aka.ms/ai21-jamba-1.5-large-microsoft-annnouncement).</span></span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a><span class="st">-## Deploy the Jamba Instruct model as a serverless API</span></span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a><span class="va">+## Deploy the Jamba family models as a serverless API</span></span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a><span class="st">-Certain models in the model catalog can be deployed as a serverless API with pay-as-you-go billing, providing a way to consume them as an API without hosting them on your subscription, while keeping the enterprise security and compliance organizations need. This deployment option doesn&#39;t require quota from your subscription.</span></span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a><span class="va">+Certain models in the model catalog can be deployed as a serverless API with pay-as-you-go billing, providing a way to consume them as an API without hosting them on your subscription, while keeping the enterprise security and compliance organizations need. This deployment option doesn&#39;t require quota from your subscription. </span></span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-41"><a href="#cb53-41" aria-hidden="true" tabindex="-1"></a><span class="st">-The AI21-Jamba-Instruct model deployed as a serverless API with pay-as-you-go billing is [offered by AI21 through Microsoft Azure Marketplace](https://aka.ms/azure-marketplace-offer-ai21-jamba-instruct). AI21 can change or update the terms of use and pricing of this model.</span></span>
<span id="cb53-42"><a href="#cb53-42" aria-hidden="true" tabindex="-1"></a><span class="va">+# [AI21 Jamba 1.5 Large](#tab/ai21-jamba-1-5-large)</span></span>
<span id="cb53-43"><a href="#cb53-43" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-44"><a href="#cb53-44" aria-hidden="true" tabindex="-1"></a><span class="st">-To get started with Jamba Instruct deployed as a serverless API, explore our integrations with [LangChain](https://aka.ms/ai21-jamba-instruct-langchain-sample), [LiteLLM](https://aka.ms/ai21-jamba-instruct-litellm-sample), [OpenAI](https://aka.ms/ai21-jamba-instruct-openai-sample) and the [Azure API](https://aka.ms/ai21-jamba-instruct-azure-api-sample).</span></span>
<span id="cb53-45"><a href="#cb53-45" aria-hidden="true" tabindex="-1"></a><span class="va">+The [AI21-Jamba 1.5 Large model](https://aka.ms/aistudio/landing/ai21-labs-jamba-1.5-large) deployed as a serverless API with pay-as-you-go billing is [offered by AI21 through Microsoft Azure Marketplace](https://aka.ms/azure-marketplace-offer-ai21-jamba-1.5-large). AI21 can change or update the terms of use and pricing of this model.</span></span>
<span id="cb53-46"><a href="#cb53-46" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-47"><a href="#cb53-47" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; [!TIP]</span></span>
<span id="cb53-48"><a href="#cb53-48" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; See our announcements of AI21&#39;s Jamba-Instruct model available now on Azure AI Model Catalog through [AI21&#39;s blog](https://aka.ms/ai21-jamba-instruct-blog) and [Microsoft Tech Community Blog](https://aka.ms/ai21-jamba-instruct-announcement).</span></span>
<span id="cb53-49"><a href="#cb53-49" aria-hidden="true" tabindex="-1"></a><span class="va">+To get started with Jamba 1.5 large deployed as a serverless API, explore our integrations with [LangChain](https://aka.ms/ai21-jamba-1.5-large-langchain-sample), [LiteLLM](https://aka.ms/ai21-jamba-1.5-large-litellm-sample), [OpenAI](https://aka.ms/ai21-jamba-1.5-large-openai-sample) and the [Azure API](https://aka.ms/ai21-jamba-1.5-large-azure-api-sample).</span></span>
<span id="cb53-50"><a href="#cb53-50" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb53-51"><a href="#cb53-51" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb53-52"><a href="#cb53-52" aria-hidden="true" tabindex="-1"></a><span class="va">+# [AI21 Jamba 1.5 Mini](#tab/ai21-jamba-1-5)</span></span>
<span id="cb53-53"><a href="#cb53-53" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb53-54"><a href="#cb53-54" aria-hidden="true" tabindex="-1"></a><span class="va">+The [AI21 Jamba 1.5 Mini model](https://aka.ms/aistudio/landing/ai21-labs-jamba-1.5-mini) deployed as a serverless API with pay-as-you-go billing is [offered by AI21 through Microsoft Azure Marketplace](https://aka.ms/azure-marketplace-offer-ai21-jamba-1.5-mini). AI21 can change or update the terms of use and pricing of this model.</span></span>
<span id="cb53-55"><a href="#cb53-55" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb53-56"><a href="#cb53-56" aria-hidden="true" tabindex="-1"></a><span class="va">+To get started with Jamba 1.5 mini deployed as a serverless API, explore our integrations with [LangChain](https://aka.ms/ai21-jamba-1.5-mini-langchain-sample), [LiteLLM](https://aka.ms/ai21-jamba-1.5-mini-litellm-sample), [OpenAI](https://aka.ms/ai21-jamba-1.5-mini-openai-sample) and the [Azure API](https://aka.ms/ai21-jamba-1.5-mini-azure-api-sample).</span></span>
<span id="cb53-57"><a href="#cb53-57" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb53-58"><a href="#cb53-58" aria-hidden="true" tabindex="-1"></a><span class="va">+---</span></span>
<span id="cb53-59"><a href="#cb53-59" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-60"><a href="#cb53-60" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-61"><a href="#cb53-61" aria-hidden="true" tabindex="-1"></a> ### Prerequisites</span>
<span id="cb53-62"><a href="#cb53-62" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-63"><a href="#cb53-63" aria-hidden="true" tabindex="-1"></a> - An Azure subscription with a valid payment method. Free or trial Azure subscriptions won&#39;t work. If you don&#39;t have an Azure subscription, create a [paid Azure account](https://azure.microsoft.com/pricing/purchase-options/pay-as-you-go) to begin.</span>
<span id="cb53-64"><a href="#cb53-64" aria-hidden="true" tabindex="-1"></a><span class="st">-- An Azure Machine Learning workspace and a compute instance. If you don&#39;t have these, use the steps in the [Quickstart: Create workspace resources](quickstart-create-resources.md) article to create them. The serverless API model deployment offering for Jamba Instruct is only available with workspaces created in these regions:</span></span>
<span id="cb53-65"><a href="#cb53-65" aria-hidden="true" tabindex="-1"></a><span class="va">+- An Azure Machine Learning workspace and a compute instance. If you don&#39;t have these, use the steps in the [Quickstart: Create workspace resources](quickstart-create-resources.md) article to create them. The serverless API model deployment offering for the Jamba family of models is only available with workspaces created in these regions:</span></span>
<span id="cb53-66"><a href="#cb53-66" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-67"><a href="#cb53-67" aria-hidden="true" tabindex="-1"></a>      * East US</span>
<span id="cb53-68"><a href="#cb53-68" aria-hidden="true" tabindex="-1"></a>      * East US 2</span>
<span id="cb53-69"><a href="#cb53-69" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -70,11 +81,11 @@ To get started with Jamba Instruct deployed as a serverless API, explore our int</span></span>
<span id="cb53-70"><a href="#cb53-70" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-71"><a href="#cb53-71" aria-hidden="true" tabindex="-1"></a> ### Create a new deployment</span>
<span id="cb53-72"><a href="#cb53-72" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-73"><a href="#cb53-73" aria-hidden="true" tabindex="-1"></a><span class="st">-These steps demonstrate the deployment of AI21-Jamba-Instruct. To create a deployment:</span></span>
<span id="cb53-74"><a href="#cb53-74" aria-hidden="true" tabindex="-1"></a><span class="va">+These steps demonstrate the deployment of `AI21 Jamba 1.5 Large` or `AI21 Jamba 1.5 Mini` models. To create a deployment:</span></span>
<span id="cb53-75"><a href="#cb53-75" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-76"><a href="#cb53-76" aria-hidden="true" tabindex="-1"></a> 1. Go to [Azure Machine Learning studio](https://ml.azure.com/home).</span>
<span id="cb53-77"><a href="#cb53-77" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Select the workspace in which you want to deploy your models. To use the Serverless API model deployment offering, your workspace must belong to the **East US 2** or **Sweden Central** region.</span></span>
<span id="cb53-78"><a href="#cb53-78" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Choose the model you want to deploy from the [model catalog](https://ml.azure.com/model/catalog).</span></span>
<span id="cb53-79"><a href="#cb53-79" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Select the workspace in which you want to deploy your models. To use the Serverless API model deployment offering, your workspace must belong to one of the supported regions that are listed in the pre-requisites.</span></span>
<span id="cb53-80"><a href="#cb53-80" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Search for and select an AI21 model like `AI21 Jamba 1.5 Large` or `AI21 Jamba 1.5 Mini` or `AI21 Jamba Instruct` from the [model catalog](https://ml.azure.com/model/catalog).</span></span>
<span id="cb53-81"><a href="#cb53-81" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-82"><a href="#cb53-82" aria-hidden="true" tabindex="-1"></a>    Alternatively, you can initiate deployment by going to your workspace and selecting **Endpoints** &gt; **Serverless endpoints** &gt; **Create**.</span>
<span id="cb53-83"><a href="#cb53-83" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-84"><a href="#cb53-84" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -97,26 +108,26 @@ These steps demonstrate the deployment of AI21-Jamba-Instruct. To create a deplo</span></span>
<span id="cb53-85"><a href="#cb53-85" aria-hidden="true" tabindex="-1"></a> 1. You can always find the endpoint&#39;s details, URL, and access keys by navigating to **Workspace** &gt; **Endpoints** &gt; **Serverless endpoints**.</span>
<span id="cb53-86"><a href="#cb53-86" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-87"><a href="#cb53-87" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-88"><a href="#cb53-88" aria-hidden="true" tabindex="-1"></a><span class="st">-To learn about billing for Jamba models deployed as a serverless API, see [Cost and quota considerations for Jamba Instruct deployed as a serverless API](#cost-and-quota-considerations-for-jamba-instruct-deployed-as-a-serverless-api).</span></span>
<span id="cb53-89"><a href="#cb53-89" aria-hidden="true" tabindex="-1"></a><span class="va">+To learn about billing for the AI21-Jamba family models deployed as a serverless API with pay-as-you-go token-based billing, see [Cost and quota considerations for Jamba family of models deployed as a serverless API](#cost-and-quota-considerations-for-jamba-family-models-deployed-as-a-serverless-api).</span></span>
<span id="cb53-90"><a href="#cb53-90" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-91"><a href="#cb53-91" aria-hidden="true" tabindex="-1"></a><span class="st">-### Consume Jamba Instruct as a service</span></span>
<span id="cb53-92"><a href="#cb53-92" aria-hidden="true" tabindex="-1"></a><span class="va">+### Consume Jamba family models as a serverless API</span></span>
<span id="cb53-93"><a href="#cb53-93" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-94"><a href="#cb53-94" aria-hidden="true" tabindex="-1"></a><span class="st">-You can consume Jamba Instruct models as follows:</span></span>
<span id="cb53-95"><a href="#cb53-95" aria-hidden="true" tabindex="-1"></a><span class="va">+You can consume Jamba family models as follows:</span></span>
<span id="cb53-96"><a href="#cb53-96" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-97"><a href="#cb53-97" aria-hidden="true" tabindex="-1"></a> 1. In the **workspace**, select **Endpoints** &gt; **Serverless endpoints**.</span>
<span id="cb53-98"><a href="#cb53-98" aria-hidden="true" tabindex="-1"></a> 1. Find and select the deployment you created.</span>
<span id="cb53-99"><a href="#cb53-99" aria-hidden="true" tabindex="-1"></a> 1. Copy the **Target** URL and the **Key** token values.</span>
<span id="cb53-100"><a href="#cb53-100" aria-hidden="true" tabindex="-1"></a> 1. Make an API request using either the [Azure AI Model Inference API](reference-model-inference-api.md) on the route `/chat/completions` or the [AI21&#39;s Azure Client](https://docs.ai21.com/reference/jamba-instruct-api) on `/v1/chat/completions`.</span>
<span id="cb53-101"><a href="#cb53-101" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-102"><a href="#cb53-102" aria-hidden="true" tabindex="-1"></a><span class="st">-For more information on using the APIs, see the [reference](#reference-for-jamba-instruct-deployed-as-a-serverless-api) section.</span></span>
<span id="cb53-103"><a href="#cb53-103" aria-hidden="true" tabindex="-1"></a><span class="va">+For more information on using the APIs, see the [reference](#reference-for-jamba-family-models-deployed-as-a-serverless-api) section.</span></span>
<span id="cb53-104"><a href="#cb53-104" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-105"><a href="#cb53-105" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-106"><a href="#cb53-106" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-107"><a href="#cb53-107" aria-hidden="true" tabindex="-1"></a><span class="st">-## Reference for Jamba Instruct deployed as a serverless API</span></span>
<span id="cb53-108"><a href="#cb53-108" aria-hidden="true" tabindex="-1"></a><span class="va">+## Reference for Jamba family models deployed as a serverless API</span></span>
<span id="cb53-109"><a href="#cb53-109" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-110"><a href="#cb53-110" aria-hidden="true" tabindex="-1"></a><span class="st">-Jamba Instruct models accept both of these APIs:</span></span>
<span id="cb53-111"><a href="#cb53-111" aria-hidden="true" tabindex="-1"></a><span class="va">+Jamba family models accept both of these APIs:</span></span>
<span id="cb53-112"><a href="#cb53-112" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-113"><a href="#cb53-113" aria-hidden="true" tabindex="-1"></a><span class="st">-- The [Azure AI model inference API](reference-model-inference-api.md) [Azure AI Model Inference API] on the route `/chat/completions` for multi-turn chat or single-turn question-answering. This API is supported because Jamba Instruct is fine-tuned for chat completion.</span></span>
<span id="cb53-114"><a href="#cb53-114" aria-hidden="true" tabindex="-1"></a><span class="va">+- The [Azure AI model inference API](reference-model-inference-api.md) [Azure AI Model Inference API] on the route `/chat/completions` for multi-turn chat or single-turn question-answering. This API is supported because Jamba family models are fine-tuned for chat completion.</span></span>
<span id="cb53-115"><a href="#cb53-115" aria-hidden="true" tabindex="-1"></a> - [AI21&#39;s Azure Client](https://docs.ai21.com/reference/jamba-instruct-api). For more information about the REST endpoint being called, visit [AI21&#39;s REST documentation](https://docs.ai21.com/reference/jamba-instruct-api).</span>
<span id="cb53-116"><a href="#cb53-116" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-117"><a href="#cb53-117" aria-hidden="true" tabindex="-1"></a> ### Azure AI model inference API</span>
<span id="cb53-118"><a href="#cb53-118" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -165,7 +176,7 @@ Payload is a JSON formatted string containing the following parameters:</span></span>
<span id="cb53-119"><a href="#cb53-119" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-120"><a href="#cb53-120" aria-hidden="true" tabindex="-1"></a> | Key           | Type           | Required/Default | Allowed values    | Description                                                                                                                                                                                                                                                                                         |</span>
<span id="cb53-121"><a href="#cb53-121" aria-hidden="true" tabindex="-1"></a> | ------------- | -------------- | :-----------------:| ----------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |</span>
<span id="cb53-122"><a href="#cb53-122" aria-hidden="true" tabindex="-1"></a><span class="st">-| `model`       | `string`       | Y    | Must be `jamba-instruct`                                                                                                                                                                                                                                                                            |</span></span>
<span id="cb53-123"><a href="#cb53-123" aria-hidden="true" tabindex="-1"></a><span class="va">+| `model`       | `string`       | Y    | `jamba-instruct` or `AI21 Jamba 1.5 Large` or `AI21 Jamba 1.5 Mini`                                                                                                                                                                                                                                                                           |</span></span>
<span id="cb53-124"><a href="#cb53-124" aria-hidden="true" tabindex="-1"></a> | `messages`    | `list[object]` | Y     | A list of objects, one per message, from oldest to newest. The oldest message can be role `system`. All later messages must alternate between user and assistant roles. See the message object definition below.                                                                                    |</span>
<span id="cb53-125"><a href="#cb53-125" aria-hidden="true" tabindex="-1"></a> | `max_tokens`  | `integer`      | N &lt;br&gt;`4096` |  0 – 4096     | The maximum number of tokens to allow for each generated response message. Typically the best way to limit output length is by providing a length limit in the system prompt (for example, &quot;limit your answers to three sentences&quot;)                                                                 |</span>
<span id="cb53-126"><a href="#cb53-126" aria-hidden="true" tabindex="-1"></a> | `temperature` | `float`        | N &lt;br&gt;`1`  |  0.0 – 2.0      | How much variation to provide in each answer. Setting this value to 0 guarantees the same response to the same question every time. Setting a higher value encourages more variation. Modifies the distribution from which tokens are sampled. We recommend altering this or `top_p`, but not both. |</span>
<span id="cb53-127"><a href="#cb53-127" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -302,9 +313,9 @@ data: [DONE]</span></span>
<span id="cb53-128"><a href="#cb53-128" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-129"><a href="#cb53-129" aria-hidden="true" tabindex="-1"></a> ## Cost and quotas</span>
<span id="cb53-130"><a href="#cb53-130" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-131"><a href="#cb53-131" aria-hidden="true" tabindex="-1"></a><span class="st">-### Cost and quota considerations for Jamba Instruct deployed as a serverless API</span></span>
<span id="cb53-132"><a href="#cb53-132" aria-hidden="true" tabindex="-1"></a><span class="va">+### Cost and quota considerations for Jamba family models deployed as a serverless API</span></span>
<span id="cb53-133"><a href="#cb53-133" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-134"><a href="#cb53-134" aria-hidden="true" tabindex="-1"></a><span class="st">-Jamba models deployed as a serverless API are offered by AI21 through Azure Marketplace and integrated with Azure Machine Learning studio for use. You can find Azure Marketplace pricing when deploying or fine-tuning models.</span></span>
<span id="cb53-135"><a href="#cb53-135" aria-hidden="true" tabindex="-1"></a><span class="va">+The Jamba family models are deployed as a serverless API and is offered by AI21 through Azure Marketplace and integrated with Azure AI studio for use. You can find Azure Marketplace pricing when deploying or fine-tuning models.</span></span>
<span id="cb53-136"><a href="#cb53-136" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-137"><a href="#cb53-137" aria-hidden="true" tabindex="-1"></a> Each time a workspace subscribes to a given model offering from Azure Marketplace, a new resource is created to track the costs associated with its consumption. The same resource is used to track costs associated with inference and fine-tuning; however, multiple meters are available to track each scenario independently.</span>
<span id="cb53-138"><a href="#cb53-138" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-14">Summary</h3>
<div class="sourceCode" id="cb54"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/how-to-deploy-models-jamba.md&quot;</span><span class="fu">,</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;AI21のJambaファミリーモデルのデプロイに関するガイドの更新&quot;</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-19">Explanation</h3>
<p>この変更は、<code>how-to-deploy-models-jamba.md</code>ファイルに対する修正を含み、AI21のJambaファミリーモデルのデプロイ方法に関する情報を更新しています。主な変更点は以下の通りです：</p>
<ol class="incremental" type="1">
<li><strong>タイトルと説明の更新</strong>：
<ul class="incremental">
<li>文書のタイトルが「AI21のJamba-Instructモデルのデプロイ」から「AI21のJambaファミリーモデルのデプロイ」に変更され、全体の説明もAI21のJambaファミリー全体に拡大されました。</li>
</ul></li>
<li><strong>日付の更新</strong>：
<ul class="incremental">
<li>最終更新日が2024年6月19日から2024年9月6日に変更され、最新の情報に更新されています。</li>
</ul></li>
<li><strong>モデルに関する情報の明確化</strong>：
<ul class="incremental">
<li>Jambaモデルの説明が更新され、AI21のハイブリッドMamba-Transformerアーキテクチャに基づく大規模言語モデル（LLM）であることが強調されています。</li>
<li>モデルが商業用途において品質とパフォーマンスが信頼できるものであることが強調されています。</li>
</ul></li>
<li><strong>新しい統合情報の追加</strong>：
<ul class="incremental">
<li>Jambaモデルに関連する新しい統合サンプルのリンクが追加され、具体的にどのように他のプラットフォームと連携できるかの情報が提供されています。</li>
</ul></li>
<li><strong>デプロイ手順の変更</strong>：
<ul class="incremental">
<li>デプロイ手順がAI21 Jamba 1.5 LargeやAI21 Jamba 1.5
Miniモデルについて明確になり、そしてサーバーレスAPIとしてのデプロイ方法が、特定の地域の要件を含めてまとめられています。</li>
<li>手順の中で、サポート対象地域が明示され、どの地域でデプロイできるかが明確に記載されています。</li>
</ul></li>
<li><strong>コストと利用制限についての更新</strong>：
<ul class="incremental">
<li>JambaファミリーモデルがサーバーレスAPIとして提供され、Azure
Marketplaceを通じて利用可能であることが記され、コスト関連の詳細についても新たに言及されています。</li>
</ul></li>
</ol>
<p>このように、全体的に文書はJambaモデルのデプロイメントに関する詳細なガイドとして、ユーザーがこれを実行する際の助けとなる情報を提供するために、刷新された内容を含んでいます。</p>
<h2
id="item-4de1d8">articles/machine-learning/how-to-prepare-datasets-for-automl-images.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb55"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,49 +1,50 @@</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a> title: Prepare data for computer vision tasks</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure Machine Learning</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="st">-description: Image data preparation for Azure Machine Learning automated ML to train computer vision models on classification, object detection,  and segmentation</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="va">+description: Learn about image data preparation for Azure Machine Learning to train computer vision models on classification, object detection, and segmentation.</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a> author: ssalgadodev</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a> ms.author: ssalgado</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a> ms.service: azure-machine-learning</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a> ms.subservice: automl</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a> ms.topic: how-to</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.custom: template-how-to, update-code, sdkv2, </span></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.custom: template-how-to, update-code, sdkv2</span></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a> ms.reviewer: rvadthyavath</span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 03/26/2024</span></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/06/2024</span></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a><span class="va">+#customer intent: As a data scientist, I want to prepare image data for training computer vision models.</span></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a> # Prepare data for computer vision tasks with automated machine learning</span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a> [!INCLUDE [dev v2](includes/machine-learning-dev-v2.md)]</span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a> &gt; [!IMPORTANT]</span>
<span id="cb55-26"><a href="#cb55-26" aria-hidden="true" tabindex="-1"></a> &gt; Support for training computer vision models with automated ML in Azure Machine Learning is an experimental public preview feature. Certain features might not be supported or might have constrained capabilities. For more information, see [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/).</span>
<span id="cb55-27"><a href="#cb55-27" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-28"><a href="#cb55-28" aria-hidden="true" tabindex="-1"></a><span class="st">-In this article, you learn how to prepare image data for training computer vision models with [automated machine learning in Azure Machine Learning](concept-automated-ml.md). </span></span>
<span id="cb55-29"><a href="#cb55-29" aria-hidden="true" tabindex="-1"></a><span class="st">-</span></span>
<span id="cb55-30"><a href="#cb55-30" aria-hidden="true" tabindex="-1"></a><span class="st">-To generate models for computer vision tasks with automated machine learning, you need to bring labeled image data as input for model training in the form of an `MLTable`. </span></span>
<span id="cb55-31"><a href="#cb55-31" aria-hidden="true" tabindex="-1"></a><span class="va">+In this article, you learn how to prepare image data for training computer vision models with [automated machine learning in Azure Machine Learning](concept-automated-ml.md). To generate models for computer vision tasks with automated machine learning, you need to bring labeled image data as input for model training in the form of an `MLTable`.</span></span>
<span id="cb55-32"><a href="#cb55-32" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-33"><a href="#cb55-33" aria-hidden="true" tabindex="-1"></a><span class="st">-You can create an `MLTable` from labeled training data in JSONL format. </span></span>
<span id="cb55-34"><a href="#cb55-34" aria-hidden="true" tabindex="-1"></a><span class="st">-If your labeled training data is in a different format (like, pascal VOC or COCO), you can use a [conversion script](https://github.com/Azure/azureml-examples/blob/v1-archive/v1/python-sdk/tutorials/automl-with-azureml/image-object-detection/coco2jsonl.py) to first convert it to JSONL, and then create an `MLTable`. Alternatively, you can use  Azure Machine Learning&#39;s [data labeling tool](how-to-create-image-labeling-projects.md) to manually label images, and export the labeled data to use for training your AutoML model.</span></span>
<span id="cb55-35"><a href="#cb55-35" aria-hidden="true" tabindex="-1"></a><span class="va">+You can create an `MLTable` from labeled training data in JSONL format. If your labeled training data is in a different format, like Pascal Visual Object Classes (VOC) or COCO, you can use a [conversion script](https://github.com/Azure/azureml-examples/blob/v1-archive/v1/python-sdk/tutorials/automl-with-azureml/image-object-detection/coco2jsonl.py) to convert it to JSONL, and then create an `MLTable`. Alternatively, you can use Azure Machine Learning&#39;s data labeling tool to manually label images. Then export the labeled data to use for training your AutoML model.</span></span>
<span id="cb55-36"><a href="#cb55-36" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-37"><a href="#cb55-37" aria-hidden="true" tabindex="-1"></a> ## Prerequisites</span>
<span id="cb55-38"><a href="#cb55-38" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-39"><a href="#cb55-39" aria-hidden="true" tabindex="-1"></a><span class="st">-* Familiarize yourself with the accepted [schemas for JSONL files for AutoML computer vision experiments](reference-automl-images-schema.md).</span></span>
<span id="cb55-40"><a href="#cb55-40" aria-hidden="true" tabindex="-1"></a><span class="va">+- Familiarize yourself with the accepted [schemas for JSONL files for AutoML computer vision experiments](reference-automl-images-schema.md).</span></span>
<span id="cb55-41"><a href="#cb55-41" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb55-42"><a href="#cb55-42" aria-hidden="true" tabindex="-1"></a><span class="va">+## Get labeled data</span></span>
<span id="cb55-43"><a href="#cb55-43" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb55-44"><a href="#cb55-44" aria-hidden="true" tabindex="-1"></a><span class="va">+In order to train computer vision models using AutoML, you need to get labeled training data. The images need to be uploaded to the cloud. Label annotations need to be in JSONL format. You can either use the Azure Machine Learning Data Labeling tool to label your data or you could start with prelabeled image data.</span></span>
<span id="cb55-45"><a href="#cb55-45" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-46"><a href="#cb55-46" aria-hidden="true" tabindex="-1"></a><span class="st">-## Get labeled data </span></span>
<span id="cb55-47"><a href="#cb55-47" aria-hidden="true" tabindex="-1"></a><span class="st">-In order to train computer vision models using AutoML, you need to first get labeled training data. The images need to be uploaded to the cloud and label annotations need to be in JSONL format. You can either use the Azure Machine Learning Data Labeling tool to label your data or you could start with prelabeled image data.</span></span>
<span id="cb55-48"><a href="#cb55-48" aria-hidden="true" tabindex="-1"></a><span class="va">+### Use Azure Machine Learning Data Labeling tool to label your training data</span></span>
<span id="cb55-49"><a href="#cb55-49" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-50"><a href="#cb55-50" aria-hidden="true" tabindex="-1"></a><span class="st">-### Using Azure Machine Learning Data Labeling tool to label your training data</span></span>
<span id="cb55-51"><a href="#cb55-51" aria-hidden="true" tabindex="-1"></a><span class="st">-If you don&#39;t have prelabeled data, you can use Azure Machine Learning&#39;s [data labeling tool](how-to-create-image-labeling-projects.md) to manually label images. This tool automatically generates the data required for training in the accepted format.</span></span>
<span id="cb55-52"><a href="#cb55-52" aria-hidden="true" tabindex="-1"></a><span class="va">+If you don&#39;t have prelabeled data, you can use Azure Machine Learning&#39;s data labeling tool to manually label images. This tool automatically generates the data required for training in the accepted format. For more information, see [Set up an image labeling project](how-to-create-image-labeling-projects.md).</span></span>
<span id="cb55-53"><a href="#cb55-53" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-54"><a href="#cb55-54" aria-hidden="true" tabindex="-1"></a><span class="st">-It helps to create, manage, and monitor data labeling tasks for </span></span>
<span id="cb55-55"><a href="#cb55-55" aria-hidden="true" tabindex="-1"></a><span class="va">+The tool helps to create, manage, and monitor data labeling tasks for:</span></span>
<span id="cb55-56"><a href="#cb55-56" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-57"><a href="#cb55-57" aria-hidden="true" tabindex="-1"></a><span class="st">-+ Image classification (multi-class and multi-label)</span></span>
<span id="cb55-58"><a href="#cb55-58" aria-hidden="true" tabindex="-1"></a><span class="st">-+ Object detection (bounding box)</span></span>
<span id="cb55-59"><a href="#cb55-59" aria-hidden="true" tabindex="-1"></a><span class="st">-+ Instance segmentation (polygon)</span></span>
<span id="cb55-60"><a href="#cb55-60" aria-hidden="true" tabindex="-1"></a><span class="va">+- Image classification (multi-class and multi-label)</span></span>
<span id="cb55-61"><a href="#cb55-61" aria-hidden="true" tabindex="-1"></a><span class="va">+- Object detection (bounding box)</span></span>
<span id="cb55-62"><a href="#cb55-62" aria-hidden="true" tabindex="-1"></a><span class="va">+- Instance segmentation (polygon)</span></span>
<span id="cb55-63"><a href="#cb55-63" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-64"><a href="#cb55-64" aria-hidden="true" tabindex="-1"></a><span class="st">-If you already have labeled data you want to use, you can [export your labeled data as an Azure Machine Learning Dataset](how-to-manage-labeling-projects.md#export-the-labels) and then access the dataset under &#39;Datasets&#39; tab in Azure Machine Learning studio. This exported dataset can then be passed as an input using `azureml:&lt;tabulardataset_name&gt;:&lt;version&gt;` format. Here&#39;s an example of how to pass existing dataset as input for training computer vision models. </span></span>
<span id="cb55-65"><a href="#cb55-65" aria-hidden="true" tabindex="-1"></a><span class="va">+If you already have labeled data to use, export that labeled data as an Azure Machine Learning Dataset and access the dataset under the **Datasets** tab in Azure Machine Learning studio. You can pass this exported dataset as an input using `azureml:&lt;tabulardataset_name&gt;:&lt;version&gt;` format. For more information, see [Export the labels](how-to-manage-labeling-projects.md#export-the-labels).</span></span>
<span id="cb55-66"><a href="#cb55-66" aria-hidden="true" tabindex="-1"></a><span class="va">+</span></span>
<span id="cb55-67"><a href="#cb55-67" aria-hidden="true" tabindex="-1"></a><span class="va">+Here&#39;s an example of how to pass existing dataset as input for training computer vision models.</span></span>
<span id="cb55-68"><a href="#cb55-68" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-69"><a href="#cb55-69" aria-hidden="true" tabindex="-1"></a> # [Azure CLI](#tab/cli)</span>
<span id="cb55-70"><a href="#cb55-70" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-71"><a href="#cb55-71" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -77,18 +78,18 @@ Refer to CLI/SDK tabs for reference.</span></span>
<span id="cb55-72"><a href="#cb55-72" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-73"><a href="#cb55-73" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb55-74"><a href="#cb55-74" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-75"><a href="#cb55-75" aria-hidden="true" tabindex="-1"></a><span class="st">-### Using prelabeled training data from local machine</span></span>
<span id="cb55-76"><a href="#cb55-76" aria-hidden="true" tabindex="-1"></a><span class="st">-If you have labeled data that you would like to use to train your model, you need to upload the images to Azure. You can upload the your images to the default Azure Blob Storage of your Azure Machine Learning Workspace and register it as a [data asset](how-to-create-data-assets.md). </span></span>
<span id="cb55-77"><a href="#cb55-77" aria-hidden="true" tabindex="-1"></a><span class="va">+### Use prelabeled training data from local machine</span></span>
<span id="cb55-78"><a href="#cb55-78" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-79"><a href="#cb55-79" aria-hidden="true" tabindex="-1"></a><span class="st">-The following script uploads the image data on your local machine at path &quot;./data/odFridgeObjects&quot; to datastore in Azure Blob Storage. It then creates a new data asset with the name &quot;fridge-items-images-object-detection&quot; in your Azure Machine Learning Workspace. </span></span>
<span id="cb55-80"><a href="#cb55-80" aria-hidden="true" tabindex="-1"></a><span class="va">+If you have labeled data that you want to use to train your model, upload the images to Azure. You can upload your images to the default Azure Blob Storage of your Azure Machine Learning Workspace. Register it as a *data asset*. For more information, see [Create and manage data assets](how-to-create-data-assets.md).</span></span>
<span id="cb55-81"><a href="#cb55-81" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-82"><a href="#cb55-82" aria-hidden="true" tabindex="-1"></a><span class="va">+The following script uploads the image data on your local machine at path *./data/odFridgeObjects* to datastore in Azure Blob Storage. It then creates a new data asset with the name `fridge-items-images-object-detection` in your Azure Machine Learning Workspace.</span></span>
<span id="cb55-83"><a href="#cb55-83" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-84"><a href="#cb55-84" aria-hidden="true" tabindex="-1"></a><span class="st">-If there already exists a data asset with the name &quot;fridge-items-images-object-detection&quot; in your Azure Machine Learning Workspace, it updates the version number of the data asset and points it to the new location where the image data uploaded.</span></span>
<span id="cb55-85"><a href="#cb55-85" aria-hidden="true" tabindex="-1"></a><span class="va">+If there already exists a data asset with the name `fridge-items-images-object-detection` in your Azure Machine Learning Workspace, the code updates the version number of the data asset and points it to the new location where the image data uploaded.</span></span>
<span id="cb55-86"><a href="#cb55-86" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-87"><a href="#cb55-87" aria-hidden="true" tabindex="-1"></a> # [Azure CLI](#tab/cli)</span>
<span id="cb55-88"><a href="#cb55-88" aria-hidden="true" tabindex="-1"></a> [!INCLUDE [cli v2](includes/machine-learning-cli-v2.md)]</span>
<span id="cb55-89"><a href="#cb55-89" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-90"><a href="#cb55-90" aria-hidden="true" tabindex="-1"></a><span class="st">-Create an .yml file with the following configuration.</span></span>
<span id="cb55-91"><a href="#cb55-91" aria-hidden="true" tabindex="-1"></a><span class="va">+Create an *.yml* file with the following configuration.</span></span>
<span id="cb55-92"><a href="#cb55-92" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb55-93"><a href="#cb55-93" aria-hidden="true" tabindex="-1"></a> ```yml</span>
<span id="cb55-94"><a href="#cb55-94" aria-hidden="true" tabindex="-1"></a> $schema: https://azuremlschemas.azureedge.net/latest/data.schema.json</span>
<span id="cb55-95"><a href="#cb55-95" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -98,30 +99,30 @@ path: ./data/odFridgeObjects</span></span>
<span id="cb55-96"><a href="#cb55-96" aria-hidden="true" tabindex="-1"></a> type: uri_folder</span></code></pre></div>
<p>-To upload the images as a data asset, you run the following CLI v2
command with the path to your .yml file, workspace name, resource group,
and subscription ID.<br />
+To upload the images as a data asset, run the following CLI v2 command
with the path to your <em>.yml</em> file, workspace name, resource
group, and subscription ID.</p>
<pre class="azurecli"><code>az ml data create -f [PATH_TO_YML_FILE] --workspace-name [YOUR_AZURE_WORKSPACE] --resource-group [YOUR_AZURE_RESOURCE_GROUP] --subscription [YOUR_AZURE_SUBSCRIPTION]</code></pre>
<p># <a href="#tab/python">Python SDK</a></p>
<ul class="incremental">
<li>[!INCLUDE <a href="includes/machine-learning-sdk-v2.md">sdk
v2</a>]<br />
+[!INCLUDE <a href="includes/machine-learning-sdk-v2.md">sdk
v2</a>]</li>
</ul>
<p>[!Notebook-python[]
(~/azureml-examples-main/sdk/python/jobs/automl-standalone-jobs/automl-image-object-detection-task-fridge-items/automl-image-object-detection-task-fridge-items.ipynb?name=upload-data)]</p>
<p># <a href="#tab/Studio">Studio</a></p>
<p>-<img
src="media\how-to-prepare-datasets-for-automl-images\ui-dataset-local.gif"
alt="Animation showing how to register a dataset from local files" /><br />
+:::image type=“content”
source=“media-to-prepare-datasets-for-automl-images-dataset-local.gif”
alt-text=“Animation showing how to register a dataset from local
files.”:::</p>
<hr />
<p>-If you already have your data present in an existing datastore and
want to create a data asset out of it, you can do so by providing the
path to the data in the datastore, instead of providing the path of your
local machine. Update the code <a
href="#using-prelabeled-training-data-from-local-machine">above</a> with
the following snippet.<br />
+If you already have your data in an existing datastore, you can create
a data asset out of it. Provide the path to the data in the datastore
instead of the path of your local machine. Update <a
href="#use-prelabeled-training-data-from-local-machine">the preceding
code</a> with the following snippet.</p>
<p># <a href="#tab/cli">Azure CLI</a><br />
[!INCLUDE <a href="includes/machine-learning-cli-v2.md">cli v2</a>]</p>
<p>-Create an .yml file with the following configuration.<br />
+Create a <em>.yml</em> file with the following configuration.</p>
<div class="sourceCode" id="cb57"><pre
class="sourceCode yml"><code class="sourceCode yaml"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">$schema</span><span class="kw">:</span><span class="at"> https://azuremlschemas.azureedge.net/latest/data.schema.json</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -133,7 +134,6 @@ type</span><span class="kw">:</span><span class="at"> uri_folder</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="co"># [Python SDK](#tab/python)</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="kw">-</span><span class="at"> </span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="at">```Python</span></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="at">my_data = Data(</span></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="at">    path=&quot;azureml://subscriptions/&lt;my-subscription-id&gt;/resourcegroups/&lt;my-resource-group&gt;/workspaces/&lt;my-workspace&gt;/datastores/&lt;my-datastore&gt;/paths/&lt;path_to_image_data_folder&gt;&quot;,</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a><span class="at">@@ -145,24 +145,25 @@ my_data = Data(</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a><span class="co"># [Studio](#tab/Studio)</span></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a><span class="at">-![Animation showing how to register a dataset from data already present in datastore](media\how-to-prepare-datasets-for-automl-images\ui-dataset-datastore.gif)</span></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="at">+:::image type=&quot;content&quot; source=&quot;media\how-to-prepare-datasets-for-automl-images\ui-dataset-datastore.gif&quot; alt-text=&quot;Animation showing how to register a dataset from data already present in datastore.&quot;:</span><span class="fu">:</span><span class="kw">:</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a><span class="pp">---</span></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a><span class="at">-Next, you need to get the label annotations in JSONL format. The schema of labeled data depends on the computer vision task at hand. Refer to [schemas for JSONL files for AutoML computer vision experiments](reference-automl-images-schema.md) to learn more about the required JSONL schema for each task type.</span></span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a><span class="at">+Next, get the label annotations in JSONL format. The schema of labeled data depends on the computer vision task at hand. To learn more about the required JSONL schema for each task type, see [Data schemas to train computer vision models with automated machine learning](reference-automl-images-schema.md).</span></span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a><span class="at">+</span></span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a><span class="at">+If your training data is in a different format, like pascal VOC or COCO, [helper scripts](https://github.com/Azure/azureml-examples/blob/v1-archive/v1/python-sdk/tutorials/automl-with-azureml/image-object-detection/coco2jsonl.py) can convert the data to JSONL. The scripts are available in [notebook examples](https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs).</span></span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a><span class="at">-If your training data is in a different format (like, pascal VOC or COCO), [helper scripts](https://github.com/Azure/azureml-examples/blob/v1-archive/v1/python-sdk/tutorials/automl-with-azureml/image-object-detection/coco2jsonl.py) to convert the data to JSONL are available in [notebook examples](https://github.com/Azure/azureml-examples/blob/main/sdk/python/jobs/automl-standalone-jobs).</span></span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a><span class="at">+After you create the *.jsonl* file, you can register it as a data asset using the UI. Make sure that you select `stream` type in schema section as shown in this animation.</span></span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a><span class="at">-Once you created jsonl file following the above steps, you can register it as a data asset using UI. Make sure you select `stream` type in schema section as shown in this animation.</span></span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a><span class="at">+:::image type=&quot;content&quot; source=&quot;media\how-to-prepare-datasets-for-automl-images\ui-dataset-jsnol.gif&quot; alt-text=&quot;Animation showing how to register a data asset from the jsonl files.&quot;:</span><span class="fu">:</span><span class="kw">:</span></span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a><span class="at">-![Animation showing how to register a data asset from the jsonl files](media\how-to-prepare-datasets-for-automl-images\ui-dataset-jsnol.gif)</span></span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a><span class="at">+</span><span class="co">### Use prelabeled training data from Azure Blob storage</span></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a><span class="at">-</span><span class="co">### Using prelabeled training data from Azure Blob storage</span></span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a><span class="at">-If you have your labeled training data present in a container in Azure Blob storage, then you can access it directly from there by [creating a datastore referring to that container](how-to-datastore.md</span><span class="co">#create-an-azure-blob-datastore).</span></span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a><span class="at">+If your labeled training data is present in a container in Azure Blob storage, you can access it directly. Create a datastore to that container. For more information, see [Create and manage data assets](how-to-datastore.md</span><span class="co">#create-an-azure-blob-datastore).</span></span>
<span id="cb57-36"><a href="#cb57-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-37"><a href="#cb57-37" aria-hidden="true" tabindex="-1"></a><span class="co">## Create MLTable</span></span>
<span id="cb57-38"><a href="#cb57-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-39"><a href="#cb57-39" aria-hidden="true" tabindex="-1"></a><span class="at">-Once you have your labeled data in JSONL format, you can use it to create `MLTable` as shown in this yaml snippet. MLtable packages your data into a consumable object for training.</span></span>
<span id="cb57-40"><a href="#cb57-40" aria-hidden="true" tabindex="-1"></a><span class="at">+After your labeled data is in JSONL format, you can use it to create `MLTable` as shown in this yaml snippet. MLtable packages your data into a consumable object for training.</span></span>
<span id="cb57-41"><a href="#cb57-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-42"><a href="#cb57-42" aria-hidden="true" tabindex="-1"></a><span class="at">```yaml</span></span>
<span id="cb57-43"><a href="#cb57-43" aria-hidden="true" tabindex="-1"></a><span class="fu">paths</span><span class="kw">:</span></span>
<span id="cb57-44"><a href="#cb57-44" aria-hidden="true" tabindex="-1"></a><span class="fu">@@ -177,10 +178,10 @@ transformations</span><span class="kw">:</span></span>
<span id="cb57-45"><a href="#cb57-45" aria-hidden="true" tabindex="-1"></a><span class="at">        </span><span class="fu">column_type</span><span class="kw">:</span><span class="at"> stream_info</span></span></code></pre></div>
<p>-You can then pass in the <code>MLTable</code> as a <a
href="./how-to-auto-train-image-models.md#consume-data">data input for
your AutoML training job</a>.<br />
+You can then pass in the <code>MLTable</code> as a data input for your
AutoML training job. For more information, see <a
href="./how-to-auto-train-image-models.md#consume-data">Set up AutoML to
train computer vision models</a>.</p>
<p>-## Next steps<br />
+## Related content</p>
<p>-* <a href="how-to-auto-train-image-models.md">Train computer vision
models with automated machine learning</a>.<br />
-* <a href="how-to-use-automl-small-object-detect.md">Train a small
object detection model with automated machine learning</a>.<br />
-* <a href="tutorial-auto-train-image-models.md">Tutorial: Train an
object detection model (preview) with AutoML and Python</a>.<br />
+- <a href="how-to-auto-train-image-models.md">Set up AutoML to train
computer vision models</a>.<br />
+- <a href="how-to-use-automl-small-object-detect.md">Train a small
object detection model with AutoML</a>.<br />
+- <a href="tutorial-auto-train-image-models.md">Tutorial: Train an
object detection model with AutoML and Python</a>.</p>
<pre><code>&lt;/details&gt;

### Summary

```json
{
    &quot;filename&quot;: &quot;articles/machine-learning/how-to-prepare-datasets-for-automl-images.md&quot;,
    &quot;modification_type&quot;: &quot;minor update&quot;,
    &quot;modification_title&quot;: &quot;自動機械学習のための画像データセット準備に関するガイドの更新&quot;
}</code></pre>
<h3 id="explanation-20">Explanation</h3>
<p>この変更は、<code>how-to-prepare-datasets-for-automl-images.md</code>ファイルに対する修正を含み、Azure
Machine Learning
の自動機械学習における画像データセットの準備方法に関する情報を更新しています。主な変更点は以下の通りです：</p>
<ol class="incremental" type="1">
<li><strong>タイトルと説明の更新</strong>：
<ul class="incremental">
<li>文書の説明が、画像データ準備に関する具体的な情報を強調する形で調整され、より明確に理解できる内容になっています。</li>
</ul></li>
<li><strong>日付の更新</strong>：
<ul class="incremental">
<li>最終更新日が2024年3月26日から2024年9月6日に変更され、最新の情報となっています。</li>
</ul></li>
<li><strong>データ準備手順の整備</strong>：
<ul class="incremental">
<li>画像データをMLTable形式で準備する手順が整理され、JSONL形式でのラベル付きデータの作成方法がより明確に説明されています。</li>
</ul></li>
<li><strong>手順の詳細化</strong>：
<ul class="incremental">
<li>前処理が必要なラベル付きデータについての説明が追加され、Azure
Machine Learning
のデータラベリングツールを使用して、手動でラベル付けを行い、そのデータをエクスポートする方法が具体的に示されています。</li>
</ul></li>
<li><strong>プラットフォーム間のリンクの追加</strong>：
<ul class="incremental">
<li>自動機械学習のためのデータ準備に関連するリンクが追加され、ユーザーが他の関連ドキュメントを簡単に参照できるようになっています。</li>
</ul></li>
<li><strong>コード例と手順の修正</strong>：
<ul class="incremental">
<li>プレラベル付きトレーニングデータをローカルマシンからAzureにアップロードする方法のスクリプトが更新され、正確なコマンド説明が提供されています。</li>
</ul></li>
<li><strong>画像やアニメーションの更新</strong>：
<ul class="incremental">
<li>UIでのデータセット登録手順を説明するためのアニメーションが追加され、視覚的にプロセスの理解が促進されるようになっています。</li>
</ul></li>
<li><strong>関連コンテンツの整備</strong>：
<ul class="incremental">
<li>関連するコンテンツリンクが整理され、ユーザーが次のステップとして参照するべき情報が容易に見つけられるようになっています。</li>
</ul></li>
</ol>
<p>これらの変更により、ユーザーはAzure Machine
Learningでコンピュータビジョンモデルをトレーニングするための画像データの準備方法に関する最新で包括的なガイドを得ることができ、より効果的に作業を行えるようになります。</p>
<h2
id="item-d072d3">articles/machine-learning/media/how-to-connection/how-to-connect-add-connection.png</h2>
<h3 id="summary-15">Summary</h3>
<div class="sourceCode" id="cb59"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/media/how-to-connection/how-to-connect-add-connection.png&quot;</span><span class="fu">,</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;接続の追加方法を示す画像の追加&quot;</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-21">Explanation</h3>
<p>この変更は、<code>how-to-connect-add-connection.png</code>という画像ファイルが新たに追加されたことを示しています。この画像は、Azure
Machine Learning
における接続の追加方法を視覚的に示すものであり、ユーザーがこの機能の使用方法を理解するのに役立ちます。</p>
<p>新しい画像の追加により、文書全体がよりインタラクティブでわかりやすくなり、特に新しいユーザーや視覚的な学習者に対して効果的な情報提供が可能になります。ユーザーはこの画像を参照することで、接続の手順や設定をより簡単に把握できるようになります。</p>
<h2
id="item-29d619">articles/machine-learning/media/how-to-connection/how-to-connect-generic-container-registry.png</h2>
<h3 id="summary-16">Summary</h3>
<div class="sourceCode" id="cb60"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/media/how-to-connection/how-to-connect-generic-container-registry.png&quot;</span><span class="fu">,</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;汎用コンテナレジストリへの接続方法を示す画像の追加&quot;</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-22">Explanation</h3>
<p>この変更は、<code>how-to-connect-generic-container-registry.png</code>という画像ファイルが新たに追加されたことを示しています。この画像は、汎用コンテナレジストリへの接続方法を視覚的に示すものであり、ユーザーに対して具体的な手順や設定方法を理解するための参考になります。</p>
<p>この新しい画像の追加によって、文書はよりわかりやすくなり、特に新しいユーザーや視覚的な学習者に対して効果的に情報を伝えることができます。ユーザーは、汎用コンテナレジストリへの接続をどのように行うかを直感的に把握でき、作業をスムーズに進める手助けとなります。</p>
<h2
id="item-7aa2af">articles/machine-learning/media/how-to-connection/how-to-manage-connections-create.png</h2>
<h3 id="summary-17">Summary</h3>
<div class="sourceCode" id="cb61"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/media/how-to-connection/how-to-manage-connections-create.png&quot;</span><span class="fu">,</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;new feature&quot;</span><span class="fu">,</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;接続管理の作成方法を示す画像の追加&quot;</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-23">Explanation</h3>
<p>この変更では、<code>how-to-manage-connections-create.png</code>という画像ファイルが新たに追加されました。この画像は、接続の管理と作成方法を視覚的に説明するもので、ユーザーがAzure
Machine Learningにおいて接続を適切に管理する手助けとなります。</p>
<p>新しい画像の追加により、関連する文書がより充実し、特に新しいユーザーや視覚的な学習者に対して具体的で理解しやすい情報を提供します。この画像を通じて、ユーザーは接続を作成する手順やベストプラクティスを簡単に把握できるようになります。</p>
<h2 id="item-e1c1a2">articles/machine-learning/samples-notebooks.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb62"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -9,7 +9,7 @@ ms.topic: sample</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a> author: sdgilley</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a> ms.author: sgilley</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a> ms.reviewer: sgilley</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 02/05/2024</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a> #Customer intent: As a professional data scientist, I find and run example Jupyter Notebooks for Azure Machine Learning.</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -23,20 +23,20 @@ This article shows you how to access the repository from the following environme</span></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a> - Azure Machine Learning compute instance</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a> - Your own compute resource</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a><span class="st">-- Data Science Virtual Machine</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a><span class="va">+- Data Science Virtual Machine (DSVM)</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a> You can also [browse code samples](/samples/browse/?expanded=azure&amp;products=azure-machine-learning) for more examples.</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a> ## Option 1: Access on Azure Machine Learning compute instance (recommended)</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a><span class="st">-The easiest way to get started with the samples is to complete the [Create resources to get started](quickstart-create-resources.md). Once completed, you&#39;ll have a dedicated notebook server preloaded with the SDK and the Azure Machine Learning Notebooks repository. No downloads or installation necessary.</span></span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a><span class="va">+The easiest way to get started with the samples is to complete [Create resources to get started](quickstart-create-resources.md). Once completed, you have a dedicated notebook server preloaded with the SDK and the Azure Machine Learning Notebooks repository. No downloads or installation necessary.</span></span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a> To view example notebooks:</span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a> 1. Sign in to [studio](https://ml.azure.com) and select your workspace if necessary.</span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a> 1. Select **Notebooks**.</span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a> 1. Select the **Samples** tab. Use the **SDK v2** folder for examples using Python SDK v2.</span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a><span class="st">-1. Open the notebook you want to run.  Select **Clone this notebook** to create a copy in your workspace file share.  This action will copy the notebook along with any dependent resources.</span></span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a><span class="va">+1. Open the notebook you want to run. Select **Clone this notebook** to create a copy in your workspace file share. This action copies the notebook, along with any dependent resources, to the file storage in your project.</span></span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-32"><a href="#cb62-32" aria-hidden="true" tabindex="-1"></a> ## Option 2: Access on your own notebook server</span>
<span id="cb62-33"><a href="#cb62-33" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-34"><a href="#cb62-34" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -48,14 +48,14 @@ These instructions install the base SDK packages necessary for the quickstart an</span></span>
<span id="cb62-35"><a href="#cb62-35" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-36"><a href="#cb62-36" aria-hidden="true" tabindex="-1"></a> ## Option 3: Access on a DSVM</span>
<span id="cb62-37"><a href="#cb62-37" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-38"><a href="#cb62-38" aria-hidden="true" tabindex="-1"></a><span class="st">-The Data Science Virtual Machine (DSVM) is a customized VM image built specifically for doing data science. If you [create a DSVM](how-to-configure-environment.md#local-and-dsvm-only-create-a-workspace-configuration-file), the SDK and notebook server are installed and configured for you. However, you&#39;ll still need to create a workspace and clone the sample repository.</span></span>
<span id="cb62-39"><a href="#cb62-39" aria-hidden="true" tabindex="-1"></a><span class="va">+The Data Science Virtual Machine (DSVM) is a customized Virtual Machine (VM) image built specifically for doing data science. If you [create a DSVM](how-to-configure-environment.md#local-and-dsvm-only-create-a-workspace-configuration-file), the SDK and notebook server are installed and configured for you. However, you still need to create a workspace and clone the sample repository.</span></span>
<span id="cb62-40"><a href="#cb62-40" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-41"><a href="#cb62-41" aria-hidden="true" tabindex="-1"></a><span class="st">-1. [Create an Azure Machine Learning workspace](how-to-manage-workspace.md).</span></span>
<span id="cb62-42"><a href="#cb62-42" aria-hidden="true" tabindex="-1"></a><span class="va">+1. [Create an Azure Machine Learning workspace](./quickstart-create-resources.md#create-the-workspace).</span></span>
<span id="cb62-43"><a href="#cb62-43" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-44"><a href="#cb62-44" aria-hidden="true" tabindex="-1"></a> 1. Clone the [the AzureML-Examples repository](https://aka.ms/aml-notebooks).</span>
<span id="cb62-45"><a href="#cb62-45" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-46"><a href="#cb62-46" aria-hidden="true" tabindex="-1"></a>     ```bash</span>
<span id="cb62-47"><a href="#cb62-47" aria-hidden="true" tabindex="-1"></a><span class="st">-    git clone https://github.com/Azure/azureml-examples.git --depth 1</span></span>
<span id="cb62-48"><a href="#cb62-48" aria-hidden="true" tabindex="-1"></a><span class="va">+    git clone https://github.com/Azure/azureml-examples.git **depth 1</span></span>
<span id="cb62-49"><a href="#cb62-49" aria-hidden="true" tabindex="-1"></a>     ```</span>
<span id="cb62-50"><a href="#cb62-50" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-51"><a href="#cb62-51" aria-hidden="true" tabindex="-1"></a> 1. Start the notebook server from the directory that contains the clone.</span>
<span id="cb62-52"><a href="#cb62-52" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -66,22 +66,22 @@ The Data Science Virtual Machine (DSVM) is a customized VM image built specifica</span></span>
<span id="cb62-53"><a href="#cb62-53" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-54"><a href="#cb62-54" aria-hidden="true" tabindex="-1"></a> ## Connect to a workspace</span>
<span id="cb62-55"><a href="#cb62-55" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-56"><a href="#cb62-56" aria-hidden="true" tabindex="-1"></a><span class="st">-Some of the samples use `MLClient.from_config()` to connect to a workspace.  For these samples to work, you need a configuration file in a directory on the path to the sample.  </span></span>
<span id="cb62-57"><a href="#cb62-57" aria-hidden="true" tabindex="-1"></a><span class="va">+Some of the samples use `MLClient.from_config()` to connect to a workspace. For these samples to work, you need a configuration file in a directory on the path to the sample. </span></span>
<span id="cb62-58"><a href="#cb62-58" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-59"><a href="#cb62-59" aria-hidden="true" tabindex="-1"></a><span class="st">-The configuration file is created for you on the Azure Machine Learning compute instance.  To use the code on your own notebook server or DSVM, create the configuration file manually.  Use either of the following methods:</span></span>
<span id="cb62-60"><a href="#cb62-60" aria-hidden="true" tabindex="-1"></a><span class="va">+The configuration file is created for you on the Azure Machine Learning compute instance. To use the code on your own notebook server or DSVM, create the configuration file manually. Use either of the following methods:</span></span>
<span id="cb62-61"><a href="#cb62-61" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-62"><a href="#cb62-62" aria-hidden="true" tabindex="-1"></a><span class="st">-* Write a [configuration file](how-to-configure-environment.md#) file (**aml_config/config.json**) in the root of your cloned repository.</span></span>
<span id="cb62-63"><a href="#cb62-63" aria-hidden="true" tabindex="-1"></a><span class="va">+- Write a [configuration file](how-to-configure-environment.md#) file (**aml_config/config.json**) in the root of your cloned repository.</span></span>
<span id="cb62-64"><a href="#cb62-64" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-65"><a href="#cb62-65" aria-hidden="true" tabindex="-1"></a><span class="st">-* Download the workspace configuration file:</span></span>
<span id="cb62-66"><a href="#cb62-66" aria-hidden="true" tabindex="-1"></a><span class="va">+- Download the workspace configuration file:</span></span>
<span id="cb62-67"><a href="#cb62-67" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-68"><a href="#cb62-68" aria-hidden="true" tabindex="-1"></a><span class="st">-    * Sign in to [Azure Machine Learning studio](https://ml.azure.com)</span></span>
<span id="cb62-69"><a href="#cb62-69" aria-hidden="true" tabindex="-1"></a><span class="st">-    * Select your workspace settings in the upper right</span></span>
<span id="cb62-70"><a href="#cb62-70" aria-hidden="true" tabindex="-1"></a><span class="st">-    * Select **Download config file**</span></span>
<span id="cb62-71"><a href="#cb62-71" aria-hidden="true" tabindex="-1"></a><span class="st">-    * Place the file in the root of your cloned repository.</span></span>
<span id="cb62-72"><a href="#cb62-72" aria-hidden="true" tabindex="-1"></a><span class="va">+    - Sign in to [Azure Machine Learning studio](https://ml.azure.com)</span></span>
<span id="cb62-73"><a href="#cb62-73" aria-hidden="true" tabindex="-1"></a><span class="va">+    - Select your workspace settings in the upper right</span></span>
<span id="cb62-74"><a href="#cb62-74" aria-hidden="true" tabindex="-1"></a><span class="va">+    - Select **Download config file**</span></span>
<span id="cb62-75"><a href="#cb62-75" aria-hidden="true" tabindex="-1"></a><span class="va">+    - Place the file in the root of your cloned repository.</span></span>
<span id="cb62-76"><a href="#cb62-76" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-77"><a href="#cb62-77" aria-hidden="true" tabindex="-1"></a>     ![Screenshot of download config.json.](./media/aml-dsvm-server/download-config.png)</span>
<span id="cb62-78"><a href="#cb62-78" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-79"><a href="#cb62-79" aria-hidden="true" tabindex="-1"></a><span class="st">-## Next steps</span></span>
<span id="cb62-80"><a href="#cb62-80" aria-hidden="true" tabindex="-1"></a><span class="va">+## Related resources</span></span>
<span id="cb62-81"><a href="#cb62-81" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb62-82"><a href="#cb62-82" aria-hidden="true" tabindex="-1"></a> Explore the [AzureML-Examples](https://github.com/Azure/azureml-examples) repository to discover what Azure Machine Learning can do.</span>
<span id="cb62-83"><a href="#cb62-83" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-18">Summary</h3>
<div class="sourceCode" id="cb63"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/samples-notebooks.md&quot;</span><span class="fu">,</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;サンプルノートブック記事の更新&quot;</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-24">Explanation</h3>
<p>この変更では、<code>samples-notebooks.md</code>という文書が修正され、16の追加と16の削除が行われました。主な変更点には日付の更新、表現の明確化、コードブロックのフォーマットの改善が含まれています。</p>
<p>具体的には、記事内の「作成日」を2024年2月5日から2024年9月9日に変更し、いくつかの用語を明確にしました。また、従来の文の構造を改善し、指示や説明がより読みやすくなるように調整されています。たとえば、「Data
Science Virtual
Machine」という用語が初めて使用された際にその略称（DSVM）も追加され、理解しやすさが向上しています。</p>
<p>さらに、いくつかの手順がより直感的に表現され、利用者が必要な操作を簡単に把握できるような変更が施されています。これにより、Azure
Machine
Learningのサンプルノートブックを使用する際のユーザーエクスペリエンスが向上します。</p>
<h2 id="item-cbc1da">articles/machine-learning/toc.yml</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb64"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -619,7 +619,7 @@</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>           href: how-to-deploy-models-llama.md</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>     - name: How to deploy JAIS models</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>       href: deploy-jais-models.md</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="st">-    - name: How to deploy Jamba Instruct model</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="va">+    - name: AI21 Jamba models</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>       href: how-to-deploy-models-jamba.md</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>     - name: Regulate deployments using policy</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>       href: how-to-regulate-registry-deployments.md</span></code></pre></div>
</details>
<h3 id="summary-19">Summary</h3>
<div class="sourceCode" id="cb65"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/toc.yml&quot;</span><span class="fu">,</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;トピックの名称更新&quot;</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-25">Explanation</h3>
<p>この変更では、<code>toc.yml</code>ファイルの内容が修正され、特定のトピック名が更新されました。具体的には、「How
to deploy Jamba Instruct model」というトピックが「AI21 Jamba
models」という新しい名称に変更されました。この修正は、トピックの内容がより明確に表現され、最新の情報を反映するために必要でした。</p>
<p>変更は1つの追加と1つの削除に留まり、結果としてトピックのリストが整理され、受け取る印象が向上しています。このような更新は、ユーザーがドキュメントを参照する際に、最新の技術やモデルに関する情報を容易に理解できるよう支援します。</p>
<h2
id="item-990f5d">articles/machine-learning/v1/how-to-deploy-azure-kubernetes-service.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb66"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -1,16 +1,17 @@</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="st">-title: Deploy ML models to Azure Kubernetes Service with CLI and SDK v1</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="va">+title: Deploy ML models to Azure Kubernetes Service - CLI/SDK v1</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a> titleSuffix: Azure Machine Learning</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a> description: &#39;Use CLI (v1) and SDK (v1) to deploy your Azure Machine Learning models as a web service using Azure Kubernetes Service.&#39;</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a> services: machine-learning</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a> ms.service: azure-machine-learning</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a> ms.subservice: inferencing</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a> ms.topic: how-to</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.custom: UpdateFrequency5, deploy, cliv1, sdkv1</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.custom: UpdateFrequency5, deploy, cliv1, sdkv1, FY25Q1-Linter</span></span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a> author: Blackmist</span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a> ms.author: larryfr</span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a> ms.reviewer: bozhlin</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a><span class="st">-ms.date: 03/08/2024</span></span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a><span class="va">+ms.date: 09/09/2024</span></span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a><span class="va">+# Customer Intent: As a data scientist, I want to deploy my machine learning model to Azure Kubernetes Service so that I can scale my model to meet production demands.</span></span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a> ---</span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a> # Deploy a model to an Azure Kubernetes Service cluster with v1</span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -43,7 +44,7 @@ When deploying to AKS, you deploy to an AKS cluster that&#39;s *connected to your wo</span></span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a> - The [Azure CLI extension (v1) for Machine Learning service](reference-azure-machine-learning-cli.md), [Azure Machine Learning Python SDK](/python/api/overview/azure/ml/intro), or the [Azure Machine Learning Visual Studio Code extension](../how-to-setup-vs-code.md).</span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a><span class="st">-    [!INCLUDE [cli v1 deprecation](../includes/machine-learning-cli-v1-deprecation.md)]</span></span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a><span class="va">+    [!INCLUDE [CLI v1 deprecation](../includes/machine-learning-cli-v1-deprecation.md)]</span></span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a> - The Python code snippets in this article assume that the following variables are set:</span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-31"><a href="#cb66-31" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -196,7 +197,7 @@ For more information on the classes, methods, and parameters used in this exampl</span></span>
<span id="cb66-32"><a href="#cb66-32" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-33"><a href="#cb66-33" aria-hidden="true" tabindex="-1"></a> # [Azure CLI](#tab/azure-cli)</span>
<span id="cb66-34"><a href="#cb66-34" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-35"><a href="#cb66-35" aria-hidden="true" tabindex="-1"></a><span class="st">-[!INCLUDE [cli v1](../includes/machine-learning-cli-v1.md)]</span></span>
<span id="cb66-36"><a href="#cb66-36" aria-hidden="true" tabindex="-1"></a><span class="va">+[!INCLUDE [CLI v1](../includes/machine-learning-cli-v1.md)]</span></span>
<span id="cb66-37"><a href="#cb66-37" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-38"><a href="#cb66-38" aria-hidden="true" tabindex="-1"></a> To deploy using the CLI, use the following command. Replace `myaks` with the name of the AKS compute target. Replace `mymodel:1` with the name and version of the registered model. Replace `myservice` with the name to give this service:</span>
<span id="cb66-39"><a href="#cb66-39" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-40"><a href="#cb66-40" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -283,9 +284,9 @@ For information on using VS Code, see [deploy to AKS via the VS Code extension](</span></span>
<span id="cb66-41"><a href="#cb66-41" aria-hidden="true" tabindex="-1"></a> The component that handles autoscaling for Azure Machine Learning model deployments is azureml-fe, which is a smart request router. Since all inference requests go through it, it has the necessary data to automatically scale the deployed models.</span>
<span id="cb66-42"><a href="#cb66-42" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-43"><a href="#cb66-43" aria-hidden="true" tabindex="-1"></a> &gt; [!IMPORTANT]</span>
<span id="cb66-44"><a href="#cb66-44" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; * **Don&#39;t enable Kubernetes Horizontal Pod Autoscaler (HPA) for model deployments**. Doing so causes the two auto-scaling components to compete with each other. Azureml-fe is designed to auto-scale models deployed by Azure Machine Learning, where HPA would have to guess or approximate model utilization from a generic metric like CPU usage or a custom metric configuration.</span></span>
<span id="cb66-45"><a href="#cb66-45" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; * __Don&#39;t enable Kubernetes Horizontal Pod Autoscaler (HPA) for model deployments__. Doing so causes the two auto-scaling components to compete with each other. Azureml-fe is designed to auto-scale models deployed by Azure Machine Learning, where HPA would have to guess or approximate model utilization from a generic metric like CPU usage or a custom metric configuration.</span></span>
<span id="cb66-46"><a href="#cb66-46" aria-hidden="true" tabindex="-1"></a> &gt; </span>
<span id="cb66-47"><a href="#cb66-47" aria-hidden="true" tabindex="-1"></a><span class="st">-&gt; * **Azureml-fe does not scale the number of nodes in an AKS cluster**, because this could lead to unexpected cost increases. Instead, **it scales the number of replicas for the model** within the physical cluster boundaries. If you need to scale the number of nodes within the cluster, you can manually scale the cluster or [configure the AKS cluster autoscaler](/azure/aks/cluster-autoscaler).</span></span>
<span id="cb66-48"><a href="#cb66-48" aria-hidden="true" tabindex="-1"></a><span class="va">+&gt; * __Azureml-fe does not scale the number of nodes in an AKS cluster__, because this could lead to unexpected cost increases. Instead, __it scales the number of replicas for the model__ within the physical cluster boundaries. If you need to scale the number of nodes within the cluster, you can manually scale the cluster or [configure the AKS cluster autoscaler](/azure/aks/cluster-autoscaler).</span></span>
<span id="cb66-49"><a href="#cb66-49" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb66-50"><a href="#cb66-50" aria-hidden="true" tabindex="-1"></a> Autoscaling can be controlled by setting `autoscale_target_utilization`, `autoscale_min_replicas`, and `autoscale_max_replicas` for the AKS web service. The following example demonstrates how to enable autoscaling:</span>
<span id="cb66-51"><a href="#cb66-51" aria-hidden="true" tabindex="-1"></a> </span></code></pre></div>
</details>
<h3 id="summary-20">Summary</h3>
<div class="sourceCode" id="cb67"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/v1/how-to-deploy-azure-kubernetes-service.md&quot;</span><span class="fu">,</span></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;Azure Kubernetes Service への ML モデルのデプロイに関するドキュメントの更新&quot;</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-26">Explanation</h3>
<p>この変更は、<code>how-to-deploy-azure-kubernetes-service.md</code>ファイルにおいて、Azure
Kubernetes
Serviceへの機械学習モデルのデプロイに関する情報を更新するものです。変更内容には、タイトルの修正、日付の更新、新しい顧客の意図を追加したことが含まれています。具体的には、タイトルが「Deploy
ML models to Azure Kubernetes Service with CLI and SDK v1」から「Deploy
ML models to Azure Kubernetes Service - CLI/SDK
v1」に変更されました。</p>
<p>さらに、顧客向けの意図が新たに追加され、データサイエンティストがモデルをデプロイしたい理由が明確化されました。また、いくつかの文面が強調表示されるように修正され、重要な注意事項を目立たせています。</p>
<p>全体として、この変更は、ユーザーが情報をより理解しやすく、関連する機能や注意事項について簡単に把握できるようにすることを目的としています。これにより、Azure
Kubernetes
Serviceを通じたモデルデプロイに関するガイダンスが向上しました。</p>
<h2
id="item-f4b00a">articles/machine-learning/v1/how-to-select-algorithms.md</h2>
<details>
<summary>
Diff
</summary>
<div class="sourceCode" id="cb68"><pre
class="sourceCode diff"><code class="sourceCode diff"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="dt">@@ -54,7 +54,7 @@ The following table summarizes some of the most important characteristics of alg</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a> | --- |:---:|:---:|:---:|:---:| --- |</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a> | **Classification family** | | | | | |</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a> | [Two-class logistic regression](../algorithm-module-reference/two-class-logistic-regression.md?WT.mc_id=docs-article-lazzeri) |Good  |Fast |Yes |4 | |</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="st">-| [Two-class decision forest](../algorithm-module-reference/two-class-decision-forest.md?WT.mc_id=docs-article-lazzeri) |Excellent |Moderate |No |5 |Shows slower scoring times. We suggest not working with One-vs-All Multiclass, because of slower scoring times caused by tread locking in accumulating tree predictions |</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="va">+| [Two-class decision forest](../algorithm-module-reference/two-class-decision-forest.md?WT.mc_id=docs-article-lazzeri) |Excellent |Moderate |No |5 |Shows slower scoring times. We suggest not working with One-vs-All Multiclass, because of slower scoring times caused by thread locking in accumulating tree predictions |</span></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a> | [Two-class boosted decision tree](../algorithm-module-reference/two-class-boosted-decision-tree.md?WT.mc_id=docs-article-lazzeri) |Excellent |Moderate |No |6 |Large memory footprint |</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a> | [Two-class neural network](../algorithm-module-reference/two-class-neural-network.md?WT.mc_id=docs-article-lazzeri) |Good |Moderate |No |8 | |</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a> | [Two-class averaged perceptron](../algorithm-module-reference/two-class-averaged-perceptron.md?WT.mc_id=docs-article-lazzeri) |Good |Moderate |Yes |4 | |</span></code></pre></div>
</details>
<h3 id="summary-21">Summary</h3>
<div class="sourceCode" id="cb69"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;filename&quot;</span><span class="fu">:</span> <span class="st">&quot;articles/machine-learning/v1/how-to-select-algorithms.md&quot;</span><span class="fu">,</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_type&quot;</span><span class="fu">:</span> <span class="st">&quot;minor update&quot;</span><span class="fu">,</span></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">&quot;modification_title&quot;</span><span class="fu">:</span> <span class="st">&quot;アルゴリズム選択に関する表の編集&quot;</span></span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div>
<h3 id="explanation-27">Explanation</h3>
<p>この変更は、<code>how-to-select-algorithms.md</code>ファイルの内容を更新し、特定のアルゴリズムに関する説明を改善しました。主な変更点は、二項分類の決定森林アルゴリズム「Two-class
decision forest」に関する説明の一部が明確化されたことです。</p>
<p>具体的には、コメントが一部形式的に修正され、より整然とした記述になりました。元の文から、単語が誤って使われていたものが修正されただけでなく、スレッドロックに関する文の表現が整理されました。これにより、ユーザーはアルゴリズムのパフォーマンスや特性について、より理解しやすくなっています。</p>
<p>このような微修正は、アルゴリズムの情報の正確性と信頼性を向上させ、データサイエンティストが適切な手法を選択する際の助けとなります。全体として、ドキュメントの整合性が向上し、利用者にとっての価値が増大しています。</p>
</body>
</html>
