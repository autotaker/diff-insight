---
date: '2025-05-23'
permalink: https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:aedda49...MicrosoftDocs:2512fb2
summary: この変更セットは、Azureプラットフォームにおける画像と関連ドキュメントの主な更新を反映しています。新たに複数の画像が追加され、特に画像の言語化やクエリオプション、テキストベクトル化に関する内容が強調されています。また、既存の画像も修正され、最新情報に基づいたビジュアル情報が提供されています。具体的な手順が追加されたことで、ユーザーは機能をより直感的に理解し、操作できるようになりました。全体として、これらの更新はユーザー体験を向上させるために設計されています。
title: Diff Insight Report - search

---

[View Diff on GitHub](https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:aedda49...MicrosoftDocs:2512fb2){target="_blank"}

# Highlights

## New features
- 新しい画像が複数追加され、具体的に画像の言語化、クエリオプション、検索ボタン、データソースの選択に関連する内容が含まれています。加えて、テキストベクトル化に関する新しいタブの画像も含まれます。

## Breaking changes
- 特に大きな破壊的変更はありませんが、一部の画像が削除され、内容の整理が進められた可能性があります。

## Other updates
- 既存の画像が複数修正され、その中にはストア画像やウィザードシナリオにおけるRAGの画像が含まれます。また、関連するドキュメントにも説明の追加や手順の明確化が実施されました。

# Insights
この変更セットは、主にAzureでのさまざまな画像と関連するドキュメントの更新に集中しています。追加された画像は、新しい機能や拡張されたビジュアルサポートを提供することで、ユーザーがシステムをより効果的に利用し、理解できるように設計されています。例えば、画像の言語化やクエリオプション、テキストベクトル化のタブなど、新しいコンセプトや機能がユーザーに視覚的に届くように配慮されています。

既存の画像が更新された点も注目すべきです。これにより、最新情報に対応したビジュアルコンテンツが提供され、特にウィザードシナリオにおけるマルチモーダルRAGのような複雑な機能が、より直感的に理解しやすくなっています。これらはすべて、ユーザーがAzureプラットフォームを利用する際の体験をより快適にするために行われたものです。

さらに、ドキュメントの更新に関しては、説明が強化され、手順がより明確に記載されています。特に、ベクター検索や画像検索のプロセスにおける具体的な手順が追加されたことで、ユーザーがこれらの機能を利用する際の理解が深まります。このような更新により、ユーザーは複雑な操作を直感的に実行しやすくなり、プラットフォームの適応性が高まることが期待されます。

# Summary Table
|  Filename  | Type |    Title    | Status | A  | D  | M  |
|------------|------|-------------|--------|----|----|----|
| [connect-to-your-data.png](#item-20d7ac) | minor update | 画像の修正: データ接続の開始 | modified | 0 | 0 | 0 | 
| [extract-your-content.png](#item-8531c0) | minor update | 画像の修正: コンテンツの抽出 | modified | 0 | 0 | 0 | 
| [image-verbalization-tab.png](#item-93404c) | new feature | 新しい画像の追加: 画像の言語化タブ | added | 0 | 0 | 0 | 
| [image-verbalization-tile.png](#item-e0825f) | new feature | 新しい画像の追加: 画像の言語化タイル | added | 0 | 0 | 0 | 
| [query-options.png](#item-480d4c) | new feature | 新しい画像の追加: クエリオプション | added | 0 | 0 | 0 | 
| [search-button.png](#item-3fb619) | new feature | 新しい画像の追加: 検索ボタン | added | 0 | 0 | 0 | 
| [select-data-source.png](#item-b45b33) | new feature | 新しい画像の追加: データソースの選択 | added | 0 | 0 | 0 | 
| [store-images.png](#item-ecd246) | minor update | 画像の更新: ストア画像 | modified | 0 | 0 | 0 | 
| [text-vectorization-tab.png](#item-da78c7) | new feature | 新しい画像の追加: テキストベクトル化タブ | added | 0 | 0 | 0 | 
| [vectorize-your-text.png](#item-249870) | minor update | 画像の削除: テキストのベクトル化 | removed | 0 | 0 | 0 | 
| [wizard-scenarios-multimodal-rag.png](#item-78df78) | minor update | 画像の更新: ウィザードシナリオ - マルチモーダル RAG | modified | 0 | 0 | 0 | 
| [command-bar.png](#item-99b377) | minor update | 画像の更新: コマンドバー | modified | 0 | 0 | 0 | 
| [wizard-scenarios-rag.png](#item-2d3082) | minor update | 画像の更新: ウィザードシナリオ - RAG | modified | 0 | 0 | 0 | 
| [search-get-started-portal-image-search.md](#item-438b9b) | minor update | ドキュメントの更新: 画像検索の開始方法 | modified | 165 | 67 | 232 | 
| [search-get-started-portal-import-vectors.md](#item-7dae77) | minor update | ドキュメントの更新: ベクター検索の開始方法 | modified | 27 | 15 | 42 | 


# Modified Contents
## articles/search/media/search-get-started-portal-images/connect-to-your-data.png{#item-20d7ac}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "画像の修正: データ接続の開始"
}
```

### Explanation
このコードの変更は、特定の画像ファイルが更新されたことを示しています。具体的には、`articles/search/media/search-get-started-portal-images/connect-to-your-data.png` というファイルが修正されましたが、実際の変更内容（追加、削除、変更）はないため、内容そのものは変更されていません。リンクを介して、画像の元の場所を参照できるため、今後の更新や修正が容易になるでしょう。この更新は、ユーザーがデータ接続に関する情報を視覚的に理解するための重要なリソースの一部として機能します。

## articles/search/media/search-get-started-portal-images/extract-your-content.png{#item-8531c0}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "画像の修正: コンテンツの抽出"
}
```

### Explanation
このコードの変更は、特定の画像ファイルが更新されたことを示しています。ファイル名は `articles/search/media/search-get-started-portal-images/extract-your-content.png` で、修正は行われたものの、具体的には追加、削除、さらには内容の変更はありません。この画像は、コンテンツ抽出に関する情報を視覚的に提示するための重要なリソースであり、リンクを介して画像を直接確認することができます。この更新により、ユーザーに対してコンテンツ抽出の理解を深めるための参考資料が引き続き利用可能となります。

## articles/search/media/search-get-started-portal-images/image-verbalization-tab.png{#item-93404c}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "新しい画像の追加: 画像の言語化タブ"
}
```

### Explanation
このコードの変更は、新しい画像ファイルが追加されたことを示しています。追加されたファイルは `articles/search/media/search-get-started-portal-images/image-verbalization-tab.png` であり、特定の機能や情報を視覚的にサポートする役割を担っています。この画像は、ユーザーが画像の言語化タブに関連する内容を理解するための大切なリソースとなります。画像は直接リンクされており、ユーザーはその内容を簡単に参照することができます。この追加により、ユーザーエクスペリエンスが向上し、関連する情報がより明確に提供されるでしょう。

## articles/search/media/search-get-started-portal-images/image-verbalization-tile.png{#item-e0825f}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "新しい画像の追加: 画像の言語化タイル"
}
```

### Explanation
このコードの変更は、新しい画像ファイルが追加されたことを示しています。追加されたファイルは `articles/search/media/search-get-started-portal-images/image-verbalization-tile.png` で、画像の言語化に関連する機能を視覚的にサポートするために作成されたものです。この画像は、ユーザーが言語化タイルの機能を理解するのに役立ちます。画像は直接リンクされており、ユーザーはその内容を容易に確認することができます。この新しい追加により、関連情報が強化され、ユーザーの学習体験が向上することが期待されます。

## articles/search/media/search-get-started-portal-images/query-options.png{#item-480d4c}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "新しい画像の追加: クエリオプション"
}
```

### Explanation
このコードの変更は、新しい画像ファイルが追加されたことを示しています。追加されたファイルは `articles/search/media/search-get-started-portal-images/query-options.png` であり、クエリオプションに関する情報を視覚的に補足する目的があります。この画像は、ユーザーがクエリオプションの使用方法やその仕組みをより良く理解できるように設計されています。画像へのリンクが提供されており、ユーザーは直接その内容を確認することができます。この新しい追加によって、関連トピックの説明が強化され、ユーザーの理解を助けることが期待されます。

## articles/search/media/search-get-started-portal-images/search-button.png{#item-3fb619}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "新しい画像の追加: 検索ボタン"
}
```

### Explanation
このコードの変更は、新しい画像ファイルが追加されたことを示しています。追加されたファイルは `articles/search/media/search-get-started-portal-images/search-button.png` で、検索ボタンのイメージを提供することで、ユーザーが検索機能を利用する際の視覚的ガイダンスを強化します。この画像は、ユーザーが検索ボタンの位置や外観を理解しやすくするために配置されており、その内容を簡単に確認できるリンクが提供されています。この新しい追加により、ドキュメントの視覚的な要素が強化され、ユーザーの利便性が向上することが期待されます。

## articles/search/media/search-get-started-portal-images/select-data-source.png{#item-b45b33}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "新しい画像の追加: データソースの選択"
}
```

### Explanation
このコードの変更は、新しい画像ファイルが追加されたことを示しています。追加されたファイルは `articles/search/media/search-get-started-portal-images/select-data-source.png` で、データソースの選択に関するビジュアルガイドを提供します。この画像は、ユーザーが適切なデータソースを選択する手順を理解しやすくするために役立ちます。また、この画像へのリンクも提供されており、ユーザーはその内容を直接確認することができます。新たに追加された画像によって、ドキュメントの内容が豊かになり、特定の手続きの理解を容易にすることが期待されています。

## articles/search/media/search-get-started-portal-images/store-images.png{#item-ecd246}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "画像の更新: ストア画像"
}
```

### Explanation
このコードの変更は、画像ファイル `articles/search/media/search-get-started-portal-images/store-images.png` に対する修正を示しています。この画像は、ストアに関連するビジュアルコンテンツを提供しており、ユーザーがストア機能を理解する際に役立つものです。変更の具体的な内容は示されていませんが、リンク先から画像の最新のビジュアルを確認することができます。更新により、ドキュメントの一貫性と正確性が向上し、ユーザーが探している情報にアクセスしやすくすることが期待されます。

## articles/search/media/search-get-started-portal-images/text-vectorization-tab.png{#item-da78c7}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "新しい画像の追加: テキストベクトル化タブ"
}
```

### Explanation
このコードの変更は、新しい画像ファイル `articles/search/media/search-get-started-portal-images/text-vectorization-tab.png` が追加されたことを示しています。この画像はテキストベクトル化に関連するタブを示しており、ユーザーがその機能を視覚的に理解するのに役立ちます。ビジュアルコンテンツの追加により、ドキュメントの内容が強化され、特定の機能や操作の理解が促進されることが期待されます。追加された画像には直接リンクが提供されており、ユーザーはその内容を容易に確認することができます。

## articles/search/media/search-get-started-portal-images/vectorize-your-text.png{#item-249870}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "画像の削除: テキストのベクトル化"
}
```

### Explanation
このコードの変更は、画像ファイル `articles/search/media/search-get-started-portal-images/vectorize-your-text.png` が削除されたことを示しています。削除された画像はテキストのベクトル化に関連するものであり、元々はドキュメント内でその機能を視覚的に説明するために使用されていました。画像が削除されたことで、コンテンツの整理や更新が進められることになりますが、代わりに関連する情報や図が別の方法で提供される可能性があります。この変更により、内容の一貫性が保たれることを期待しています。

## articles/search/media/search-get-started-portal-images/wizard-scenarios-multimodal-rag.png{#item-78df78}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "画像の更新: ウィザードシナリオ - マルチモーダル RAG"
}
```

### Explanation
このコードの変更は、画像ファイル `articles/search/media/search-get-started-portal-images/wizard-scenarios-multimodal-rag.png` が更新されたことを示しています。この画像はウィザードシナリオにおけるマルチモーダル RAG（Retrieval-Augmented Generation）に関連するもので、以前のものと比べて内容の改良や視覚的表現の見直しが行われた可能性があります。画像の更新により、ユーザーがこの機能をより理解しやすくなり、ドキュメントの全体的な質が向上することが期待されます。変更された画像のリンクも提供されており、ユーザーは最新の内容を確認することができます。

## articles/search/media/search-get-started-portal-import-vectors/command-bar.png{#item-99b377}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "画像の更新: コマンドバー"
}
```

### Explanation
このコードの変更は、画像ファイル `articles/search/media/search-get-started-portal-import-vectors/command-bar.png` が更新されたことを示しています。この画像はコマンドバーに関連するもので、機能や使用法のビジュアルガイドとして重要です。更新が行われたことにより、ユーザーは最新のインターフェースや操作手順をより正確に理解できるようになります。画像には具体的な変更内容は記載されていませんが、一般的にこのような更新は視覚的な明瞭さや使いやすさを向上させるために行われます。更新された画像のリンクも提供されており、ユーザーは新しい内容を簡単に確認することができます。

## articles/search/media/search-get-started-portal-import-vectors/wizard-scenarios-rag.png{#item-2d3082}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "画像の更新: ウィザードシナリオ - RAG"
}
```

### Explanation
このコードの変更は、画像ファイル `articles/search/media/search-get-started-portal-import-vectors/wizard-scenarios-rag.png` が更新されたことを示しています。この画像はウィザードシナリオにおけるRAG（Retrieval-Augmented Generation）の利用方法を示しており、ユーザーがこの機能を理解する助けとなる重要なビジュアルリソースです。更新により、画像の内容や視覚的表現が改善され、ユーザーにとってより親しみやすく、わかりやすい情報提供が行われたことが期待されます。リンクが提供されているため、ユーザーは最新の画像を直接確認することができます。

## articles/search/search-get-started-portal-image-search.md{#item-438b9b}

<details>
<summary>Diff</summary>
````diff
@@ -1,33 +1,33 @@
 ---
 title: "Quickstart: Multimodal Search in the Azure portal"
 titleSuffix: Azure AI Search
-description: Learn how to search for multimodal content on an Azure AI Search index in the Azure portal. Run a wizard to vectorize text and images, and then use Search Explorer to provide multimodal content as your query input.
+description: Learn how to search for multimodal content on an Azure AI Search index in the Azure portal. Run a wizard to generate natural-language descriptions of images and vectorize both text and images, and then use Search Explorer to query your multimodal index.
 author: haileytap
 ms.author: haileytapia
 ms.service: azure-ai-search
 ms.topic: quickstart
-ms.date: 05/12/2025
+ms.date: 05/22/2025
 ms.custom:
   - references_regions
 ---
 
 # Quickstart: Search for multimodal content in the Azure portal
 
-In this quickstart, you use the **Import and vectorize data wizard** in the Azure portal to get started with [multimodal search](multimodal-search-overview.md). Multimodality refers to the ability to process and query over multiple types of data, such as text and images.
+In this quickstart, you use the **Import and vectorize data** wizard in the Azure portal to get started with [multimodal search](multimodal-search-overview.md). The wizard simplifies the process of extracting page text and inline images from documents, describing images in natural language, vectorizing image descriptions and text, and storing images for later retrieval.
 
 The sample data consists of a multimodal PDF in the [azure-search-sample-data](https://github.com/Azure-Samples/azure-search-sample-data/tree/main/sustainable-ai-pdf) repo, but you can use different files and still follow this quickstart.
 
 ## Prerequisites
 
 + An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F).
 
-+ An [Azure Storage account](/azure/storage/common/storage-account-create) to store files as blobs. Use Azure Blob Storage or Azure Data Lake Storage Gen2 (a storage account with a hierarchical namespace) on a standard performance (general-purpose v2) account. Access tiers can be hot, cool, or cold.
++ An [Azure Storage account](/azure/storage/common/storage-account-create). Use Azure Blob Storage or Azure Data Lake Storage Gen2 (storage account with a hierarchical namespace) on a standard performance (general-purpose v2) account. Access tiers can be hot, cool, or cold.
 
-+ An [Azure AI services multi-service account](/azure/ai-services/multi-service-resource#azure-ai-services-resource-for-azure-ai-search-skills) for image vectorization, which requires the Azure AI Vision multimodal embeddings. For regional availability, see the [Azure AI Vision documentation](/azure/ai-services/computer-vision/overview-image-analysis#region-availability).
++ An [Azure AI services multi-service account](/azure/ai-services/multi-service-resource#azure-ai-multi-services-resource-for-azure-ai-search-skills) in East US, West Europe, or North Central US.
 
-+ An [Azure AI Search service](search-create-service-portal.md) for indexing and queries. Your service can be on any tier, but it must be in the [same region as your Azure AI multi-service account](search-create-service-portal.md#regions-with-the-most-overlap).
++ An [Azure AI Search service](search-create-service-portal.md) in the same region as your Azure AI multi-service account.
 
-  + The pricing tier determines how many blobs you can index. We used the free tier to create this quickstart and limited the content to one PDF.
++ An [Azure OpenAI resource](/azure/ai-services/openai/how-to/create-resource).
 
 + Familiarity with the wizard. See [Import data wizards in the Azure portal](search-import-data-portal.md).
 
@@ -37,106 +37,204 @@ All of the preceding resources must have public access enabled so that the Azure
 
 If private endpoints are already present and you can't disable them, the alternative is to run the respective end-to-end flow from a script or program on a virtual machine. The virtual machine must be on the same virtual network as the private endpoint. [Here's a Python code sample](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-python/code/integrated-vectorization) for integrated vectorization. The same [GitHub repo](https://github.com/Azure/azure-search-vector-samples/tree/main) has samples in other programming languages.
 
-### Role-based access
+### Check for space
 
-A free search service supports role-based access control on connections to Azure AI Search, but it doesn't support managed identities on outbound connections to Azure Storage or Azure AI Vision. This level of support means you must use key-based authentication on connections between a free search service and other Azure services. For more secure connections:
+If you're starting with the free service, you're limited to three indexes, three data sources, three skillsets, and three indexers. Make sure you have room for extra items before you begin. This quickstart creates one of each object.
 
-+ Use the Basic tier or higher.
+## Configure access
 
-+ [Configure a system-assigned managed identity](search-howto-managed-identities-data-sources.md#create-a-system-managed-identity) and role assignments to admit requests from Azure AI Search on other Azure services.
+Before you begin, make sure you have permissions to access content and operations. We recommend Microsoft Entra ID authentication and role-based access for authorization. You must be an **Owner** or **User Access Administrator** to assign roles. If roles aren't feasible, you can use [key-based authentication](search-security-api-keys.md) instead.
 
-### Check for space
+Configure access to each resource identified in this section.
 
-If you're starting with the free service, you're limited to three indexes, three data sources, three skillsets, and three indexers. Make sure you have room for extra items before you begin. This quickstart creates one of each object.
+### [**Azure AI Search**](#tab/search-perms)
+
+Azure AI Search provides the multimodal pipeline. Configure access for yourself and your search service to read data, run the pipeline, and interact with other Azure resources.
+
+On your Azure AI Search service:
+
+1. [Enable role-based access](search-security-enable-roles.md).
+
+1. [Configure a system-assigned managed identity](search-howto-managed-identities-data-sources.md#create-a-system-managed-identity).
+
+1. [Assign the following roles](search-security-rbac.md) to yourself:
+
+   + **Search Service Contributor**
+
+   + **Search Index Data Contributor**
+
+   + **Search Index Data Reader**
+
+### [**Azure Storage**](#tab/storage-perms)
+
+Azure Storage is both the data source for your documents and the destination for extracted images. Your search service requires access to these storage containers, which you create in the next section of this quickstart.
+
+On your Azure Storage account:
+
++ Assign **Storage Blob Data Contributor** to your [search service identity](search-howto-managed-identities-data-sources.md#create-a-system-managed-identity).
+
+### [**Azure AI services**](#tab/ai-services-perms)
+
+An Azure AI multi-service account provides multiple Azure AI services, including [Azure AI Document Intelligence](/azure/ai-services/document-intelligence/overview) for content extraction and semantic chunking. Your search service requires access to call the [Document Layout skill](cognitive-search-skill-document-intelligence-layout.md).
+
+On your Azure AI multi-service account:
+
++ Assign **Cognitive Services User** to your [search service identity](search-howto-managed-identities-data-sources.md#create-a-system-managed-identity).
+
+### [**Azure OpenAI**](#tab/openai-perms)
+
+Azure OpenAI provides large language models (LLMs) for image verbalization and embedding models for text and image vectorization. Your search service requires access to call the [GenAI Prompt skill](cognitive-search-skill-genai-prompt.md) and [Azure OpenAI Embedding skill](cognitive-search-skill-azure-openai-embedding.md).
+
+On your Azure OpenAI resource:
+
++ Assign **Cognitive Services OpenAI User** to your [search service identity](search-howto-managed-identities-data-sources.md#create-a-system-managed-identity).
+
+---
 
 ## Prepare sample data
 
 This quickstart uses a sample multimodal PDF, but you can also use your own files. If you're on a free search service, use fewer than 20 files to stay within the free quota for enrichment processing.
 
 To prepare the sample data for this quickstart:
 
-1. Sign in to the [Azure portal](https://portal.azure.com/) and go to your Azure Storage account.
+1. Sign in to the [Azure portal](https://portal.azure.com/) and select your Azure Storage account.
 
 1. From the left pane, select **Data storage** > **Containers**.
 
 1. Create a container, and then upload the [sample PDF](https://github.com/Azure-Samples/azure-search-sample-data/blob/main/sustainable-ai-pdf/Accelerating-Sustainability-with-AI-2025.pdf) to the container.
 
 1. Create another container to store images extracted from the PDF.
 
-## Start the wizard
+## Deploy models
+
+The wizard requires an LLM to verbalize images and an embedding model to generate vector representations of text and verbalized text content. Both models are available through Azure OpenAI.
+
+To deploy the models for this quickstart:
+
+1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com) and select your Azure OpenAI resource.
+
+1. From the left pane, select **Model catalog**.
 
-If your Azure AI Search service and Azure AI multi-service account are in the [same region](/azure/ai-services/computer-vision/how-to/image-retrieval) and tenant, and if your Azure Storage blob container has the default configuration, you're ready to proceed.
+1. Deploy one of the following LLMs:
+
+   + gpt-4o
+
+   + gpt-4o-mini
+
+1. Deploy one of the following embedding models:
+
+   + text-embedding-ada-002
+
+   + text-embedding-3-small
+
+   + text-embedding-3-large
+
+## Start the wizard
 
 To start the wizard for multimodal search:
 
-1. Sign in to the [Azure portal](https://portal.azure.com/) and go to your Azure AI Search service.
+1. Sign in to the [Azure portal](https://portal.azure.com/) and select your Azure AI Search service.
 
 1. On the **Overview** page, select **Import and vectorize data**.
 
    :::image type="content" source="media/search-get-started-portal-import-vectors/command-bar.png" alt-text="Screenshot of the command to open the wizard for importing and vectorizing data.":::
 
 1. Select your data source: **Azure Blob Storage** or **Azure Data Lake Storage Gen2**.
 
-1. Select the **Multimodal RAG** tile.
+   :::image type="content" source="media/search-get-started-portal-images/select-data-source.png" alt-text="Screenshot of the options for selecting a data source in the wizard." border="true" lightbox="media/search-get-started-portal-images/select-data-source.png":::
+
+1. Select **Multimodal RAG**.
 
    :::image type="content" source="media/search-get-started-portal-images/wizard-scenarios-multimodal-rag.png" alt-text="Screenshot of the Multimodal RAG tile in the wizard." border="true" lightbox="media/search-get-started-portal-images/wizard-scenarios-multimodal-rag.png":::
 
 ## Connect to your data
 
-Azure AI Search requires a connection to the data source that contains the sample data. In this case, the data source is an Azure Storage account.
+Azure AI Search requires a connection to a data source for content ingestion and indexing. In this case, the data source is your Azure Storage account.
+
+To connect to your data:
 
-To connect to your data source:
+1. On the **Connect to your data** page, specify your Azure subscription.
 
-1. On the **Connect to your data** page, specify the Azure subscription.
+1. Select the storage account and container to which you uploaded the sample data.
 
-1. Select the storage account and container that provide the data. Use the default values for the remaining boxes.
+1. Select the **Authenticate using managed identity** checkbox. Leave the identity type as **System-assigned**.
 
    :::image type="content" source="media/search-get-started-portal-images/connect-to-your-data.png" alt-text="Screenshot of the wizard page for setting up a data connection." border="true" lightbox="media/search-get-started-portal-images/connect-to-your-data.png":::
 
 1. Select **Next**.
 
 ## Extract your content
 
-The next step is to select a method for document cracking and chunking. The default method uses the [Document Extraction skill](cognitive-search-skill-document-extraction.md) to extract content and metadata from documents, which includes generating normalized images. The [Text Split skill](cognitive-search-skill-textsplit.md) is then used to split the extracted content into pages.
+The next step is to select a method for document cracking and chunking.
+
+Your Azure AI multi-service account provides access to the [Document Layout skill](cognitive-search-skill-document-intelligence-layout.md), which extracts page numbers, bounding polygons, and other location metadata from both text and images. The Document Layout skill also breaks documents into smaller, more manageable chunks.
+
+To use the Document Layout skill:
 
-To use the default extraction method:
+1. On the **Content extraction** page, select **AI Document Intelligence**.
 
-1. On the **Content extraction** page, select the **Default** tile.
+1. Specify your Azure subscription and Azure AI multi-service account.
+
+1. For the authentication type, select **System assigned identity**.
+
+1. Select the checkbox that acknowledges the billing effects of using these resources.
 
    :::image type="content" source="media/search-get-started-portal-images/extract-your-content.png" alt-text="Screenshot of the wizard page for selecting a content extraction method." border="true" lightbox="media/search-get-started-portal-images/extract-your-content.png":::
 
 1. Select **Next**.
 
 ## Embed your content
 
-If the raw content includes text, or if the Document Extraction skill produces text, the wizard calls the [Azure AI Vision multimodal embeddings skill](cognitive-search-skill-vision-vectorize.md) to vectorize the text. The same embedding skill is used to generate vector representations of images.
+During this step, the wizard calls two skills to generate descriptive text for images (image verbalization) and vector embeddings for text and images.
+
+For image verbalization, the [GenAI Prompt skill](cognitive-search-skill-genai-prompt.md) uses the LLM you deployed to analyze each extracted image and produce a natural-language description.
 
-The wizard also calls the [Shaper skill](cognitive-search-skill-shaper.md) to enrich the output with metadata, such as page numbers. This metadata is useful for associating vectorized content with its original context in the document.
+For text and image embeddings, the [Azure OpenAI Embedding skill](cognitive-search-skill-azure-openai-embedding.md) uses the embedding model you deployed to convert the text chunks and verbalized descriptions into high-dimensional vectors. These vectors enable similarity and hybrid retrieval.
 
-To generate embeddings for your text and images:
+To use the GenAI Prompt skill and Azure OpenAI Embedding skill:
 
-1. On the **Content embedding** page, select the **Multimodal Embedding** tile.
+1. On the **Content embedding** page, select **Image Verbalization**.
 
-1. Select **AI Vision vectorization** for the embedding kind. If it's unavailable, make sure your Azure AI Search service and Azure AI multi-service account are both in a region that [supports the AI Vision multimodal APIs](/azure/ai-services/computer-vision/how-to/image-retrieval).
+   :::image type="content" source="media/search-get-started-portal-images/image-verbalization-tile.png" alt-text="Screenshot of the Image Verbalization tile in the wizard." border="true" lightbox="media/search-get-started-portal-images/image-verbalization-tile.png":::
 
-1. Specify the subscription, multi-service account, and authentication type.
+1. On the **Image Verbalization** tab:
 
-1. Select the checkbox that acknowledges the billing effects of using this resource.
+   1. For the kind, select **Azure OpenAI**.
 
-   :::image type="content" source="media/search-get-started-portal-images/vectorize-your-text.png" alt-text="Screenshot of the wizard page for vectorizing text and images." border="true" lightbox="media/search-get-started-portal-images/vectorize-your-text.png":::
+   1. Specify your Azure subscription, Azure OpenAI resource, and LLM deployment.
+
+   1. For the authentication type, select **System assigned identity**.
+
+   1. Select the checkbox that acknowledges the billing effects of using these resources.
+
+      :::image type="content" source="media/search-get-started-portal-images/image-verbalization-tab.png" alt-text="Screenshot of the wizard page for verbalizing images." border="true" lightbox="media/search-get-started-portal-images/image-verbalization-tab.png":::
+
+1. On the **Text Vectorization** tab:
+
+   1. For the kind, select **Azure OpenAI**.
+
+   1. Specify your Azure subscription, Azure OpenAI resource, and embedding model deployment.
+
+   1. For the authentication type, select **System assigned identity**.
+
+   1. Select the checkbox that acknowledges the billing effects of using these resources.
+
+      :::image type="content" source="media/search-get-started-portal-images/text-vectorization-tab.png" alt-text="Screenshot of the wizard page for vectorizing text and images." border="true" lightbox="media/search-get-started-portal-images/text-vectorization-tab.png":::
 
 1. Select **Next**.
 
 ## Store the extracted images
 
-The next step is to save any images extracted from your documents in Azure Storage. In Azure AI Search, this is known as a knowledge store.
+The next step is to send images extracted from your documents to Azure Storage. In Azure AI Search, this secondary storage is known as a [knowledge store](knowledge-store-concept-intro.md).
 
 To store the extracted images:
 
-1. On the **Image output** page, specify the subscription.
+1. On the **Image output** page, specify your Azure subscription.
 
 1. Select the storage account and blob container you created to store the images.
 
+1. Select the **Authenticate using managed identity** checkbox. Leave the identity type as **System-assigned**.
+
    :::image type="content" source="media/search-get-started-portal-images/store-images.png" alt-text="Screenshot of the wizard page for storing the extracting images." border="true" lightbox="media/search-get-started-portal-images/store-images.png":::
 
 1. Select **Next**.
@@ -150,39 +248,42 @@ On the **Advanced settings** page, you can optionally add fields to the index sc
 | content_id | Text and image vectors | String field. Document key for the index. | Searchable, retrievable, sortable, filterable, and facetable. |
 | document_title | Text and image vectors | String field. Human-readable document title, page title, or page number. | Searchable, retrievable, sortable, filterable, and facetable. |
 | text_document_id | Text vectors | String field. Identifies the parent document from which the text chunk originates. | Retrievable and filterable. |
-| image_document_id | Image vectors | String field. Identifies the parent document from which the image chunk originates. | Searchable, retrievable, sortable, filterable, and facetable. |
+| image_document_id | Image vectors | String field. Identifies the parent document from which the image originates. | Searchable, retrievable, sortable, filterable, and facetable. |
 | content_text | Text vectors | String field. Human-readable version of the text chunk. | Searchable, retrievable, sortable, filterable, and facetable. |
-| content_embedding | Image vectors | Collection(Edm.Single). Vector representation of the image chunk. | Searchable and retrievable. |
+| content_embedding | Image vectors | Collection(Edm.Single). Vector representation of the image verbalization. | Searchable and retrievable. |
 | content_path | Text and image vectors | String field. Path to the content in the storage container. | Retrievable, sortable, filterable, and facetable. |
 | locationMetadata | Text and image vectors | Edm.ComplexType. Contains metadata about the content's location. | Varies by field. |
 
 You can't modify the generated fields or their attributes, but you can add fields if your data source provides them. For example, Azure Blob Storage provides a collection of metadata fields.
 
 To add fields to the index schema:
 
-1. Select **Add new**.
+1. Under **Index fields**, select **Preview and edit**.
 
-1. Select a source field from the list of available fields, provide a field name for the index, and accept the default data type or override as needed.
+1. Select **Add field**.
 
-   + Metadata fields are searchable but not retrievable, filterable, facetable, or sortable.
+1. Select a source field from the available fields, enter a field name for the index, and accept (or override) the default data type.
 
-1. Select **Reset** if you want to restore the schema to its original version.
+   > [!NOTE]
+   > Metadata fields are searchable but not retrievable, filterable, facetable, or sortable.
+
+1. If you want to restore the schema to its original version, select **Reset**.
 
 ## Schedule indexing
 
-For data sources where the underlying data is volatile, you can schedule indexing to capture changes at specific intervals or specific dates and times.
+For data sources where the underlying data is volatile, you can [schedule indexing](search-howto-schedule-indexers.md) to capture changes at specific intervals or specific dates and times.
 
 To schedule indexing:
 
-1. On the **Advanced settings** page, under **Schedule indexing**, specify a [run schedule](search-howto-schedule-indexers.md) for the indexer. We recommend **Once** for this quickstart.
+1. On the **Advanced settings** page, under **Schedule indexing**, specify a run schedule for the indexer. We recommend **Once** for this quickstart.
 
    :::image type="content" source="media/search-get-started-portal-images/run-once.png" alt-text="Screenshot of the wizard page for scheduling indexing." border="true" lightbox="media/search-get-started-portal-images/run-once.png":::
 
 1. Select **Next**.
 
 ## Finish the wizard
 
-The final step is to review your configuration and create the objects required for multimodal search. If necessary, return to previous pages in the wizard to adjust your configuration.
+The final step is to review your configuration and create the necessary objects for multimodal search. If necessary, return to the previous pages in the wizard to adjust your configuration.
 
 To finish the wizard:
 
@@ -202,52 +303,49 @@ When the wizard completes the configuration, it creates the following objects:
 
 + A skillset with the following skills:
 
-  + The [Document Extraction skill](cognitive-search-skill-document-extraction.md) extracts both text and images from the documents.
+  + The [Document Layout skill](cognitive-search-skill-document-intelligence-layout.md) splits documents into text chunks and extracts images with location data.
 
-  + The [Text Split skill](cognitive-search-skill-textsplit.md) adds data chunking.
+  + The [GenAI Prompt skill](cognitive-search-skill-genai-prompt.md) generates natural-language descriptions (verbalizations) of images.
 
-  + The [Azure AI Vision multimodal embeddings skill](cognitive-search-skill-vision-vectorize.md) vectorizes text produced by the Document Extraction skill.
+  + The [Azure OpenAI Embedding skill](cognitive-search-skill-azure-openai-embedding.md) vectorizes each text chunk.
 
-  + The [Azure AI Vision multimodal embeddings skill](cognitive-search-skill-vision-vectorize.md) is called again to vectorize images.
+  + The [Azure OpenAI Embedding skill](cognitive-search-skill-azure-openai-embedding.md) is called again to vectorize each image verbalization.
 
   + The [Shaper skill](cognitive-search-skill-shaper.md) enriches the output with metadata and creates new images with contextual information.
 
-## Check results
+> [!TIP]
+> Wizard-created objects have configurable JSON definitions. To view or modify these definitions, select **Search management** from the left pane, where you can view your indexes, indexers, data sources, and skillsets.
 
-Search Explorer accepts text, images, and vectors as query inputs. For images, Search Explorer vectorizes the image and sends the vector as a query input to the search engine. Image vectorization assumes that your index has a vectorizer definition, which the **Import and vectorize data wizard** creates based on your embedding model inputs.
-
-The following steps assume that you're searching for images. For the other two query types, see [Quickstart: Keyword search](search-get-started-portal.md#query-with-search-explorer) and [Quickstart: Vector search](search-get-started-portal-import-vectors.md#check-results).
-
-To use Search Explorer for image search:
+## Check results
 
-1. Sign in to the [Azure portal](https://portal.azure.com/) and go to your Azure AI Search service.
+This quickstart creates a multimodal index that supports [hybrid search](hybrid-search-overview.md) over both text and verbalized images. However, it doesn't support images as query inputs, which requires integrated vectorization using an embedding skill and an equivalent vectorizer. For more information, see [Query with Search explorer](search-explorer.md).
 
-1. From the left pane, select **Search management** > **Indexes**, and then select the index you created.
+Hybrid search is a combination of full-text queries and vector queries. When you issue a hybrid query, the search engine computes the semantic similarity between your query and the indexed vectors and ranks the results accordingly. For the index created in this quickstart, the results surface content from the `content_text` field that closely aligns with your query.
 
-1. Select the **Search explorer** tab.
+To query your multimodal index:
 
-1. From the **View** menu, select **Image view**.
+1. Sign in to the [Azure portal](https://portal.azure.com/) and select your Azure AI Search service.
 
-   :::image type="content" source="media/search-get-started-portal-images/select-image-view.png" alt-text="Screenshot of the command for selecting image view." border="true" lightbox="media/search-get-started-portal-images/select-image-view.png":::
+1. From the left pane, select **Search management** > **Indexes**.
 
-1. Drag or select a [sample PNG](https://github.com/Azure-Samples/azure-search-sample-data/blob/main/sustainable-ai-pdf) from your local folder. The PNGs come directly from the sample PDF used in this quickstart.
+1. Select your index.
 
-1. Select **Search** to run the query.
+1. Select **Query options**, and then select **Hide vector values in search results**. This step makes the results more readable.
 
-   The top match should be the image for which you searched. Because a [vector search](vector-search-overview.md) matches on similar vectors, the search engine returns any document that's sufficiently similar to the query input, up to the `k` number of results. For more advanced queries that include relevance tuning, switch to the JSON view.
+   :::image type="content" source="media/search-get-started-portal-images/query-options.png" alt-text="Screenshot of the Query Options menu in Search Explorer." border="true" lightbox="media/search-get-started-portal-images/query-options.png":::
 
-   :::image type="content" source="media/search-get-started-portal-images/image-search.png" alt-text="Screenshot of the search results for image search." border="true" lightbox="media/search-get-started-portal-images/image-search.png":::
+1. Enter text for which you want to search. Our example uses `energy`.
 
-1. Try other query options to compare search outcomes:
+1. To run the query, select **Search**.
 
-   + (Recommended) Hide vectors for more readable results.
+   :::image type="content" source="media/search-get-started-portal-images/search-button.png" alt-text="Screenshot of the Search button in Search Explorer." border="true" lightbox="media/search-get-started-portal-images/search-button.png":::
 
-   + Select a vector field to query over. The default is text vectors, but you can specify the image vector to exclude text vectors from query execution.
+   The results should include text and image content related to `energy` in your index. Highlights from relevant passages and image verbalizations appear in `@search.captions`, helping you quickly identify matches to your query.
 
 ## Clean up resources
 
 This quickstart uses billable Azure resources. If you no longer need the resources, delete them from your subscription to avoid charges.
 
 ## Next step
 
-This quickstart introduced you to the **Import and vectorize data wizard**, which creates all of the necessary objects for multimodal search. To explore each step in detail, see [Tutorial: Index mixed content using multimodal embeddings and the Document Extraction skill](tutorial-multimodal-indexing-with-embedding-and-doc-extraction.md).
+This quickstart introduced you to the **Import and vectorize data wizard**, which creates all of the necessary objects for multimodal search. To explore each step in detail, see [Tutorial: Index mixed content using image verbalizations and the Document Layout skill](tutorial-multimodal-index-image-verbalization-skill.md).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "ドキュメントの更新: 画像検索の開始方法"
}
```

### Explanation
このコードの変更は、`articles/search/search-get-started-portal-image-search.md` というマークダウンファイルに対して行われた重要な更新を示しています。この更新では、主に以下の内容が改善されました。

1. **説明文の強化**: 説明に、画像の自然言語による記述生成や、テキストと画像のベクトル化についてより詳細に記述されるようになりました。これにより、ユーザーがこのセクションで学ぶべきことの理解が深まります。

2. **手順の明確化**: ユーザーがウィザードを使用してプロセスを進める際の各ステップがより明確になり、以前よりも扱いやすくなっています。特に、必要なリソースや設定手順が具体的に示されています。

3. **新しい機能の説明**: ドキュメントにおいて、Azure AIの新機能であるGenAI Prompt skillやその他のスキルについても説明が追加され、最新の情報が反映されています。

4. **日付の更新**: 記事内の日付が更新され、現在の情報に基づいてその正確性を保っています。

この更新により、ユーザーはマルチモーダル検索に関するより多くの情報と最新の変更を明確に理解できるようになるため、Azureプラットフォームをより効果的に活用できるようになります。リンクも提供されており、ユーザーは適切なリソースに簡単にアクセスできます。

## articles/search/search-get-started-portal-import-vectors.md{#item-7dae77}

<details>
<summary>Diff</summary>
````diff
@@ -1,5 +1,5 @@
 ---
-title: "Quickstart: Vector Search in the Azure Portal"
+title: "Quickstart: Vector Search in the Azure portal"
 titleSuffix: Azure AI Search
 description: Learn how to use a wizard to automate data chunking and vectorization in a search index.
 author: haileytap
@@ -9,12 +9,12 @@ ms.custom:
   - build-2024
   - ignite-2024
 ms.topic: quickstart
-ms.date: 05/12/2025
+ms.date: 05/22/2025
 ---
 
 # Quickstart: Vectorize text in the Azure portal
 
-In this quickstart, you use the **Import and vectorize data wizard** in the Azure portal to get started with [integrated vectorization](vector-search-integrated-vectorization.md). The wizard chunks your content and calls an embedding model to vectorize content during indexing and for queries.
+In this quickstart, you use the **Import and vectorize data** wizard in the Azure portal to get started with [integrated vectorization](vector-search-integrated-vectorization.md). The wizard chunks your content and calls an embedding model to vectorize content during indexing and for queries.
 
 The sample data for this quickstart consists of text-based PDFs, but you can also use images and follow this quickstart to vectorize them.
 
@@ -47,7 +47,7 @@ For integrated vectorization, you must use one of the following embedding models
 | Provider | Supported models |
 |--|--|
 | [Azure OpenAI in Azure AI Foundry Models](/azure/ai-services/openai/how-to/create-resource) <sup>1, 2</sup> | text-embedding-ada-002<br>text-embedding-3-small<br>text-embedding-3-large |
-| [Azure AI services multi-service resource](/azure/ai-services/multi-service-resource#azure-ai-services-resource-for-azure-ai-search-skills) <sup>3</sup> | For text and images: [Azure AI Vision multimodal](/azure/ai-services/computer-vision/how-to/image-retrieval) <sup>4</sup></li> |
+| [Azure AI services multi-service resource](/azure/ai-services/multi-service-resource#azure-ai-multi-services-resource-for-azure-ai-search-skills) <sup>3</sup> | For text and images: [Azure AI Vision multimodal](/azure/ai-services/computer-vision/how-to/image-retrieval) <sup>4</sup></li> |
 | [Azure AI Foundry model catalog](/azure/ai-foundry/what-is-azure-ai-foundry) | For text:<br>Cohere-embed-v3-english<br>Cohere-embed-v3-multilingual<br><br>For images:<br>Facebook-DinoV2-Image-Embeddings-ViT-Base<br>Facebook-DinoV2-Image-Embeddings-ViT-Giant |
 
 <sup>1</sup> The endpoint of your Azure OpenAI resource must have a [custom subdomain](/azure/ai-services/cognitive-services-custom-subdomains), such as `https://my-unique-name.openai.azure.com`. If you created your resource in the [Azure portal](https://portal.azure.com/), this subdomain was automatically generated during resource setup.
@@ -74,6 +74,14 @@ To configure the recommended role-based access:
 
 1. On your search service, [enable roles](search-security-enable-roles.md) and [configure a system-assigned managed identity](search-howto-managed-identities-data-sources.md#create-a-system-managed-identity).
 
+1. [Assign the following roles](search-security-rbac.md) to yourself:
+
+   + **Search Service Contributor**
+
+   + **Search Index Data Contributor**
+
+   + **Search Index Data Reader**
+
 1. On your data source platform and embedding model provider, create role assignments that allow your search service to access data and models. See [Prepare sample data](#prepare-sample-data) and [Prepare embedding models](#prepare-embedding-model).
 
 > [!NOTE]
@@ -101,7 +109,7 @@ This section points you to the content that works for this quickstart. Before yo
 
    1. Select **Add** > **Add role assignment**.
 
-   1. Under **Job function roles**, select **[Storage Blob Data Reader](search-howto-managed-identities-data-sources.md#assign-a-role)**, and then select **Next**.
+   1. Under **Job function roles**, select **Storage Blob Data Reader**, and then select **Next**.
 
    1. Under **Members**, select **Managed identity**, and then select **Select members**.
 
@@ -127,7 +135,7 @@ This section points you to the content that works for this quickstart. Before yo
 
    1. Select **Add** > **Add role assignment**.
 
-   1. Under **Job function roles**, select **[Storage Blob Data Reader](search-howto-managed-identities-data-sources.md#assign-a-role)**, and then select **Next**.
+   1. Under **Job function roles**, select **Storage Blob Data Reader**, and then select **Next**.
 
    1. Under **Members**, select **Managed identity**, and then select **Select members**.
 
@@ -188,7 +196,7 @@ The wizard supports text-embedding-ada-002, text-embedding-3-large, and text-emb
 
    1. Select **Add** > **Add role assignment**.
 
-   1. Under **Job function roles**, select **[Cognitive Services OpenAI User](/azure/ai-services/openai/how-to/role-based-access-control#azure-openai-roles)**, and then select **Next**.
+   1. Under **Job function roles**, select **Cognitive Services OpenAI User**, and then select **Next**.
 
    1. Under **Members**, select **Managed identity**, and then select **Select members**.
 
@@ -257,7 +265,7 @@ For the model catalog, you should have an [Azure AI Foundry project](/azure/ai-f
 
 ## Start the wizard
 
-1. Sign in to the [Azure portal](https://portal.azure.com/) and go to your Azure AI Search service.
+1. Sign in to the [Azure portal](https://portal.azure.com/) and select your Azure AI Search service.
 
 1. On the **Overview** page, select **Import and vectorize data**.
 
@@ -271,7 +279,7 @@ For the model catalog, you should have an [Azure AI Foundry project](/azure/ai-f
 
    + OneLake
 
-1. Select the **RAG** tile.
+1. Select **RAG**.
 
    :::image type="content" source="media/search-get-started-portal-import-vectors/wizard-scenarios-rag.png" alt-text="Screenshot of the RAG tile in the wizard." border="true" lightbox="media/search-get-started-portal-import-vectors/wizard-scenarios-rag.png":::
 
@@ -371,7 +379,7 @@ In this step, you specify an embedding model to vectorize chunked data. Chunking
 
    + Azure AI Foundry model catalog
 
-   + An Azure AI Vision multimodal resource in the same region as Azure AI Search. If there's no [Azure AI services multi-service account](/azure/ai-services/multi-service-resource#azure-ai-services-resource-for-azure-ai-search-skills) in the same region, this option isn't available.
+   + An Azure AI Vision multimodal resource in the same region as Azure AI Search. If there's no [Azure AI services multi-service account](/azure/ai-services/multi-service-resource#azure-ai-multi-services-resource-for-azure-ai-search-skills) in the same region, this option isn't available.
 
 1. Specify the Azure subscription.
 
@@ -447,11 +455,12 @@ You can't modify the generated fields or their attributes, but you can add new f
 
 1. Select **Add field**.
 
-1. Select a source field from the list of available fields, provide a field name for the index, and accept the default data type or override as needed.
+1. Select a source field from the available fields, enter a field name for the index, and accept (or override) the default data type.
 
-   + Metadata fields are searchable but not retrievable, filterable, facetable, or sortable.
+   > [!NOTE]
+   > Metadata fields are searchable but not retrievable, filterable, facetable, or sortable.
 
-1. Select **Reset** if you want to restore the schema to its original version.
+1. If you want to restore the schema to its original version, select **Reset**.
 
 ## Schedule indexing
 
@@ -473,13 +482,16 @@ When the wizard completes the configuration, it creates the following objects:
 
 + An indexer with field mappings and output field mappings (if applicable).
 
+> [!TIP]
+> Wizard-created objects have configurable JSON definitions. To view or modify these definitions, select **Search management** from the left pane, where you can view your indexes, indexers, data sources, and skillsets.
+
 ## Check results
 
 Search Explorer accepts text strings as input and then vectorizes the text for vector query execution.
 
-1. In the Azure portal, go to **Search Management** > **Indexes**, and then select the index that you created.
+1. In the Azure portal, go to **Search Management** > **Indexes**, and then select your index.
 
-1. Select **Query options** and hide vector values in search results. This step makes your search results easier to read.
+1. Select **Query options**, and then select **Hide vector values in search results**. This step makes the results more readable.
 
    :::image type="content" source="media/search-get-started-portal-import-vectors/query-options.png" alt-text="Screenshot of the button for query options.":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "ドキュメントの更新: ベクター検索の開始方法"
}
```

### Explanation
このコードの変更は、`articles/search/search-get-started-portal-import-vectors.md` というマークダウンファイルに対して行われた更新を示しています。この更新では、主に以下のような改善が施されています。

1. **タイトルの修正**: 直訳的な表現から、より一貫性のあるスタイルに変更され、文の流れが向上しました。

2. **日付の更新**: 文書内の日付が更新され、最新の内容が反映されています。

3. **手順の明確化**: ウィザードを使用したデータのインポートとベクトル化に関する手順が具体的に記述されており、ユーザーがプロセスを追いやすくなっています。特に、役割の割り当てや資格情報の設定に関して詳しく説明されています。

4. **段落の整頓**: 段落が整頓され、情報が整理されることにより、視認性が向上しています。また、ベストプラクティスや役立つヒントが追加されており、読者がよりスムーズに作業を進められるよう配慮されています。

5. **機能の追加**: 検索結果をより見やすくするために、ベクトル値を隠すオプションが強調されています。

この更新により、ユーザーはAzureポータルでのベクター検索の利用方法をより体系的に理解でき、手順に従ってスムーズに操作を行うことができるようになります。リンクが提供されているため、ユーザーは関連情報に簡単にアクセスできます。


